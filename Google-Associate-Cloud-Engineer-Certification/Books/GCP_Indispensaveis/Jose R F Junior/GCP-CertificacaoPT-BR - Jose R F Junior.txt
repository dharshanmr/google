Guia de estudo oficial do engenheiro de nuvem do associado do Google Cloud Certified 

Introdução O 
Google Cloud Platform (GCP) é uma nuvem pública líder que fornece aos usuários parte da 
mesma infraestrutura de software, hardware e rede usada para fornecer serviços do Google. 
Empresas, organizações e indivíduos podem iniciar servidores em minutos, armazenar petabytes 
de dados e implementar nuvens virtuais globais com o GCP. Ele inclui uma 
interface de console fácil de usar , ferramentas de linha de comando e interfaces de programação de aplicativos (APIs) para gerenciar recursos na nuvem. Os usuários podem trabalhar com recursos gerais, como máquinas virtuais 
(VMs) e discos permanentes, ou optar por serviços altamente focados para Internet of Things (IoT),
aprendizado de máquina, mídia e outros domínios especializados. 
Implantar e gerenciar aplicativos e serviços no GCP exige um entendimento claro da maneira como o Google estrutura contas de usuários e gerencia identidades e 
controles de acesso . Você também precisa entender as vantagens e desvantagens de usar vários serviços. Engenheiros de computação associados certificados demonstraram o conhecimento 
e as habilidades necessárias para implantar e operar infraestrutura, serviços e redes no 
Google Cloud. 
Este guia de estudo foi elaborado para ajudar você a entender o GCP em detalhes para atender 
às necessidades desses recursos operacionais no Google Cloud. Sim, este livro irá, é claro, ajudá- 
lo a passar no exame de certificação Associate Cloud Engineer, mas este não é um emp:
guia. Você aprenderá mais do que o necessário para passar no exame; você entenderá como 
enfrentar os desafios do dia a dia enfrentados pelos engenheiros de nuvem, incluindo a escolha de serviços, o gerenciamento de usuários, a implantação e o monitoramento da infraestrutura e o mapeamento dos requisitos de negócios em soluções baseadas na nuvem. 
Cada capítulo deste livro aborda um único tópico e inclui uma 
seção “Exame Básico” que descreve as principais informações que você deve saber para passar no exame de certificação. Também 
há exercícios para ajudá-lo a revisar e reforçar sua compreensão do 
tópico do capítulo . Perguntas de exemplo são incluídas no final de cada capítulo para que você possa ter uma noção dos 
tipos de perguntas que você verá no exame. O livro também inclui flashcards e prática
exames que cobrem todos os tópicos que você aprenderá com este guia. 
O que este livro cobre? 
Este livro descreve produtos e serviços no GCP. Não inclui tópicos de administração do G Suite. 
Capítulo 1: Visão geral do Google Cloud Platform No capítulo de abertura, examinamos 
os tipos de serviços fornecidos pelo GCP, que incluem serviços de computação, armazenamento e rede 
, bem como serviços especializados, como produtos de aprendizado de máquina. Este capítulo 
Introdução 
também descreve algumas das principais diferenças entre a computação em nuvem e data center ou computação OnPremise.

Capítulo 2: Serviços do Google Cloud Computing Este capítulo fornece uma visão geral dos serviços de infraestrutura, como computação, armazenamento e rede. Introduz o conceito de gerenciamento de identidade e serviços relacionados. Também apresenta tópicos e ferramentas DevOps 
para implementar e monitorar aplicativos e recursos. O GCP inclui uma lista crescente de 
serviços especializados, como aprendizado de máquina e serviços de processamento de linguagem natural. 
Essas são brevemente discutidas neste capítulo. O capítulo apresenta a estrutura organizacional do Google Cloud com uma olhada nas regiões e zonas. O capítulo termina com uma discussão sobre o Cloud Launcher para implantar aplicativos empacotados. 

Capítulo 3: Projetos, contas de serviço e faturamento Uma das primeiras coisas que você fará
quando começar a trabalhar com o GCP é configurar suas contas. Neste capítulo, você aprenderá 
como os recursos nas contas são organizados em organizações, pastas e projetos. Você 
aprenderá a criar e editar essas estruturas. Você também verá como ativar APIs para 
projetos específicos, bem como gerenciar identidades de usuários e seus controles de acesso. Este capítulo 
descreve como criar contas de faturamento e vinculá-las a projetos. Você também aprenderá como 
criar orçamentos e definir alertas de faturamento para ajudá-lo a gerenciar os custos. Por fim, o capítulo 
descreve como criar contas do Stackdriver, que são usadas como parte do sistema de monitoramento no GCP. 

Capítulo 4: Introdução à computação no Google Cloud Neste capítulo, você verá
variedade de opções disponíveis para executar aplicativos e serviços no GCP. As opções incluem o 
Compute Engine, que fornece VMs que executam sistemas operacionais Linux ou Windows. O App 
Engine é uma opção de plataforma como serviço (PaaS) que permite aos desenvolvedores executar seus aplicativos sem ter que se preocupar com o gerenciamento de VMs. Se você estiver executando 
vários aplicativos e serviços, convém aproveitar os contêineres, que 
são uma alternativa leve às VMs. Você aprenderá sobre containers e como gerenciá- 
los com o Kubernetes Engine. Este capítulo também apresenta o Cloud Functions, que é para 
tarefas de curta duração orientadas a eventos, como o acionamento do processamento de uma imagem carregada em
Armazenamento na núvem. Você também aprenderá sobre o Firebase, um conjunto de serviços adequados para fornecer 
infraestrutura de back-end para aplicativos móveis. 
Capítulo 5: Computação com máquinas virtuais do Compute Engine Neste capítulo, você 
aprenderá a configurar VMs, incluindo a seleção de CPU, memória, opções de armazenamento e imagens do sistema operacional. Você aprenderá a usar o Console do GCP e o Cloud Shell para funcionar com as 
VMs. Além disso, você verá como instalar a interface da linha de comandos e o SDK, que 
será usado para iniciar e interromper as VMs. O capítulo também descreverá como habilitar o 
acesso à rede para VMs. 
Capítulo 6: Gerenciando máquinas virtuais No capítulo anterior, você aprendeu como
crie VMs e, neste capítulo, você aprenderá como gerenciar indivíduos e grupos 
de VMs. Você começará gerenciando uma única instância de uma VM usando o console do GCP 
e executando as mesmas operações usando o Cloud Shell e a linha de comando. Você 
Introdução XXIII 
também irá aprender a visualizar actualmente em execução VMs. Em seguida, você aprenderá sobre 
grupos de instâncias , que permitem criar conjuntos de VMs que você pode gerenciar como uma única unidade. 
Na seção sobre grupos de instâncias, você aprenderá a diferença entre 
grupos de instâncias gerenciados e não gerenciados. Você também aprenderá sobre instâncias preemptivas, que
são VMs de baixo custo que podem ser desativadas pelo Google. Você aprenderá sobre as compensações de custo-benefício de instâncias preemptivas. Por fim, o capítulo fecha com diretrizes 
para o gerenciamento de VMs. 

Capítulo 7: Computação com Kubernetes Este capítulo apresenta o Kubernetes Engine, 
o serviço Kubernetes gerenciado do Google. O Kubernetes é uma plataforma de orquestração de contêineres 
criada e lançada como código aberto pelo Google. Neste capítulo, você aprenderá os conceitos básicos 
de contêineres, orquestração de contêineres e a arquitetura do Kubernetes. A discussão incluirá uma visão geral dos objetos do Kubernetes, como pods, serviços, volumes e namespaces, bem como os controladores do Kubernetes, como ReplicaSets, implantações e jobs.
Em seguida, o capítulo recorre à implantação de um cluster do Kubernetes usando o console do GCP, o Cloud Shell 
e o SDK. Você também verá como implantar pods, o que inclui o download de uma 
imagem existente do Docker, a criação de uma imagem do Docker, a criação de um pod e a implantação de um aplicativo 
no cluster do Kubernetes. Claro, você precisará saber como monitorar um cluster de 
servidores. Este capítulo fornece uma descrição de como configurar o monitoramento e o registro em log com o 
Stackdriver, que é o serviço de monitoramento de aplicativos, serviços, contêiner e infraestrutura do Google. 
Capítulo 8: Gerenciando clusters do Kubernetes Neste capítulo, você aprenderá os fundamentos do 
gerenciamento de um cluster do Kubernetes, incluindo a visualização do status do cluster, a visualização do
conteúdo do repositório de imagens, exibindo detalhes sobre imagens no repositório e 
adicionando, modificando e removendo nós, pods e serviços. Como no capítulo sobre 
gerenciamento de VMs, neste capítulo, você aprenderá a realizar operações de gerenciamento com as três ferramentas de gerenciamento: console do GCP, Cloud Shell e SDK. O capítulo termina com uma discussão de diretrizes e boas práticas para gerenciar um 
cluster do Kubernetes. 

Capítulo 9: Computação com o App Engine O Google App Engine é a oferta de PaaS do Google. 
Você aprenderá sobre os componentes do App Engine, como aplicativos, serviços, versões e
instâncias. O capítulo também aborda como definir arquivos de configuração e especificar dependências de um aplicativo. Neste capítulo, você aprenderá como visualizar os recursos do App Engine 
usando o console do GCP, o Cloud Shell e o SDK. O capítulo também descreve como distribuir a 
carga de trabalho ajustando o tráfego com parâmetros de divisão. Você também aprenderá sobre o 
escalonamento automático no App Engine. 

Capítulo 10: Computação com funções de nuvem O Cloud Functions é para 
cálculos sem servidor e orientados a eventos . Este capítulo apresenta o Cloud Functions, inclusive usando-o para 
receber eventos, evocar serviços e retornar resultados. Em seguida, você verá casos de uso do Cloud Functions, como a integração com APIs de terceiros e o processamento orientado a eventos. Você vai aprender
sobre o serviço Pub / Sub do Google para processamento baseado em publicação e assinatura e 
como usar o Cloud Functions com Pub / Sub. As Cloud Functions são adequadas para responder a 
eventos no Cloud Storage. O capítulo descreve eventos do Cloud Storage e como usar as 
Funções de 

Introdução à Nuvem para receber e responder a esses eventos. Você aprenderá como usar o Stackdriver para 
monitorar e registrar detalhes das execuções da Cloud Function. Por fim, o capítulo termina com uma 
discussão sobre diretrizes para usar e gerenciar as Funções da nuvem. 
Capítulo 11: Planejando o armazenamento na nuvem Tendo descrito várias opções de computação no 
GCP, é hora de voltar sua atenção para o armazenamento. Este capítulo descreve as características de
sistemas de armazenamento, como tempo de acesso, persistência e modelo de dados. Neste capítulo, 
você aprenderá sobre diferenças entre caches, armazenamento persistente e armazenamento de arquivos. 
Você aprenderá sobre as vantagens e desvantagens em termos de custo-benefício do uso de armazenamento persistente regional e multirregional e do uso de armazenamento de arquivos nearline versus coldline. O capítulo inclui detalhes 
sobre as várias opções de armazenamento do GCP, incluindo o Cloud Storage para armazenamento de blobs; Cloud SQL 
e Spanner para dados relacionais; Datastore, Bigtable e BigQuery para armazenamento NoSQL; 
e Cloud Firebase para dados de aplicativos móveis. O capítulo inclui orientações detalhadas sobre
escolha de um armazenamento de dados com base em requisitos de consistência, disponibilidade, suporte a transações, custo, latência e suporte para diferentes padrões de leitura / gravação. 

Capítulo 12: Implantando o armazenamento no Google Cloud Platform Neste capítulo, você aprenderá 
como criar bancos de dados, adicionar dados, listar registros e excluir dados de cada um dos 
sistemas de armazenamento do GCP . O capítulo começa com a introdução do Cloud SQL, um serviço de banco de dados gerenciado que 
oferece instâncias gerenciadas MySQL e PostgreSQL. Você também aprenderá como criar 
bancos de dados no Cloud Datastore, BigQuery, Bigtable e Spanner. Em seguida, você voltará sua 
atenção para o Cloud Pub / Sub para armazenar dados em filas de mensagens, seguido por uma discussão sobre
Cloud Dataproc, um serviço de cluster Hadoop e Spark gerenciado, para processamento de grandes conjuntos de dados. 
Na próxima seção, você aprenderá sobre o Cloud Storage para objetos. O capítulo termina 
com orientações sobre como escolher um repositório de dados para um conjunto específico de requisitos. 
Capítulo 13: Carregando Dados no Armazenamento Há várias maneiras de obter dados no 
GCP. Este capítulo descreve como usar o SDK da linha de comando para carregar dados no Cloud 
SQL, no Cloud Storage, no Datastore, no BigQuery, no BigTable e no Dataproc. Ele também descreverá a 
importação e exportação em massa desses mesmos serviços. Em seguida, você aprenderá sobre dois 
padrões comuns de carregamento de dados: mover dados do Cloud Storage e transmitir dados para o 
Cloud Pub / Sub.
Capítulo 14: Funcionamento em rede na nuvem: nuvens privadas virtuais e redes privadas virtuais 
Neste capítulo, você voltará sua atenção para a rede com uma introdução aos 
conceitos básicos de rede, incluindo os seguintes: 
■ Endereços IP 
■ Blocos CIDR 
■ Redes e sub-redes 
■ Nuvens privadas virtuais (VPCs) 
■ Roteamento e regras 
■ Redes virtuais privadas (VPNs) 
■ Cloud DNS 
Introdução xxv 
■ Roteadores em 
nuvem 
■ Interconexão em nuvem ■ Emparelhamento externo 
Após ser apresentado aos principais conceitos de rede, você aprenderá a criar um VPC. 
Especificamente, isso incluirá a definição de uma VPC, a especificação de regras de firewall, a criação de uma VPN e
trabalhando com balanceadores de carga. Você aprenderá sobre diferentes tipos de balanceadores de carga e 
quando usá-los. 
Capítulo 15: Funcionamento em rede na nuvem: DNS, balanceamento de carga e endereçamento IP Neste 
capítulo, você aprenderá sobre tarefas comuns de gerenciamento de rede, como definir sub-redes, adicionar sub-redes a uma VPC, gerenciar blocos CIDR e reservar endereços IP. 
Você aprenderá a realizar cada uma dessas tarefas usando o Cloud Console, o Cloud Shell e o 
Cloud SDK. 
Capítulo 16: Implantando aplicativos com o Cloud Launcher e o Deployment Manager O 
Google Cloud Launcher é o mercado de GCPs de pilhas e serviços pré-configurados. Este 
capítulo apresenta o Cloud Launcher e descreve alguns aplicativos e serviços atualmente
acessível. Você aprenderá como navegar no Cloud Launcher, implantar aplicativos do Cloud 
Launcher e encerrar os aplicativos do Cloud Launcher. O capítulo também abordará os 
modelos do Deployment Manager para automatizar a implantação de um aplicativo e lançar 
um modelo do Deployment Manager para provisionar recursos do GCP e configurar um aplicativo 
automaticamente. 
Capítulo 17: Configurando o acesso e a segurança Este capítulo apresenta o gerenciamento de identidades. Em particular, você aprenderá sobre identidades, funções e atribuição e remoção de 
papéis de identidade. Este capítulo também apresenta as contas de serviço e como criá-las, atribuí- 
las às VMs e trabalhar com elas nos projetos. Você também aprenderá como visualizar a auditoria
logs para projetos e serviços. O capítulo termina com diretrizes para configurar a 
segurança do controle de acesso . 
Capítulo 18: Monitoramento, registro em log e estimativa de custos No capítulo final, discutiremos os alertas, o registro em log, o rastreamento distribuído e a depuração de aplicativos do Stackdriver. Cada um dos 
serviços GCP correspondentes é projetado para permitir serviços mais eficientes, funcionais e confiáveis 
. O capítulo termina com uma revisão da Calculadora de preços, que é útil para 
estimar o custo dos recursos no GCP. 
Ambiente de 
Aprendizagem Online Interativo e TestBank 
Estudar o material no Estudo Oficial de Engenheiro de Nuvem do Associado Certificado do Google
O guia é uma parte importante da preparação para o 
exame de certificação Associate Cloud Engineer , mas fornecemos ferramentas adicionais para ajudá-lo a se preparar. O TestBank on-line ajudará 
você a entender os tipos de perguntas que aparecerão no exame de certificação. 
Introdução 
Os testes de amostra no TestBank incluem todas as questões em cada capítulo, bem como as 
perguntas do teste de avaliação. Além disso, existem dois exames práticos com 50 questões cada. Você pode usar esses testes para avaliar sua compreensão e identificar áreas que 
podem exigir estudo adicional. 
Os flashcards no TestBank vão empurrar os limites do que você deve saber para o exame de certificação. Existem 100 perguntas fornecidas em formato digital. Cada flashcard tem um
pergunta e uma resposta correta. 
O glossário on-line é uma lista pesquisável de termos-chave introduzidos neste guia de exame que 
você deve conhecer para o exame de certificação Associate Cloud Engineer. 
Para começar a usá-los para estudar para o exame Engenheiro 
de computação do Google Certified Associate, acesse www.wiley.com/go/sybextestprep e registre seu livro para receber seu 
PIN exclusivo . Depois de ter o PIN, volte para www.wiley.com/go/sybextestprep, encontre seu livro 
e clique em Registrar ou Login e siga o link para registrar uma nova conta ou adicionar este 
livro a uma conta existente. 
Objetivos do Exame 
A certificação Associate Cloud Engineer é projetada para pessoas que criam, implantam e
gerenciar aplicativos e infraestrutura empresariais no GCP. Um Engenheiro de Nuvem Associado se 
sente à vontade para trabalhar com o Cloud Console, o Cloud Shell e o Cloud SDK. Esses indivíduos 
também entendem os produtos oferecidos como parte do GCP e seus casos de uso apropriados. 
O exame testará seu conhecimento do seguinte: 
■ Planejando uma solução de nuvem usando um ou mais serviços GCP 
■ Criando um ambiente de nuvem para uma organização 
■ Implantando aplicativos e infraestrutura 
■ Usando o monitoramento e o log para garantir a disponibilidade de soluções em nuvem 
■ Configurando o gerenciamento de identidades , controles de acesso e outras medidas de segurança 
Mapa de objetivos 
A seguir, os objetivos específicos definidos pelo Google em https://cloud.google.com/
certificação / guias / engenheiro de nuvem /. 
Seção 1: Configurando um ambiente de solução em nuvem 
1.1 Configurando projetos e contas em nuvem. As atividades incluem: 
■ Criar projetos 
■ Atribuir usuários a funções predefinidas de IAM (gerenciamento de identidades e acesso) em um 
projeto 
■ Vincular usuários a identidades do G Suite 
Introdução xxvii 
■ Ativando APIs em projetos 
■ Provisionando uma ou mais contas do Stackdriver 
1.2 Gerenciando a configuração de faturamento. As atividades incluem: 
■ Criar uma ou mais contas de faturamento 
■ Vincular projetos a uma conta de faturamento 
■ Estabelecer orçamentos e alertas de 
faturamento ■ Configurar exportações de faturamento para estimar cobranças diárias / mensais
1.3 Instalando e configurando a interface de linha de comando (CLI), especificamente o 
Cloud SDK (por exemplo, definindo o projeto padrão) 
Seção 2: Planejando e configurando uma solução em nuvem 
2.1 Planejando e estimando o uso do produto GCP usando a Calculadora de Preços 
2.2 Planejando e configurando recursos de computação . As considerações incluem: 
■ Selecionar opções de computação apropriadas para uma determinada carga de trabalho (por exemplo, Compute Engine, 
Kubernetes Engine, App Engine). 
■ Usar VMs preemptivas e tipos de máquina personalizados, conforme apropriado. 
2.3 Planejar e configurar as opções de armazenamento de dados. As considerações incluem: 
■ Escolha do produto (por exemplo, Cloud SQL, BigQuery, Cloud Spanner, Cloud Bigtable)
■ Escolhendo opções de armazenamento (por exemplo, Regional, Multirregional, Nearline, Coldline) 
2.4 Planejando e configurando recursos de rede. As tarefas incluem: 
■ Diferenciação das opções de balanceamento de carga 
■ Identificação dos locais de recursos em uma rede para disponibilidade 
■ Configuração do Cloud DNS 
Seção 3: implantação e implementação de uma solução em nuvem 
3.1 Implantando e implementando recursos do Compute Engine. As tarefas incluem: 
■ Iniciar uma instância de computação usando o Cloud Console e o Cloud SDK (gcloud) (por exemplo, 
atribuir discos, política de disponibilidade, chaves SSH) 
■ Criando um grupo de instâncias gerenciadas autoescaladas usando um modelo de instância 
■ Gerando / carregando uma chave SSH personalizada para instâncias
■ Configurando uma VM para o monitoramento e o registro em log do Stackdriver 
■ Avaliando cotas de computação e solicitando aumentos 
■ Instalando o Stackdriver Agent para monitoramento e registro em log 
xxviii Introdução 
3.2 Implantando e implementando recursos do Kubernetes Engine. As tarefas incluem: 
■ Implantando um cluster do Kubernetes Engine 
■ Implantando um aplicativo contêiner no Kubernetes Engine usando pods 
■ Configurando o monitoramento e o registro de aplicativos do Kubernetes Engine 
3.3 Implantando e implementando recursos do App Engine e do Cloud Functions. 
As tarefas incluem: 
■ Implantação de um aplicativo no App Engine (por exemplo, configuração de escala, versões e 
divisão de tráfego)
■ Implantando uma nuvem que recebe eventos do Google Cloud (por exemplo, eventos do Cloud Pub / Sub 
, eventos de notificação de alteração do objeto do Cloud Storage) 
3.4 Implantando e implementando soluções de dados. As tarefas incluem: 
■ Inicialização de sistemas de dados com produtos (por exemplo, Cloud SQL, Cloud Datastore, BigQuery, 
Cloud Spanner, Cloud Pub / Sub, Cloud Bigtable, Cloud Dataproc, Cloud Storage) 
■ Carregando dados (por exemplo, upload de linha de comando, transferência de API , importar / exportar, carregar dados 
do Cloud Storage, transmitir dados para o Cloud Pub / Sub) 
Implantando e implementando recursos de rede. As tarefas incluem: 
■ Criar um VPC com sub-redes (por exemplo, VPC de modo personalizado, VPC compartilhado) 
■ Iniciar uma instância do Compute Engine com configuração de rede personalizada (por exemplo,
endereço IP interno somente, acesso privado do Google, endereço IP externo e privado estático, 
tags de rede) 
■ Criando regras de entrada e saída de firewall para um VPC (por exemplo, sub-redes IP, tags, 
contas de serviço ) 
■ Criando uma VPN entre um Google VPC e uma rede externa usando o Cloud VPN 
■ Criando um balanceador de carga para distribuir o tráfego da rede de aplicativos para um aplicativo 
(por exemplo, balanceador de carga HTTP global, balanceador de carga proxy global 
, balanceador de carga proxy TCP global , balanceador de carga de rede regional, carga interna regional 
balancer) 
3.6 Implantando uma Solução usando o Cloud Launcher. As tarefas incluem: 
■ Navegar no catálogo do Cloud Launcher e visualizar os detalhes da solução
■ Implantando uma solução do mercado do Cloud Launcher 
3.7 Implantando um aplicativo usando o Deployment Manager. As tarefas incluem: 
■ Desenvolvimento de modelos do Deployment Manager para automatizar a implantação de um aplicativo 
■ Lançamento de um modelo do Deployment Manager para provisionar recursos do GCP e configurar 
um aplicativo automaticamente 
Introdução xxix 
Seção 4: Garantir a operação bem-sucedida de uma solução em nuvem 
4.1 Gerenciando recursos do Compute Engine. As tarefas incluem: 
■ Gerenciamento de uma única instância de VM (por exemplo, iniciar, interromper, editar a configuração ou excluir uma 
instância) 
■ SSH / RDP para a instância 
■ Anexar uma GPU a uma nova instância e instalar bibliotecas CUDA
■ Visualizando o inventário atual de VMs em execução (IDs de instâncias, detalhes) 
■ Trabalhando com instantâneos (por exemplo, criar um instantâneo de uma VM, ver instantâneos, excluir um 
instantâneo) 
■ Trabalhando com imagens (por exemplo, criar uma imagem de uma VM ou instantâneo ver imagens, 
apagar uma imagem) 
■ Trabalhando com grupos de instância (por exemplo, definir os parâmetros de escala automática, atribuir uma instância 
modelo, criar um modelo de exemplo, remover um grupo de instâncias) 
■ Trabalhar com interfaces de gerenciamento (por exemplo, Cloud Console, Nuvem Shell, Nuvem SDK ) 
4.2 recursos Motor Managing Kubernetes. As tarefas incluem: 
■ Visualização do inventário de clusters em execução atual (nós, pods, serviços) 
■ Navegação no repositório de imagens do contêiner e visualização dos detalhes da imagem do contêiner
■ Trabalhando com nós (por exemplo, adicionar, editar ou remover um nó) 
■ Trabalhando com pods (por exemplo, adicionar, editar ou remover pods) 
■ Trabalhando com serviços (por exemplo, adicionar, editar ou remover um serviço) 
■ Trabalhando com interfaces de gerenciamento (por exemplo, Cloud Console, Cloud Shell, Cloud SDK) 
4.3 Gerenciando recursos do App Engine. As tarefas incluem: 
■ Ajuste de parâmetros de divisão de tráfego de aplicativos 
■ Definição de parâmetros de dimensionamento para instâncias de escalonamento automático 
■ Trabalho com interfaces de gerenciamento (por exemplo, Cloud Console, Cloud Shell, Cloud SDK) 
4.4 Gerenciando soluções de dados. As tarefas incluem: 
■ Execução de consultas para recuperar dados de instâncias de dados (por exemplo, Cloud SQL, BigQuery, 
Cloud Spanner, Cloud Datastore, Cloud Bigtable, Cloud Dataproc)
■ Estimativa de custos de um BigQuery consulta 
■ backup e restauração de instâncias de dados (por exemplo, Cloud SQL, Cloud Datastore, Nuvem 
Dataproc) 
■ Rever o status do trabalho na nuvem Dataproc ou BigQuery 
■ Mover objetos entre baldes Cloud Storage 
xxx Introdução 
■ Convertendo baldes Cloud Storage entre classes de armazenamento 
■ Definir políticas de gerenciamento de ciclo de vida do objeto para intervalos do Cloud Storage 
■ Trabalhar com interfaces de gerenciamento (por exemplo, Cloud Console, Cloud Shell, Cloud SDK) 
4.5 Gerenciando recursos de rede. As tarefas incluem: 
■ Adicionando uma sub-rede a uma VPC existente 
■ Expandindo uma sub-rede de bloco CIDR para ter mais endereços IP 
■ Reservando endereços IP externos ou internos estáticos
■ Trabalhando com interfaces de gerenciamento (por exemplo, Cloud Console, Cloud Shell, Cloud SDK) 
4.6 Monitoramento e registro. As tarefas incluem: 
■ Criar alertas do Stackdriver com base nas métricas de recursos 
■ Criar métricas personalizadas do Stackdriver 
■ Configurar coletores de registros para exportar registros para sistemas externos (por exemplo, no local ou 
BigQuery) 
■ Exibindo e filtrando registros no Stackdriver 
■ Exibindo detalhes de mensagens de log específicos no Stackdriver 
■ Usando o diagnóstico de nuvem para pesquisar um problema de aplicativo (por exemplo, exibindo 
dados do Cloud Trace , usando o Cloud Debug para exibir um ponto no aplicativo) 
■ Visualizando o status do GCP 
■ Trabalhando com interfaces de gerenciamento (por exemplo, Cloud Console, Cloud Shell, Cloud SDK)
Seção 5: Configurando acesso e segurança 
5.1 Gerenciando o gerenciamento de identidade e acesso. As tarefas incluem: 
■ Exibir atribuições de IAM de conta 
■ Atribuir funções do IAM a contas ou Grupos do Google 
■ Definir funções personalizadas do IAM 
5.2 Gerenciar contas de serviço. As tarefas incluem: 
■ Gerenciando contas de serviço com escopos limitados 
■ Designando uma conta de serviço para instâncias de VM 
■ Concedendo acesso a uma conta de serviço em outro projeto 
Introdução xxxi 
5.3 Visualizando logs de auditoria para serviços gerenciados e de projeto 
Componentes de Computação em nuvem 
■ Recursos de computação 
■ Armazenamento 
■ Rede 
■ Serviços especializados
Diferença entre Cloud Computing e Data Center Computing 
■ Alugue em vez de recursos próprios 
■ Modelo de pagamento por uso 
Conforme alocação de recursos elásticos 
■ Serviços especializados O 

Google Cloud Platform (GCP) é um serviço de nuvem pública que 
oferece algumas das mesmas tecnologias usadas pelo Google para entregar 
seus próprios produtos. Este capítulo descreve os componentes mais importantes do GCP e discute como ele difere da 
computação baseada em datacenter no local . 
Tipos de serviços em 
nuvem Os provedores de nuvem públicos, como Google, Amazon e Microsoft, oferecem uma variedade de serviços para 
implantar computação, armazenamento, rede e outras infraestruturas para executar uma ampla variedade de serviços.
serviços e aplicações de negócios. Alguns usuários da nuvem são novas empresas que começam na 
nuvem. Eles nunca possuíram seu próprio hardware e software. Outros clientes da nuvem 
são empresas com vários datacenters que usam nuvens públicas para complementar seus 
datacenters. Esses diferentes tipos de usuários possuem requisitos diferentes. 
Uma empresa que começa na nuvem pode escolher os serviços que melhor atendem às 
necessidades de aplicativos e arquitetura sem precisar considerar a infraestrutura existente. Por exemplo, uma 
startup pode usar os serviços Cloud Identity e Access Management do GCP para todas as necessidades de autenticação e autorização. Uma empresa que já investiu em um Microsoft Active
A solução de diretórios para gerenciamento de identidades pode querer aproveitar esse sistema em vez de 
trabalhar somente com o sistema de gerenciamento de identidades da nuvem. Isso pode levar a um 
trabalho adicional para integrar os dois sistemas e mantê-los sincronizados. 
Outra área de preocupação para empresas com infraestrutura própria é estabelecer e 
manter uma rede segura entre seus recursos no local e seus 
recursos de nuvem pública . Se houver tráfego de rede de alto volume entre os sistemas no local e 
a nuvem pública, a empresa pode precisar investir em rede dedicada entre seu data 
center e uma instalação do provedor de nuvem pública. Se o volume de tráfego não justificar
o custo de uma conexão dedicada entre as instalações, a empresa pode usar uma 
rede privada virtual que é executada pela Internet pública. Isso requer design 
e gerenciamento de rede adicionais que uma empresa que esteja apenas na nuvem não precisaria resolver. 
Os provedores de nuvem pública oferecem serviços que se enquadram em quatro categorias amplas. 
■ Recursos de computação 
■ Armazenamento 
■ Rede 
■ Serviços especializados, como os 
clientes do Machine Learning Services Cloud, normalmente usam serviços em mais de uma dessas categorias. 
Tipos de serviços em nuvem 3 
Recursos de 
computação Os recursos de computação são apresentados em diversas formas em nuvens públicas. 
Máquinas virtuais
Máquinas Virtuais são uma unidade básica de recursos de computação e um bom ponto de partida para 
experimentar com a nuvem. Depois de criar uma conta com um provedor de nuvem e 
fornecer informações de faturamento, você pode usar um portal ou ferramentas de linha de comando para criar VMs. 
O Google Cloud Platform oferece várias VMs pré-configuradas com vários números de 
vCPUs e quantidades de memória. Você também pode criar uma configuração personalizada se as ofertas pré-configuradas não atenderem às suas necessidades. 
Depois de criar uma VM, você pode fazer login e administrá-la como quiser. Você tem 
acesso total à VM, para poder configurar sistemas de arquivos, adicionar armazenamento persistente, corrigir o 
sistema operacional ou instalar pacotes adicionais. Você decide o que executar na VM, que
outra pessoa terá acesso a ela e quando encerrar a VM. Uma VM gerenciada por você é como 
ter um servidor em seu escritório ao qual você tem direitos totais de administrador. 
Você pode, obviamente, criar várias VMs executando sistemas operacionais e 
aplicativos diferentes. O GCP também fornece serviços, como balanceadores de carga, que fornecem um único 
ponto de acesso a um back-end distribuído. Isso é especialmente útil quando você precisa ter 
alta disponibilidade para seu aplicativo. Se uma das VMs em um cluster falhar, a carga de trabalho 
poderá ser direcionada para as outras VMs no cluster. Os autoescaladores podem adicionar ou remover VMs do 
cluster com base na carga de trabalho. Isso é chamado de escalonamento automático. Isso ajuda a controlar o custo
por não executar mais VMs do que o necessário e garantir que a capacidade de computação suficiente esteja 
disponível quando as cargas de trabalho aumentarem. 
Clusters gerenciados do Kubernetes O 
Google Cloud Platform oferece todas as ferramentas necessárias para criar e gerenciar clusters 
de servidores. Muitos usuários da nuvem preferem se concentrar em seus aplicativos e não nas tarefas 
necessárias para manter um cluster de servidores funcionando. Para esses usuários, os clusters gerenciados são uma 
boa opção. 
Clusters gerenciados fazem uso de contêineres. Um contêiner é como uma VM leve que 
isola processos em execução em um contêiner de processos em execução em outro contêiner 
no mesmo servidor. Em um cluster gerenciado, você pode especificar o número de servidores
gostaria de correr e os recipientes que devem ser executados neles. Você também pode especificar 
parâmetros de escalonamento automático para otimizar o número de contêineres em execução. 
Em um cluster gerenciado, a integridade dos contêineres é monitorada para você. Se um contêiner falhar, 
o software de gerenciamento de cluster detectará e iniciará outro contêiner. 
Os contêineres são boas opções quando você precisa executar aplicativos que dependem de vários 
micro serviços em execução em seu ambiente. Os serviços são implantados por meio de contêineres 
e o serviço de gerenciamento de cluster cuida do monitoramento, da rede e de algumas 
tarefas de gerenciamento de segurança. 

4 Capítulo 1 ■ Visão geral da 
computação sem servidor do Google Cloud Platform
Ambas as VMs e clusters de kubernetes gerenciados exigem algum nível de esforço para configurar e 
administrar recursos de computação. A computação sem servidor é uma abordagem que permite aos desenvolvedores e administradores de aplicativos executarem seus códigos em um ambiente de computação que 
não requer a configuração de clusters de VMs ou kubernetes. 
O Google Cloud Platform tem duas opções de computação sem servidor: App Engine e Cloud 
Functions. O App Engine é usado para aplicativos e contêineres que são executados por longos períodos de tempo, como um back-end de website, um sistema de ponto de vendas ou um aplicativo de negócios personalizado. O Cloud Functions é uma plataforma para execução de código em resposta a um evento, como o 
upload de um arquivo ou a adição de uma mensagem a uma fila de mensagens. Esta opção sem servidor funciona bem
quando você precisa responder a um evento executando um pequeno processo codificado em uma função ou 
chamando um aplicativo de execução mais longa que pode estar em execução em uma VM, cluster gerenciado ou 
App Engine. 
Armazenamento 
As nuvens públicas oferecem alguns tipos de serviços de armazenamento que são úteis para uma ampla gama de requisitos de aplicativos. Esses tipos incluem o seguinte: 
■ Armazenamento de objetos ■ Armazenamento de 
arquivos 
■ Armazenamento em 
block ■ Caches Os 
usuários corporativos de serviços em nuvem costumam usar uma combinação desses serviços. 
O armazenamento de objetos é um sistema que gerencia o uso de armazenamento em termos de objetos ou blobs. 
Geralmente esses objetos são arquivos, mas é importante observar que os arquivos não são armazenados
um sistema de arquivos convencional. Objetos são agrupados em baldes. Cada objeto é individualmente 
endereçável, geralmente por um URL. 
O armazenamento de objetos não é limitado pelo tamanho dos discos ou unidades de estado sólido (SSDs) conectados a 
um servidor. Objetos podem ser carregados sem preocupação com a quantidade de espaço disponível em um 
disco. Várias cópias de objetos são armazenadas para melhorar a disponibilidade e a durabilidade. Em alguns 
casos, cópias de objetos podem ser armazenadas em regiões diferentes para garantir a disponibilidade, mesmo se uma 
região se tornar inacessível. 
Outra vantagem do armazenamento de objetos é que é sem servidor. Não há necessidade de criar 
VMs e anexar armazenamento a elas. Armazenamento de objetos do Google Cloud Platform, chamado Cloud
O armazenamento é acessível a partir de servidores em execução no GCP, bem como de outros dispositivos com 
acesso à Internet. 
Controles de acesso podem ser aplicados no nível do objeto. Isso permite que os usuários do armazenamento em nuvem 
controlem quais usuários podem acessar e atualizar objetos. 
Tipos de serviços na nuvem 5 
Armazenamento de 
arquivos Os serviços de armazenamento de arquivos fornecem um sistema de armazenamento hierárquico para arquivos. O armazenamento de sistemas de arquivos fornece sistemas de arquivos compartilhados em rede. O Google Cloud Platform tem um serviço de armazenamento de arquivos chamado 
Cloud Filestore, que é baseado no sistema de armazenamento Network File System (NFS). 
O armazenamento de arquivos é adequado para aplicativos que exigem acesso a arquivos do tipo
arquivos. O sistema de armazenamento de arquivos separa o sistema de arquivos de VMs específicas. O sistema de arquivos, 
seus diretórios e seus arquivos existem independentemente de VMs ou aplicativos que podem acessar esses 
arquivos. 
O armazenamento em bloco usa uma estrutura de dados de tamanho fixo chamada bloco para organizar dados. O armazenamento em bloco 
é comumente usado em discos efêmeros e persistentes conectados a VMs. Com um 
sistema de armazenamento em bloco , você pode instalar sistemas de arquivos na parte superior do armazenamento em bloco ou pode executar aplicativos 
que acessam blocos diretamente. Alguns bancos de dados relacionais podem ser projetados para acessar blocos 
diretamente, em vez de trabalhar com sistemas de arquivos. 
Nos sistemas de arquivos Linux, o 4KB é um tamanho de bloco comum. Bancos de dados relacionais geralmente escrevem
diretamente para blocos, mas eles geralmente usam tamanhos maiores, como 8KB ou mais. 
O armazenamento em block está disponível em discos conectados a VMs no Google Cloud Platform. 
O armazenamento em bloco pode ser persistente ou efêmero. Um disco persistente continua existindo 
e armazenando dados mesmo se ele estiver desconectado de um servidor virtual ou o servidor virtual ao qual ele está 
conectado for encerrado. Discos efêmeros existem e armazenam dados apenas enquanto uma VM está em execução. 
Os discos efêmeros armazenam arquivos do sistema operacional e outros arquivos e dados que são excluídos quando 
a VM é desligada. Os discos permanentes são usados ​​quando você deseja que os dados existam em um 
dispositivo de armazenamento de bloco independente de uma VM. Esses discos são boas opções quando você tem dados
que você deseja disponibilizar, independentemente do ciclo de vida de uma VM, e oferecer suporte ao rápido acesso ao 
sistema operacional e ao sistema de arquivos. 
O armazenamento de objetos também mantém os dados independentes do ciclo de vida de uma VM, mas não suporta 
o acesso ao sistema operacional ou ao sistema de arquivos; você tem que usar protocolos de alto nível como HTTP 
para acessar objetos. Leva mais tempo para recuperar dados do armazenamento de objetos do que para recuperá-los do 
armazenamento em bloco. Você pode precisar de uma combinação de armazenamento de objetos e armazenamento em bloco para atender às necessidades de sua 
aplicação. O armazenamento de objetos pode armazenar grandes volumes de dados que são copiados para o 
disco permanente quando necessário. Essa combinação oferece a vantagem de grandes volumes de armazenamento
com sistema operacional - e acesso baseado em sistema de arquivos quando necessário. 
Caches 
Caches são armazenamentos de dados na memória que mantêm o acesso rápido aos dados. O tempo necessário para recuperar 
dados é chamado de latência. A latência dos armazenamentos na memória é projetada para ser sub-milissegundo. Para fazer 
uma comparação, veja algumas outras latências: 
■ Fazer uma referência de memória principal demora 100 nanossegundos ou 0,1 microssegundo 
■ A leitura aleatória de 4KB de um SSD demora 150 microssegundos 
■ A leitura de 1 MB sequencialmente da memória demora 250 microssegundos 
6 Capítulo 1 ■ Visão geral de Google Cloud Platform 
■ A leitura sequencial de 1 MB de um SSD demora 1.000 microssegundos ou 1 milissegundo
■ A leitura sequencial de 1 MB do disco demora 20.000 microssegundos ou 20 milissegundos. 
Aqui estão algumas conversões para referência: 
■ 1.000 nanossegundos iguais a 1 microssegundo. 
■ 1.000 microssegundos iguais a 1 milissegundo. 
■ 1.000 milissegundos iguais a 1 segundo. 
Estes e outros dados de temporização úteis estão disponíveis em “Números de Latência 
Todos os Programadores Devem Saber” de Jonas Bonér em https://gist.github.com/jboner/2841832. 
Vamos trabalhar com um exemplo de leitura de 1 MB de dados. Se você tiver os dados armazenados em 
um cache na memória, poderá recuperar os dados em 250 microssegundos ou 0,25 milissegundos. 
Se esses mesmos dados forem armazenados em um SSD, levará quatro vezes mais tempo para ser recuperado em
1 milissegundo. Se você recuperar os mesmos dados de uma unidade de disco rígido, poderá esperar 
20 milissegundos ou 80 vezes a leitura de um cache na memória. 
Os caches são bastante úteis quando você precisa manter a latência de leitura ao mínimo em seu 
aplicativo. Claro, quem não ama tempos de recuperação rápidos? Por que nem sempre armazenamos 
nossos dados em caches? Existem três razões. 
■ A memória é mais cara que o armazenamento em SSD ou unidade de disco rígido (HDD). Não é prático, em muitos casos, ter tanto armazenamento em memória quanto armazenamento em bloco persistente em 
SSDs ou HDDs. 
■ Caches são voláteis; você perde os dados armazenados no cache quando a energia é perdida ou o 
sistema operacional é reinicializado. Você pode armazenar dados em um cache para acesso rápido, mas deve
nunca ser usado como o único armazenamento de dados que mantém os dados. Alguma forma de armazenamento persistente 
deve ser usada para manter um "sistema de verdade" ou um armazenamento de dados que sempre tenha a versão mais atualizada e precisa dos dados. 
■ Caches podem sair da sincronização com o sistema da verdade. Isso pode acontecer se o 
sistema de verdade for atualizado, mas os novos dados não forem gravados no cache. Quando isso acontece, pode ser difícil para um aplicativo que depende do cache detectar o fato de 
que os dados no cache são inválidos. Se você decidir usar um cache, certifique-se de criar uma 
estratégia de atualização de cache que atenda aos seus requisitos de consistência entre o cache e o cache.
sistema de verdade. Este é um problema tão grande projeto desafiador que tornou-se imortalizado em piada bem conhecida de Phil Karlton, “Há apenas duas coisas difíceis em computador 
ciência:. Cache invalidação e nomear as coisas” (Veja https://martinfowler.com/ 
bliki / TwoHardThings.html para riffs sobre esse raro exemplo de humor de ciência da computação.) 
Melhorando o tempo de resposta da consulta ao banco de dados Os 
usuários esperam que os aplicativos da Web sejam altamente responsivos. Se uma página levar mais de 2 a 
3 segundos para ser carregada, a experiência do usuário pode sofrer. É comum gerar o conteúdo 
de uma página usando os resultados de uma consulta de banco de dados, como pesquisar informações da conta. 
Tipos de serviços na nuvem 7
por ID do cliente. Quando uma consulta é feita ao banco de dados, o mecanismo de banco de dados procurará 
os dados, que geralmente estão no disco. Quanto mais usuários consultam o banco de dados, mais consultas 
ele precisa atender. Os bancos de dados mantêm uma fila de consultas que precisam ser respondidas, mas 
ainda não podem ser processadas porque o banco de dados está ocupado com outras consultas. Isso pode causar um tempo de 
resposta de latência mais longo, já que o aplicativo da Web terá que esperar que o banco de dados 
retorne os resultados da consulta. 
Uma maneira de reduzir a latência é reduzir o tempo necessário para ler os dados. Em alguns casos, 
ajuda a substituir as unidades de disco rígido por unidades SSD mais rápidas. No entanto, se o volume de consultas for alto o suficiente para que a fila de consultas seja longa mesmo com SSDs, outra opção é
use um cache. 
Quando os resultados da consulta são buscados, eles são armazenados no cache. Na próxima vez em que as informações forem necessárias, elas serão obtidas do cache, em vez do banco de dados. Isso pode reduzir a 
latência porque os dados são buscados da memória, o que é mais rápido que o disco. Ele também reduz 
o número de consultas ao banco de dados, portanto, as consultas que não podem ser respondidas procurando 
dados no cache não terão que esperar tanto tempo na fila de consulta antes de serem processadas. 
Rede 
Ao trabalhar na nuvem, você precisará trabalhar com a rede entre seus 
recursos de nuvem e possivelmente com seus sistemas locais. 
Quando você tem várias VMs em execução no seu ambiente de nuvem, provavelmente precisará
para gerenciar endereços IP em algum momento. Cada dispositivo ou serviço acessível por rede em seu 
ambiente precisará de um endereço IP. De fato, os dispositivos dentro do GCP podem ter 
endereços internos e externos. Os endereços internos são acessíveis apenas aos serviços da sua 
rede interna do GCP. Sua rede GCP interna é definida como uma nuvem privada virtual (VPC). 
Endereços externos podem ser acessados ​​da Internet. 
Endereços IP externos podem ser estáticos ou efêmeros. Endereços estáticos são atribuídos a um 
dispositivo por longos períodos de tempo. Endereços IP externos efêmeros são anexados às VMs 
e liberados quando a VM é interrompida. 
Além de especificar endereços IP, você frequentemente precisará definir regras de firewall
para controlar o acesso a sub-redes e VMs no seu VPC. Por exemplo, você pode ter um 
servidor de banco de dados ao qual deseja restringir o acesso, de forma que apenas um servidor de aplicativos possa 
consultar o banco de dados. Uma regra de firewall pode ser configurada para limitar o 
tráfego de entrada e saída ao endereço IP do servidor de aplicativos ou ao balanceador de carga na frente do cluster de aplicativos. 
Talvez seja necessário compartilhar dados e acesso à rede entre um data center local e 
seu VPC. Você pode fazer isso usando um dos vários tipos de peering, que é o termo geral 
para vincular redes distintas. 
8 Capítulo 1 ■ Visão geral dos 
serviços especializados do Google Cloud Platform
A maioria dos provedores de nuvem pública oferece serviços especializados que podem ser usados ​​como blocos de construção de 
aplicativos ou como parte de um fluxo de trabalho para processamento de dados. As características comuns dos serviços especializados são as seguintes: 
■ São sem servidor; você não precisa configurar servidores ou clusters. 
■ Eles fornecem uma função específica, como traduzir texto ou analisar imagens. 
■ Eles fornecem uma interface de programação de aplicativos (API) para acessar a funcionalidade do 
serviço. 
■ Assim como em outros serviços de nuvem, você é cobrado com base no uso do serviço. 
Estes são alguns dos serviços especializados no Google Cloud Platform: 
■ AutoML, um serviço de aprendizado de máquina 
■ Cloud Natural Language, um serviço para analisar texto
■ Cloud Vision para análise de imagens 
■ Cloud Inference API, um serviço para calcular correlações em dados de séries temporais 
Serviços especializados encapsulam recursos avançados de computação e os tornam acessíveis a desenvolvedores que não são especialistas em domínios, como processamento de linguagem natural 
e aprendizado de máquina. Espere ver mais serviços especializados adicionados ao Google Cloud 
Platform. 
Cloud Computing vs. Data Center 
Computing 
Embora possa parecer que a execução de VMs na nuvem não é muito diferente da execução 
-los em seu centro de dados, existem diferenças significativas entre a operar ambientes de TI na nuvem e um centro on-premise ou dados colocated. 
Aluguel em vez de recursos próprios
Os datacenters corporativos são preenchidos com servidores, matrizes de disco e equipamentos de rede. Este 
equipamento é geralmente de propriedade ou alugado por longos períodos pela empresa, um modelo que 
exige que as empresas gastem uma quantia significativa de dinheiro na frente para comprar 
equipamentos ou se comprometerem com um contrato de longo prazo para o equipamento. Essa abordagem funciona bem 
quando uma organização pode prever com precisão o número de servidores e outros equipamentos 
necessários por um período prolongado e pode utilizar esse equipamento de maneira consistente. 
O modelo não funciona tão bem quando as empresas precisam planejar capacidade de pico 
significativamente maior do que a carga de trabalho média. Por exemplo, um varejista pode ter uma média de 
Cloud Computing vs. Data Center Computing 9
carga que requer um cluster de 20 servidores, mas durante a temporada de férias a carga de trabalho 
aumenta até o ponto em que 80 servidores são necessários. A empresa poderia comprar 80 servidores e deixar 60 ociosos durante a maior parte do ano para ter recursos para acomodar a capacidade de pico. 
Alternativamente, ele poderia comprar ou alugar menos servidores e tolerar a perda nos negócios que 
ocorreria quando seus recursos computacionais não conseguissem acompanhar a demanda. Nenhuma delas é uma opção atraente. 
As nuvens públicas oferecem uma alternativa de aluguel de curto prazo da capacidade de computação. O varejista, 
por exemplo, pode executar VMs na nuvem durante períodos de pico, além de seus 
servidores no local . Isso dá ao varejista acesso aos servidores necessários quando precisa deles sem
ter que pagar por eles quando não são necessários. 
O custo unitário da execução de servidores na nuvem pode ser maior do que o da execução do 
servidor equivalente no data center, mas o custo total do local e de curto prazo na 
mistura de servidores na nuvem ainda pode ser significativamente menor do que o custo de compra ou leasing para 
capacidade máxima e deixar os recursos ociosos. 
Modelo Pay-as-You-Go-para-o-que-você-usa 
Relacionado ao modelo de aluguel de curto prazo da computação em nuvem está o modelo pay-as-you-go. 
Quando você executa um servidor virtual na nuvem, normalmente paga por um período mínimo, 
como 10 minutos, e depois paga por minuto usado posteriormente. O custo unitário por minuto
variar dependendo das características do servidor. Servidores com mais CPUs e memória 
custarão mais que servidores com menos CPUs e menos memória. 
É importante que os engenheiros de nuvem compreendam o modelo de preços de seu provedor de nuvem. É fácil criar uma conta grande para servidores e armazenamento se você não estiver monitorando seu 
uso. Na verdade, alguns clientes da nuvem acham que executar aplicativos na nuvem pode ser 
mais caro do que executá-los no local. 
Alocação de recursos elásticos 
Outro diferencial importante entre a computação em nuvem local e pública é a capacidade 
de adicionar e remover recursos de computação e armazenamento com pouca antecedência. Na nuvem, você poderia
inicie 20 servidores em questão de minutos. Em um data center local, pode levar dias ou 
semanas para fazer o mesmo se hardware adicional precisar ser provisionado. 
Os provedores de nuvem projetam seus data centers com recursos extensivos de computação, armazenamento e rede 
. Eles otimizam seu investimento alugando eficientemente esses recursos para os clientes. Com dados suficientes sobre os padrões de uso do cliente, eles podem prever a capacidade de que 
precisam para atender à demanda do cliente. Como eles têm muitos clientes, a variação na demanda 
de qualquer um dos clientes tem pouco efeito sobre o uso geral de seus recursos. 
Recursos extensivos e a capacidade de transferir recursos rapidamente entre os clientes
provedores de nuvem pública oferecem alocação de recursos elástica com mais eficiência do que pode ser feita 
em data centers menores. 
10 Capítulo 1 ■ Visão geral dos 
serviços 
especializados do Google Cloud Platform Os serviços especializados são, por sua natureza, pouco conhecidos. Muitos desenvolvedores entendem como desenvolver interfaces de usuário ou consultar um banco de dados, mas poucos foram expostos 
aos detalhes do processamento de linguagem natural ou do aprendizado de máquina. Grandes empresas podem 
ter recursos financeiros para desenvolver expertise interna em áreas como ciência de dados e 
visão de máquina, mas muitas outras não. 
Ao oferecer serviços especializados, os provedores de nuvem estão trazendo recursos avançados para
um público maior de desenvolvedores. Como o investimento em grandes quantidades de hardware, os 
fornecedores de nuvem pública podem investir em serviços especializados e recuperar seus custos e obter lucro porque 
os serviços especializados são usados ​​por um grande número de clientes. 
Fundamentos do exame 
Entenda as diferentes maneiras de fornecer recursos de computação em nuvem. Recursos de computação 
podem ser alocados como VMs individuais ou clusters de VMs gerenciados por você. Você também pode usar o 
cluster gerenciado de kubernetes (GKE) que alivia a sobrecarga operacional 
do gerenciamento de um cluster do Kubernetes. Opções de computação sem servidor aliviam os usuários de qualquer servidor
gestão. Em vez disso, os desenvolvedores executam seu código em um ambiente de contêiner gerenciado pelo provedor de nuvem ou em uma plataforma de computação projetada para código de execução curta. 
Desenvolvedores e profissionais de DevOps têm mais controle sobre os recursos quando 
gerenciam seus próprios servidores e clusters. Os serviços gerenciados e as opções sem servidor são boas 
escolhas quando você não precisa de controle sobre o ambiente de computação e obterá mais 
valor por não precisar gerenciar recursos de computação. 
Entenda as diferentes formas de armazenamento em nuvem e quando usá-las. Existem quatro 
categorias principais de armazenamento: caches de objeto, arquivo, bloco e memória. O armazenamento de objetos é 
projetado para armazenamento altamente confiável e durável de objetos, como imagens ou conjuntos de dados.
O armazenamento de objetos tem uma funcionalidade mais limitada do que os sistemas de armazenamento baseados no sistema de arquivos. O 
armazenamento baseado em sistema de arquivos fornece armazenamento de diretório hierárquico para arquivos e suporta 
funções comuns do sistema operacional e do sistema de arquivos. Os serviços do sistema de arquivos fornecem 
sistemas de arquivos acessíveis pela rede que podem ser acessados ​​por vários servidores. O armazenamento em bloco é usado para armazenar dados 
em discos. Sistemas de arquivos e bancos de dados fazem uso de sistemas de armazenamento em bloco. O armazenamento em bloco é 
usado com dispositivos de armazenamento persistentes, como SSDs e HDDs. Caches são 
armazenamentos de dados na memória usados ​​para minimizar a latência de recuperação de dados. Eles não fornecem armazenamento persistente e nunca devem ser considerados um "sistema de verdade".
Entenda as diferenças entre a execução de um ambiente de TI no local ou na nuvem. 
A execução de um ambiente de TI na nuvem tem várias vantagens, incluindo 
aluguel de recursos a curto prazo , modelo de pagamento conforme o uso, alocação de recursos elástica e a capacidade de usar 
serviços especializados. O custo unitário dos recursos da nuvem, como o custo por minuto de um servidor de médio porte, pode ser maior na nuvem do que no local. É importante entender o 
modelo de custo do seu provedor de nuvem para que você possa tomar decisões sobre a distribuição mais eficiente de carga de trabalho entre recursos em nuvem e no local. 
O Google Cloud Platform (GCP) é composto de quase 40 serviços 
que atendem a diversas necessidades de computação, armazenamento e rede.
Este capítulo fornece uma visão geral dos 
serviços GCP mais importantes e descreve alguns casos de uso importantes para esses serviços. 

Componentes de computação do Google Cloud Platform O 
Google Cloud Platform é um pacote de serviços de computação em nuvem que inclui serviços de computação, armazenamento e rede projetados para atender às necessidades de uma ampla variedade de clientes de computação em nuvem. Pequenas empresas podem ser atraídas por máquinas virtuais (VMs) e 
serviços de armazenamento . Grandes empresas e outras organizações consideráveis ​​podem estar mais interessadas no acesso 
a clusters altamente escaláveis ​​de VMs, uma variedade de bancos de dados relacionais e NoSQL, 
serviços de rede especializados e inteligência artificial avançada e recursos de aprendizado de máquina.
Este capítulo fornece uma visão geral de muitos dos serviços do GCP. A amplitude de serviços 
disponíveis no GCP continua a crescer. Quando você lê isso, o Google pode oferecer 
serviços adicionais. A maioria dos serviços pode ser agrupada em várias categorias principais. 
■ Recursos de computação ■ Recursos de 
armazenamento 
■ Bancos de dados 
■ Serviços de rede 
■ Gerenciamento de identidade e segurança 
■ Ferramentas de desenvolvimento ■ Ferramentas de 
gerenciamento 
■ Serviços especializados 
Computação Componentes do Google Cloud Platform 17 
Um engenheiro de nuvem associado certificado pelo Google deve estar familiarizado com os serviços de cada 
categoria eles são usados, e as vantagens e desvantagens dos vários serviços
em cada categoria. 
Recursos de computação 
Os serviços de nuvem pública fornecem uma variedade de opções de serviços de computação. Em uma extremidade do espectro, os clientes podem criar e gerenciar as próprias VMs. Esse modelo oferece ao usuário da nuvem 
o maior controle de todos os serviços de computação. Os usuários podem escolher o sistema operacional a ser 
executado, quais pacotes instalar e quando fazer backup e executar outras operações de manutenção. Esse tipo de serviço de computação é geralmente chamado de infraestrutura como serviço 
(IaaS). 
Um modelo alternativo é chamado de plataforma como um serviço (PaaS), que fornece um 
ambiente de tempo de execução para executar aplicativos sem a necessidade de gerenciar servidores, redes e sistemas de armazenamento subjacentes.
O produto de computação de IaaS do GCP é chamado de Compute Engine, e as ofertas de PaaS são o 
App Engine e as Cloud Functions. Além disso, o Google oferece o Kubernetes Engine, que é um 
serviço para gerenciar contêineres em um cluster; Esse tipo de serviço é uma 
alternativa cada vez mais popular ao gerenciamento de conjuntos individuais de VMs. 
O Compute Engine 
Compute Engine é um serviço que permite aos usuários criar VMs, anexar armazenamento persistente a 
essas VMs e fazer uso de outros serviços do GCP, como o Cloud Storage. 
VMs são abstrações de servidores físicos. Eles são essencialmente programas que emulam 
servidores físicos e fornecem CPU, memória, armazenamento e outros serviços que você
encontre se você executou seu sistema operacional favorito em um servidor em sua mesa ou em um data 
center. As VMs são executadas em um serviço de baixo nível chamado hypervisor. O GCP usa uma 
versão protegida de segurança do hipervisor KVM. KVM significa Kernel Virtual Machine e 
fornece virtualização em sistemas Linux executados em hardware x86. 
Os hipervisores são executados em um sistema operacional como o Linux ou o Windows Server. Os hipervisores podem 
executar vários sistemas operacionais, chamados de sistemas operacionais convidados, enquanto mantêm as 
atividades de cada um isolado de outros sistemas operacionais convidados. Cada instância de um 
sistema operacional convidado em execução é uma instância de VM. A Figura 2.1 mostra a organização lógica de 
instâncias de VM em execução em um servidor físico.
18 Capítulo 2 ■ As 
VMs do Google Cloud Computing Services vêm em uma variedade de tamanhos predefinidos, mas você também pode criar uma configuração personalizada. Quando você cria uma instância, você pode especificar um número de parâmetros, incluindo o 
seguinte: 
■ O sistema operacional 
■ Tamanho de armazenamento persistente 
■ Adição de unidades de processamento gráfico (GPUs) para as operações de computação intensiva, como 
a aprendizagem de máquina 
■ Fazendo o VM preemptivo 
A última opção, tornando uma VM preemptiva, significa que você pode ser cobrado significativamente menos 
para a VM do que o normal (cerca de 80 por cento menos), mas sua VM pode ser desligada a qualquer 
momento pelo Google. Ele será freqüentemente desligado se a VM preemptiva for executada por pelo menos 
24 horas.
Componentes de computação do Google Cloud Platform 19 O 
Capítulo 4 apresentará os detalhes do gerenciamento de VMs do Compute Engine. Para explorar o 
Compute Engine, faça login no Google Cloud Console, navegue até o menu principal à 
esquerda e selecione Compute Engine. 
Kubernetes Engine O 
Kubernetes Engine foi projetado para permitir que os usuários executem facilmente aplicativos em contêiner em um 
cluster de servidores. Os contêineres costumam ser comparados às VMs porque são usados ​​para 
isolar o processamento e os recursos de computação. Os contêineres adotam uma abordagem diferente das 
VMs para isolar processos de computação. 
Como mencionado, uma VM executa um sistema operacional convidado em um servidor físico. O físico
O servidor também executa um sistema operacional, junto com um hypervisor. Outra abordagem para isolar recursos de computação é usar recursos do sistema operacional host para isolar processos 
e recursos. Com essa abordagem, não há necessidade de um hipervisor; o sistema operacional do host 
mantém o isolamento. Em vez disso, um gerenciador de contêiner é usado. Ou seja, um único 
gerenciador de contêineres coordena os contêineres em execução no servidor. Nenhum 
sistema operacional adicional ou convidado é executado na parte superior do gerenciador de contêineres. Em vez disso, os contêineres utilizam a funcionalidade do sistema operacional do host, enquanto o sistema operacional e o gerenciador de contêiner asseguram o isolamento 
entre os contêineres em execução. A Figura 2.2 mostra a estrutura lógica dos contêineres.

20 Capítulo 2 ■ Serviços do Google Cloud Computing O 
Kubernetes Engine é um produto do GCP que permite aos usuários descrever os recursos de computação, 
armazenamento e memória que gostariam de executar seus serviços. O Kubernetes Engine, em 
seguida, provisiona os recursos subjacentes. É fácil adicionar e remover recursos de um 
cluster do Kubernetes usando uma interface de linha de comando ou uma interface gráfica com o usuário. 
Além disso, o Kubernetes monitora a integridade dos servidores no cluster e 
repara automaticamente os problemas, como servidores com falha. O Kubernetes Engine também suporta escalonamento automático, 
portanto , se a carga de seus aplicativos aumentar, o Kubernetes Engine alocará 
recursos adicionais .
O Capítulo 7 descreverá os detalhes do planejamento e do gerenciamento do Kubernetes Engine. Para 
explorar o Kubernetes Engine, faça login no Google Cloud Console, navegue até o menu principal 
à esquerda e selecione Kubernetes Engine. 
O App Engine do Google 
App Engine é a oferta de PaaS de computação do GCP. Com o App Engine, os desenvolvedores e administradores de aplicativos não precisam se preocupar com a configuração de VMs ou com a especificação de 
clusters do Kubernetes. Em vez disso, os desenvolvedores criam aplicativos em uma linguagem de programação popular, como Java, Go, Python ou Node.js, e implantam esse código em um 
ambiente de aplicativo sem servidor . 
O App Engine gerencia a infraestrutura de computação e rede subjacente. Não há
precisa configurar VMs ou proteger redes para proteger seu aplicativo. O App Engine é 
adequado para aplicativos de back-end da web e de dispositivos móveis. 
O App Engine está disponível em dois tipos: padrão e flexível. 
No ambiente padrão, você executa aplicativos em uma sandbox específica do idioma, portanto, 
seu aplicativo é isolado do sistema operacional do servidor subjacente, bem como de 
outros aplicativos em execução nesse servidor. O ambiente padrão é bem adequado para 
aplicativos que são escritos em um dos idiomas suportados e não precisam de 
pacotes do sistema operacional ou outros softwares compilados que precisem ser instalados junto com o 
código do aplicativo.
No ambiente flexível, você executa contêineres do Docker no ambiente do App Engine. 
O ambiente flexível funciona bem nos casos em que você tem código de aplicativo, mas também precisa de 
bibliotecas ou outro software de terceiros instalado. Como o nome indica, o ambiente flexível oferece mais opções, incluindo a capacidade de trabalhar com processos em segundo plano e 
gravar no disco local. 
O Capítulo 9 apresentará detalhes para usar e gerenciar o App Engine. Para explorar o App 
Engine, faça login no Google Cloud Console, navegue até o menu principal à esquerda e 
selecione App Engine. 
Funções de nuvem O 
Google Cloud Functions é uma opção de computação leve que é adequada para
Processamento orientado a eventos. O Cloud Functions executa o código em resposta a um evento, como um arquivo 
sendo carregado no Cloud Storage ou uma mensagem sendo gravada em uma fila de mensagens. O código 
que é executado no ambiente do Cloud Functions deve ser de curta duração - esse 
serviço de computação não é projetado para executar códigos de longa duração. Se você precisar dar suporte a 
aplicativos ou trabalhos de longa duração , considere o Compute Engine, o Kubernetes Engine ou o App Engine. 
Componentes de armazenamento do Google Cloud Platform 21 O 
Cloud Functions geralmente é usado para chamar outros serviços, como 
APIs (interfaces de programação de aplicativos ) de terceiros ou outros serviços do GCP, como um 
serviço de tradução de idiomas naturais .
Como o App Engine, o Cloud Functions é um produto sem servidor. Os usuários precisam apenas fornecer 
código; eles não precisam configurar VMs ou criar contêineres. O Cloud Functions será dimensionado automaticamente conforme a carga aumenta. 
Além dos quatro principais produtos de computação, o GCP oferece vários 
recursos de armazenamento . 
O Capítulo 10 descreverá os detalhes do uso e do gerenciamento das Funções do Cloud. Para explorar o 
Cloud Functions, faça login no Google Cloud Console, navegue até o menu principal à 
esquerda e selecione Cloud Functions. 
Componentes de armazenamento do Google 
Cloud Platform Os 
aplicativos e serviços que são executados na nuvem precisam atender a uma ampla gama de requisitos 
quando se trata de armazenamento. 
Recursos de armazenamento
Às vezes, um aplicativo precisa ler e gravar rapidamente para quantidades moderadas de dados. 
Outras vezes, um aplicativo de negócios pode precisar de acesso a petabytes de armazenamento de arquivamento, mas 
pode tolerar minutos e até horas para recuperar um documento. O GCP tem vários 
recursos de armazenamento para armazenar objetos e arquivos. 
Cloud Storage 
Cloud Storage é o sistema de armazenamento de objetos do GCP. Objetos podem ser qualquer tipo de arquivo ou 
objeto grande binário . Os objetos são organizados em buckets, que são análogos aos diretórios em um 
sistema de arquivos. É importante lembrar que o Cloud Storage não é um sistema de arquivos. É um serviço que recebe, armazena e recupera arquivos ou objetos de um sistema de armazenamento distribuído.
O Cloud Storage não faz parte de uma VM da mesma forma que um disco permanente anexado. O Cloud Storage 
é acessível a partir da VM (ou qualquer outro dispositivo de rede com privilégios apropriados) e, assim, 
complementa os sistemas de arquivos em discos permanentes. 
Cada objeto armazenado é endereçável exclusivamente por um URL. Por exemplo, uma versão em .pdf deste 
capítulo, denominada chapter1.pdf, armazenada em um bucket denominado ace-certification-exam-prep 
, pode ser endereçada da seguinte forma: 
https://storage.cloud.google.com/ace- certification-exam-prep / chapter1.pdf Os 
usuários do GCP e outros podem receber permissão para ler e gravar objetos em um 
bucket. Geralmente, um aplicativo receberá privilégios por meio de funções do IAM para permitir que o 
aplicativo leia e grave em intervalos.
O 
Cloud Storage é útil para armazenar objetos tratados como unidades de dados únicas. Por 
exemplo, um arquivo de imagem é um bom candidato para armazenamento de objetos. As imagens são geralmente lidas e 
escritas de uma só vez. Raramente é necessário recuperar apenas uma parte da imagem. Em geral, 
se você gravar ou recuperar um objeto de uma só vez e precisar armazená-lo independentemente dos servidores que podem ou não estar sendo executados a qualquer momento, o Cloud Storage é uma boa opção. 
Existem diferentes classes de armazenamento em nuvem. O armazenamento regional mantém cópias de objetos em 
uma única região do Google Cloud. Regiões são áreas geográficas distintas que podem ter múltiplos
zonas ou áreas de implantação. Uma zona é considerada um único domínio de falha, o que significa 
que, se todas as instâncias do aplicativo estiverem sendo executadas em uma zona e houver uma falha, todas as 
instâncias do aplicativo ficarão inacessíveis. O armazenamento regional é adequado para aplicativos que são executados na mesma região e precisam de acesso de baixa latência a objetos no Cloud Storage. 
O Cloud Storage tem alguns recursos avançados úteis, como suporte para várias regiões. 
Isso fornece o armazenamento de réplicas de objetos em várias regiões do Google Cloud, o que é 
importante para alta disponibilidade, durabilidade e baixa latência. 
Cenário do mundo real 
Se houve uma interrupção na região us-east1 e seus objetos foram armazenados apenas nessa região,
então você não seria capaz de acessar esses objetos durante a interrupção. No entanto, se você 
ativou o armazenamento em várias 
regiões, seus objetos armazenados em us-east1 também serão armazenados em outra região, como us-west1. 
Além da alta disponibilidade e durabilidade, o armazenamento de 
várias regiões permite acesso mais rápido aos dados quando os usuários ou aplicativos são distribuídos pelas regiões. 
Às vezes, os dados precisam ser mantidos por longos períodos de tempo, mas raramente são acessados. 
Nesses casos, o armazenamento nearline é uma boa opção porque custa menos do que o 
armazenamento regional ou multirregional e é otimizado para acesso não freqüente.
A classe de armazenamento a frio é um armazenamento de arquivamento de baixo custo projetado para alta durabilidade e acesso pouco frequente. Essa classe de armazenamento é adequada para dados acessados ​​menos de uma vez por ano. 
Um recurso útil do Cloud Storage é o conjunto de políticas de gerenciamento de ciclo de vida que podem 
gerenciar automaticamente objetos com base nas políticas que você define. Por exemplo, você pode definir 
uma política que mova todos os objetos com mais de 60 dias em um intervalo para aproximar o armazenamento ou 
exclua qualquer objeto em um intervalo de armazenamento de linha fria com mais de cinco anos. 
Disco 
permanente Os discos permanentes 
são serviços de armazenamento anexados a VMs no Compute Engine ou no Kubernetes Engine. Discos persistentes fornecem armazenamento de bloco em unidades de estado sólido (SSDs) e
discos rígidos (HDDs). Os SSDs costumam ser usados ​​para aplicativos de baixa latência nos quais 
o desempenho de disco persistente é importante. SSDs custar mais do que HDDs, então aplicações que requerem 
componentes de armazenamento de Cloud Platform Google 23 
grandes quantidades de armazenamento em disco persistente, mas podem tolerar vezes mais ler e escrever pode 
usar HDDs para satisfazer as suas necessidades de armazenamento. 
Uma vantagem dos discos permanentes no Google Cloud Platform é que esses discos suportam vários leitores sem prejudicar o desempenho. Isso permite que várias 
instâncias leiam uma única cópia de dados. Os discos também podem ser redimensionados conforme necessário durante o uso, 
sem a necessidade de reiniciar suas VMs. 
Os discos permanentes podem ter até 64 TB de tamanho usando SSDs ou HDDs.
O Cloud Storage para Firebase 
Mobile pode achar o Cloud Storage for Firebase a melhor combinação de 
armazenamento de objetos em nuvem e a capacidade de suportar uploads e downloads de dispositivos móveis 
com conexões de rede às vezes não confiáveis. 
A API do Cloud Storage for Firebase foi projetada para fornecer transmissão segura, além de 
mecanismos de recuperação robustos para lidar com a qualidade da rede potencialmente problemática. Depois que os arquivos, 
como fotos ou gravações musicais, são carregados no Cloud Storage, você pode acessar esses arquivos 
por meio da interface da linha de comando do Cloud Storage e dos SDKs (kits de desenvolvimento de software). 
Cloud Filestore 
Às vezes, os desenvolvedores precisam ter acesso a um sistema de arquivos hospedado em um servidor de rede.
armazenamento. Para esses casos de uso, o serviço Cloud Filestore fornece um sistema de arquivos compartilhado para uso 
com o Compute Engine e o Kubernetes Engine. 
O Filestore pode fornecer altos números de operações de entrada / saída por segundo (IOPS), bem 
como capacidade de armazenamento variável. Os administradores do sistema de arquivos podem configurar o Cloud Filestore para 
atender a seus requisitos específicos de IOPS e capacidade. 
O Filestore implementa o protocolo NFS (Network File System) para que os administradores do sistema 
possam montar facilmente sistemas de arquivos compartilhados em servidores virtuais. 
Sistemas de armazenamento como os que acabamos de descrever são usados ​​para armazenar objetos de granulação grossa, como 
arquivos. Quando os dados são mais bem estruturados e precisam ser recuperados usando linguagens de consulta
Para descrever o subconjunto de dados a ser retornado, é melhor usar um sistema de gerenciamento de banco de dados. 
O Capítulo 11 descreve detalhes e diretrizes para o planejamento de serviços de armazenamento. Para explorar as opções de armazenamento, faça login no Google Cloud Console, navegue até o menu principal à esquerda e 
selecione Armazenamento ou Filestore. 
Bancos de dados O 
GCP fornece várias opções de banco de dados. Alguns são bancos de dados relacionais e alguns são 
bancos de dados NoSQL. Alguns são sem servidor e outros exigem que os usuários gerenciem clusters de 
servidores. Alguns fornecem suporte para transações atômicas e outros são mais adequados para 
aplicativos com requisitos de consistência e transações menos rigorosos. Os usuários do GCP devem
Entender seus requisitos de aplicativo antes de escolher um serviço, e isso é especialmente 
importante ao escolher um banco de dados, que geralmente fornece serviços de armazenamento principais na 
pilha de aplicativos. 
O 
SQL 
Cloud SQL é o serviço de banco de dados relacional gerenciado do GCP que permite aos usuários configurar 
bancos de dados MySQL ou PostgreSQL em VMs sem precisar atender tarefas de administração de banco de dados, como fazer backup de bancos de dados ou aplicar patches ao software de banco de dados. O Cloud SQL está 
disponível em diversas configurações: 
■ Os bancos de dados MySQL de primeira geração usam o MySQL 5.5 ou 5.6 e podem ter até 16 GB de 
RAM e 500 GB de armazenamento de dados.
■ Os bancos de dados MySQL de segunda geração usam o MySQL 5.6 ou 5.7 e podem ter até 416 GB 
de RAM, além de 10 TB de armazenamento de dados. Os bancos de dados MySQL de segunda geração podem ser 
configurados para adicionar armazenamento automaticamente, conforme necessário. 
■ O PostgreSQL 9.6 é executado na plataforma de segunda geração e pode ser configurado com 
até 64 CPUs, 416 GB de RAM e até 10 TB de armazenamento. O Cloud SQL PostgreSQL 
também suporta extensões comuns como PostGIS, cubos para processamento analítico e 
hstore para armazenar pares de valores-chave em um único valor do PostgreSQL. 
Esse serviço de banco de dados inclui gerenciamento de replicação e permite 
failover automático , fornecendo bancos de dados altamente disponíveis.
Os bancos de dados relacionais são adequados para aplicativos com requisitos de estrutura de dados relativamente consistentes. Por exemplo, um banco de dados bancário pode rastrear números de contas, 
nomes de clientes , endereços e assim por diante. Como praticamente todos os registros no banco de dados precisarão da mesma 
informação, esse aplicativo é adequado para um banco de dados relacional. 
Cloud Bigtable O 
Cloud Bigtable é projetado para aplicativos em escala de petabytes que podem gerenciar até bilhões de 
linhas e milhares de colunas. Ele é baseado em um modelo NoSQL conhecido como 
modelo de dados de coluna ampla e, ao contrário do Cloud SQL, que suporta bancos de dados relacionais. O Bigtable é adequado para 
aplicativos que exigem operações de gravação e leitura de baixa latência. Ele é projetado para suportar
milhões de operações por segundo. 
O Bigtable se integra a outros serviços do Google Cloud, como Cloud Storage, Cloud 
Pub / Sub, Cloud Dataflow e Cloud Dataproc. Ele também suporta a API Hbase, que é uma 
API para acesso a dados no ecossistema de big data do Hadoop. O Bigtable também se integra a 
ferramentas de software livre para processamento de dados, análise de gráficos e análise de séries temporais. 
O Cloud Spanner 
Cloud Spanner é o banco de dados relacional distribuído globalmente do Google que combina os principais 
benefícios dos bancos de dados relacionais, como consistência e transações fortes, com a capacidade de dimensionar horizontalmente como um banco de dados NoSQL. Spanner é um banco de dados de alta disponibilidade
um Acordo de Nível de Serviço (SLA) de disponibilidade de 99,999%, tornando-o uma boa opção para 
aplicativos empresariais que exigem serviços de banco de dados relacional escalonáveis ​​e altamente disponíveis. 
O Cloud Spanner também tem segurança de nível empresarial com criptografia em repouso e criptografia 
em trânsito, junto com controles de acesso baseados em identidade. 
Cloud Spanner suporta SQL padrão ANSI 2011. 
Componentes de armazenamento do Google Cloud Platform 25 
Cloud Datastore O 
Cloud Datastore é um banco de dados de documentos NoSQL. Esse tipo de banco de dados usa o conceito de 
um documento, ou coleção de pares de valores-chave, como o bloco de construção básico. Documentos permitem
para esquemas flexíveis. Por exemplo, um documento sobre um livro pode ter pares de valores-chave listando autor, título e data de publicação. Alguns livros também podem ter informações sobre 
sites complementares e traduções para outros idiomas. O conjunto de chaves que podem ser 
incluídas não precisa ser definido antes do uso em bancos de dados de documentos. Isso é especialmente 
útil quando os aplicativos devem acomodar um intervalo de atributos, alguns dos quais podem não 
ser conhecidos em tempo de design. 
O Cloud Datastore é acessado por meio de uma API REST que pode ser usada em aplicativos em execução
no Compute Engine, no Kubernetes Engine ou no App Engine. Este banco de dados será dimensionado automaticamente com base na carga. Ele também fragmentará ou particionará dados conforme necessário para manter o desempenho. Como o Cloud Datastore é um serviço gerenciado, ele cuida da replicação, backups 
e outras tarefas de administração do banco de dados. 
Embora seja um banco de dados NoSQL, o Cloud Datastore oferece suporte a transações, índices e 
consultas semelhantes a SQL. 
O Cloud Datastore é adequado para aplicativos que exigem alta escalabilidade e dados estruturados e nem sempre precisam de consistência forte ao ler dados. Catálogos de produtos, 
perfis de usuários e histórico de navegação do usuário são exemplos dos tipos de aplicativos que usam o 
Cloud Datastore. 
Cloud Memorystore
Cloud Memorystore é um serviço de cache na memória. Outros bancos de dados oferecidos no GCP 
são projetados para armazenar grandes volumes de dados e oferecer suporte a consultas complexas, mas o Cloud 
Memorystore é um serviço Redis gerenciado para armazenamento em cache de dados usados ​​com freqüência na memória. 
Caches como esse são usados ​​para reduzir o tempo necessário para ler dados em um aplicativo. O Cloud 
Memorystore foi projetado para fornecer acesso sub-milissegundo aos dados. 
Como um serviço gerenciado, o Cloud Memorystore permite que os usuários especifiquem o tamanho de um cache 
enquanto deixam as tarefas administrativas no Google. O GCP garante alta disponibilidade, correção e 
failover automático para que os usuários não precisem. 
Cloud Firestore
O Cloud Firestore é outro serviço de banco de dados NoSQL gerenciado pelo GCP projetado como back-end para aplicativos móveis e da Web altamente escalonáveis. Um recurso distintivo do Cloud 
Firestore são suas bibliotecas cliente que fornecem suporte, sincronização e outros recursos off-line para gerenciar dados em dispositivos móveis, dispositivos IoT e armazenamentos de dados de back-end. Por 
exemplo, aplicativos em dispositivos móveis podem ser atualizados em tempo real conforme os dados no back-end são alterados. 
O Cloud Firebase inclui um modo Datastore, que permite que aplicativos escritos para o 
Datastore funcionem com o Cloud Firebase também. Ao executar no modo nativo, o Cloud 
Firestore fornece sincronização de dados em tempo real e suporte offline. 
26 Capítulo 2 ■ Serviços do Google Cloud Computing
O Cloud Firestore está atualmente em versão beta. 
O Capítulo 12 investiga detalhes de como criar vários tipos de bancos de dados, além de como 
carregar, excluir e consultar dados. Cada um dos bancos de dados pode ser acessado no 
menu principal do Google Cloud Console. A partir daí, você pode começar a explorar como cada um funciona 
e começar a ver as diferenças. 
Componentes de rede do Google 
Cloud Platform 
Nesta seção, revisaremos os principais componentes de rede. Os detalhes sobre como configurar 
redes e gerenciá-los estão descritos nos Capítulos 14 e 15. 
Serviços de rede O 
Google Cloud Platform fornece vários serviços de rede projetados para permitir que os usuários
Para configurar redes virtuais dentro da infraestrutura de rede global do Google, conecte os datacenters privados à rede do Google, otimize a entrega de conteúdo e proteja seus 
recursos de nuvem usando serviços de segurança de rede. 
Nuvem privada virtual 
Quando uma empresa opera seu próprio datacenter, ela controla o que está fisicamente localizado 
nesse datacenter e conectado à sua rede. Sua infraestrutura é fisicamente isolada 
de outras organizações em execução em outros data centers. Quando uma organização muda para 
uma nuvem pública, ela compartilha a infraestrutura com outros clientes dessa nuvem pública. Embora 
várias empresas usem a mesma infraestrutura de nuvem, cada empresa pode logicamente
isolar seus recursos de nuvem criando uma nuvem privada virtual (VPC). 
Uma característica distintiva do GPC é que um VPC pode abranger o mundo sem depender 
da Internet pública. O tráfego de qualquer servidor em um VPC pode ser roteado de forma segura pela 
rede global do Google para qualquer outro ponto da rede. Outra vantagem da 
estrutura de rede do Google é que seus servidores de back-end podem acessar serviços do Google, 
como aprendizado de máquina ou serviços de IoT, sem criar um endereço IP público para 
servidores de back-end . 
As VPCs no Google Cloud podem ser vinculadas a redes privadas virtuais no local usando o 
IPSec (Internet Protocol Security). 
Embora uma VPC seja global, as empresas podem usar projetos e contas de faturamento separados para
gerenciar diferentes departamentos ou grupos dentro da organização. Os firewalls também podem ser usados ​​para 
restringir o acesso a recursos em um VPC. 
Componentes de rede do Google Cloud Platform 27 
Balanceamento de carga em nuvem O 
Google fornece balanceamento de carga global para distribuir cargas de trabalho em toda a sua infraestrutura em nuvem. Usando um único endereço IP de multicast, o Cloud Load Balancing pode distribuir a 
carga de trabalho dentro e entre regiões, adaptar-se a servidores com falha ou degradados e dimensionar automaticamente seus 
recursos de computação para acomodar alterações na carga de trabalho. O Cloud Load Balancing também suporta o balanceamento de carga interno, portanto, nenhum endereço IP precisa ser exposto à Internet para obter 
as vantagens do balanceamento de carga.
O Cloud Load Balancing é um serviço de software que pode balancear a carga de 
tráfego HTTP, HTTPS, TCP / SSL e UDP. 
Os Cloud Armor 
Services expostos à Internet podem se tornar alvos de ataques distribuídos de negação de serviço (DDoS) 
. O Cloud Armor é um serviço de segurança de rede do Google que se baseia no 
serviço de Balanceamento de Carga de HTTP Global (s). Os recursos do Cloud Armor incluem: 
■ Capacidade de permitir ou restringir o acesso com base no endereço IP 
■ Regras predefinidas para combater ataques de script entre sites 
■ Capacidade de combater ataques de injeção SQL 
■ Capacidade de definir regras no nível 3 (rede) e no nível 7 (aplicativo) 
■ Permite e restringe o acesso com base na geolocalização do tráfego de entrada 
Cloud CDN
Com redes de entrega de conteúdo (CDNs), usuários em qualquer lugar podem solicitar conteúdo de sistemas 
distribuídos em várias regiões. As CDNs permitem uma resposta de baixa latência a essas solicitações, 
armazenando em cache o conteúdo em um conjunto de pontos de extremidade em todo o mundo. Atualmente, o Google tem mais de 
90 endpoints CDN gerenciados como um recurso global, portanto, não há necessidade de manter 
configurações específicas da região. 
As CDNs são especialmente importantes para sites com grandes quantidades de conteúdo estático e um 
público global. Os sites de notícias, por exemplo, podem usar o serviço Cloud CDN para garantir uma 
resposta rápida a solicitações de qualquer ponto do mundo. 
O Cloud Interconnect 
Cloud Interconnect é um conjunto de serviços do GCP para conectar suas redes existentes ao
Rede do Google. O Cloud Interconnect oferece dois tipos de conexões: interconexões e 
peering. 
A interconexão com acesso direto a redes usa o 
padrão Alocação de Endereços para Internets Privados (RFC 1918) para se conectar a dispositivos em seu VPC. A conexão de rede direta é mantida entre uma on-premise ou hospedado centro de dados e um dos do Google 
instalações de colocation, que estão localizados na América do Norte, América do Sul, Europa, Ásia, 
28 Capítulo 2 ■ Google Cloud Computing Serviços 
e Austrália. Como alternativa, se uma organização não puder obter uma interconexão direta com 
um recurso do Google, ela poderá usar o Partner Interconnect. Este serviço depende de um terceiro
provedor de rede para fornecer conectividade entre o data center da empresa e uma 
instalação do Google . 
Para organizações que não exigem a largura de banda de uma interconexão direta ou por pares, o 
Google oferece serviços de VPN que permitem que o tráfego transmita entre data centers e 
instalações do Google usando a Internet pública. 
Cloud DNS 
Cloud DNS é um serviço de nome de domínio fornecido no GCP. O Cloud DNS é um serviço de alta disponibilidade e 
baixa latência para mapeamento de nomes de domínio, como example.com, para endereços IP, 
como 74.120.28.18. 
O Cloud DNS é projetado para dimensionar automaticamente para que os clientes possam ter milhares e milhões de endereços sem a preocupação de dimensionar a infraestrutura subjacente. DNS da nuvem
também fornece zonas privadas que permitem criar nomes personalizados para suas VMs, se você 
precisar delas. 
Gerenciamento de identidades O serviço de gerenciamento 
de identidade e acesso a nuvem (IAM) do GCP permite que os clientes definam 
controles de acesso refinados em recursos na nuvem. O IAM usa os conceitos de usuários, 
funções e privilégios. 
Identidades são abstrações sobre usuários de serviços, como um usuário humano. Depois que uma 
identidade é autenticada pelo login ou por algum outro mecanismo, o usuário autenticado pode 
acessar recursos e executar operações com base nos privilégios concedidos a essa identidade. 
Por exemplo, um usuário pode ter o privilégio de criar um intervalo no Cloud Storage ou excluir uma 
VM em execução no Compute Engine.
Os usuários geralmente precisam de conjuntos semelhantes de permissões. Alguém que tenha a capacidade de criar uma 
VM provavelmente desejará modificar ou excluir essas VMs. Grupos de permissões relacionadas podem ser agrupados em funções. Funções são conjuntos de permissões que podem ser atribuídas a uma 
identidade. 
Como Engenheiro de Nuvem de Associado Certificado pelo Google, você se familiarizará com identidades, funções e permissões e como administrá-las em organizações e projetos. 
Você pode encontrar ferramentas de gerenciamento de identidade no menu do IAM e do administrador no Google 
Cloud Console. O Capítulo 17 fornece detalhes sobre identidade, funções e melhores práticas para seu 
gerenciamento. 
Ferramentas de desenvolvimento O 
Google Cloud Platform é uma excelente opção para desenvolvedores e engenheiros de software, porque
do fácil acesso a serviços de infraestrutura e gerenciamento de dados, mas também às ferramentas que ele 
suporta. 
Componentes adicionais do Google Cloud Platform 29 O 
Cloud SDK é uma interface de linha de comando para gerenciar recursos do GCP, incluindo VMs, 
armazenamento em disco, firewalls de rede e praticamente qualquer outro recurso que você possa implantar no GCP. 
Além de uma interface de linha de comando, o Cloud SDK tem bibliotecas de clientes para Java, Python, 
Node.js, Ruby, GO, .NET e PHP. 
O GCP também oferece suporte à implantação de aplicativos em contêineres com o Container Registry, Cloud 
Build e Cloud Source Repositories. 
O Google também desenvolveu plug-ins para facilitar o trabalho com 
ferramentas de desenvolvimento populares . Estes incluem o seguinte:
■ Ferramentas em nuvem para IntelliJ 
■ Ferramentas em nuvem para PowerShell 
■ Ferramentas em nuvem para Visual Studio 
■ Ferramentas em nuvem para Eclipse 
■ Plug-in Gradle do 
App Engine ■ Plug- in Maven do App Engine 
Obviamente, os aplicativos passam do desenvolvimento para a implantação de produção e o GCP 
acompanha esse fluxo com gerenciamento adicional ferramentas para ajudar a monitorar e manter os aplicativos depois que eles são implantados. 
Componentes adicionais das 
ferramentas de gerenciamento do Google 
Cloud Platform são projetados para profissionais de DevOps que são responsáveis ​​por garantir 
a confiabilidade, a disponibilidade e a escalabilidade dos aplicativos. 
Ferramentas de gerenciamento 
A seguir estão algumas das ferramentas mais importantes na categoria de ferramentas de gerenciamento:
Stackdriver Este é um serviço que coleta métricas, logs e dados de eventos de aplicativos 
e infraestrutura e integra os dados para que os engenheiros de DevOps possam monitorar, avaliar e 
diagnosticar problemas operacionais. 
Monitoramento Isso amplia os recursos do Stackdriver coletando dados de desempenho 
do GCP, recursos da AWS e instrumentação de aplicativos, incluindo 
sistemas populares de código aberto , como NGINX, Cassandra e Elasticsearch. 
Registro Este serviço permite que os usuários armazenem e analisem e alertem sobre dados de registro dos registros do 
GCP e AWS. 
Relatório de Erros Agrega as informações de falha do aplicativo para exibição em uma 
interface centralizada . 
30 Capítulo 2 ■ Serviços do Google Cloud Computing
Rastreamento Este é um serviço de rastreamento distribuído que captura dados de latência sobre um aplicativo 
para ajudar a identificar áreas com problemas de desempenho. 
Depurador Permite que os desenvolvedores inspecionem o estado de execução do código, injetem comandos e visualizem as variáveis ​​da pilha de chamadas. 
Perfilador Usado para coletar informações de utilização de CPU e memória na 
hierarquia de chamadas de um aplicativo. O Profiler usa amostragem estatística para minimizar o impacto do perfil no desempenho do aplicativo. 
A combinação de ferramentas de gerenciamento fornece insights sobre aplicativos à medida que eles são executados na 
produção, permitindo um monitoramento e análise mais eficazes dos sistemas operacionais. 
Serviços Especializados
Além das ofertas de IaaS e PaaS, o GCP possui serviços especializados para APIs, análise de dados e aprendizado de máquina. 
Apigee API Platform 
A plataforma API Apigee é um serviço de gerenciamento para clientes GCP que fornecem acesso API 
aos seus aplicativos. A plataforma Apigee permite que os desenvolvedores implantem, monitorem e protejam 
suas APIs. Ele também gera proxies de API com base na especificação de API aberta. 
É difícil prever a carga em uma API e, às vezes, picos de uso podem ocorrer. Para esses 
momentos, a plataforma Apigee API fornece roteamento e limitação de taxa com base nas políticas que os clientes podem definir. 
As APIs podem ser autenticadas usando o OAuth 2.0 ou o SAML. Os dados são criptografados em 
trânsito e em repouso na plataforma Apigee API.
Análise de dados O 
GCP tem vários serviços projetados para analisar grandes volumes de dados nos 
modos de lote e fluxo contínuo . Algumas das ferramentas mais importantes desse conjunto de serviços incluem: 
■ BigQuery, um serviço de banco de dados de análise em escala de petabytes para armazenamento de dados 
■ Cloud Dataflow, uma estrutura para definir pipelines de processamento em lote e fluxo 
■ Cloud Dataproc, Hadoop e Spark gerenciados serviço 
■ Cloud Dataprep, um serviço que permite aos analistas explorarem e prepararem dados para análise 
Muitas vezes, os projetos de análise de dados e data warehousing usam vários desses serviços 
juntos. 
Fundamentos do Exame 31 
IA e Aprendizagem Automática
O Google é líder em IA e aprendizado de máquina, portanto, não é surpresa que o GCP inclua vários 
serviços de AI. Os serviços especializados nessa área incluem o seguinte: 
Cloud AutoML Esta é uma ferramenta que permite que os desenvolvedores sem experiência 
em aprendizado de máquina desenvolvam modelos de aprendizado de máquina. 
Cloud Machine Learning Engine Esta é uma plataforma para construir e implementar 
sistemas de aprendizado de máquina escaláveis para produção. 
Cloud Natural Language Processing Esta ferramenta é para analisar linguagens humanas e 
extrair informações do texto. 
Cloud Vision Esta é uma plataforma de análise de imagens para anotar imagens com metadados, 
extrair texto ou filtrar conteúdo. 
Fundamentos do Exame
Entenda as diferenças entre o Compute Engine, o Kubernetes Engine, o App Engine e o 
Cloud Functions. O Compute Engine é o serviço de VM do Google. Os usuários podem escolher CPUs, memória, discos permanentes e sistemas operacionais. Eles podem personalizar ainda mais uma VM adicionando 
unidades de processamento gráfico para operações com uso intenso de computação. As VMs são gerenciadas individualmente 
ou em grupos de servidores semelhantes. 
O Kubernetes Engine gerencia grupos de servidores e aplicativos virtuais que são executados em contêineres. Contêineres são mais leves que as VMs. O Kubernetes é chamado de serviço de orquestração 
porque distribui contêineres entre clusters, monitora a integridade do cluster e dimensiona conforme proscrito por configurações.
O Google App Engine é o PaaS do Google. Os desenvolvedores podem executar seu código em uma caixa de proteção específica do idioma ao usar o ambiente padrão ou em um contêiner ao usar o ambiente flexível. O App Engine é um serviço sem servidor, portanto, os clientes não precisam especificar 
configurações de VM nem gerenciar servidores. 
O Cloud Functions é um serviço sem servidor projetado para executar código de execução curta que 
responde a eventos, como uploads de arquivos ou mensagens que estão sendo publicadas em uma fila de mensagens. 
Funções podem ser escritas em Node.js ou Python. 
Entenda o que se entende por serverless. Sem servidor significa que os clientes que usam um serviço 
não precisam configurar, monitorar ou manter os recursos de computação subjacentes ao serviço.
Isso não significa que não haja servidores envolvidos - sempre há servidores físicos que executam 
aplicativos, funções e outros softwares. Sem servidor refere-se apenas a não precisar gerenciar 
esses recursos subjacentes. 
32 Capítulo 2 ■ Serviços do Google Cloud Computing 
Entenda a diferença entre armazenamento de objetos e arquivos. Armazenamentos de objetos são usados ​​para armazenar 
e acessar recursos baseados em arquivos. Esses objetos são referenciados por um identificador único, como 
um URL. Os armazenamentos de objetos não fornecem serviços de sistema de bloco ou de arquivo, portanto, não são adequados 
para armazenamento de banco de dados. O Cloud Storage é o serviço de armazenamento de objetos do GCP. 
O armazenamento de arquivos suporta o acesso baseado em blocos aos arquivos. Os arquivos são organizados em diretórios e
subdiretórios. O Filestore do Google é baseado no NFS. 
Conheça os diferentes tipos de bancos de dados. Bancos de dados são amplamente divididos em 
bancos de dados relacionais e NoSQL. 
Bancos de dados relacionais suportam transações, consistência forte e as linguagens de consulta SQL. Bancos de dados relacionais têm sido tradicionalmente difíceis de dimensionar horizontalmente. O Cloud 
Spanner é um banco de dados relacional global que fornece as vantagens dos bancos de dados relacionais 
com a escalabilidade anteriormente encontrada apenas em bancos de dados NoSQL. 
Bancos de dados NoSQL são projetados para serem escaláveis ​​horizontalmente. Outros recursos, como 
consistência forte e suporte para SQL padrão, são frequentemente sacrificados para obter escalabilidade.
e respostas de consulta de baixa latência. Os bancos de dados NoSQL podem ser armazenamentos de valor-chave, como o Cloud 
Memorystore, bancos de dados de documentos, como o Cloud Datastore, ou bancos de dados de coluna ampla, como o 
Cloud Bigtable. 
Entenda nuvens privadas virtuais. Um VPC é um isolamento lógico dos 
recursos de nuvem de uma organização dentro de uma nuvem pública. No GCP, as VPCs são globais; eles não estão restritos a uma única 
zona ou região. Todo o tráfego entre os serviços do GCP pode ser transmitido pela rede do Google sem a necessidade de enviar tráfego pela Internet pública. 
Entenda o balanceamento de carga. O balanceamento de carga é o processo de distribuição de uma carga de trabalho 
em um grupo de servidores. Os balanceadores de carga podem rotear a carga de trabalho com base no nível da rede ou
regras em nível de aplicativo. Os balanceadores de carga do GCP podem distribuir cargas de trabalho globalmente. 
Entenda as ferramentas de desenvolvedor e gerenciamento. As ferramentas para desenvolvedores suportam fluxos de trabalho comuns em engenharia de software, incluindo o uso de controle de versão para software, criação de 
contêineres para executar aplicativos e serviços e disponibilização de contêineres para outros desenvolvedores e sistemas de orquestração, como o Kubernetes Engine. 
As ferramentas de gerenciamento, como Stackdriver, Monitoring e Logging, são projetadas para fornecer 
informações de administração de sistemas a desenvolvedores e operadores responsáveis ​​por 
garantir que os aplicativos estejam disponíveis e funcionando conforme o esperado. 
Conheça os tipos de serviços especializados oferecidos pelo Google Cloud Platform. O GCP inclui um
crescente lista de serviços especializados para análise de dados e AI e aprendizado de máquina. 
Conheça as principais diferenças entre a computação em nuvem local e pública. A 
computação no local é computação, armazenamento, rede e serviços relacionados que ocorrem na infraestrutura gerenciada por uma empresa ou organização para seu próprio uso. O hardware pode estar localizado literalmente nas instalações de um prédio da empresa ou em uma instalação de colocation de terceiros. As 
instalações de colocation fornecem energia, refrigeração e segurança física, mas os clientes das 
instalações de colocation são responsáveis ​​por toda a configuração e gerenciamento da infraestrutura. 
Fundamentos do exame 33 
A computação em nuvem pública usa a infraestrutura e os serviços fornecidos por um provedor de nuvem, como
como Google, AWS ou Microsoft. O provedor de nuvem mantém todo o hardware e 
instalações físicas . Ele fornece uma combinação de serviços, como VMs que são configuradas e mantidas por 
clientes e ofertas sem servidor que permitem aos clientes se concentrarem no desenvolvimento de aplicativos, enquanto o provedor de nuvem assume mais responsabilidade pela manutenção da 
infraestrutura de computação subjacente . 
34 Capítulo 2 ■ Google Cloud Computing Serviços 
Antes de aprofundar em computação, armazenamento e serviços de rede, é preciso discutir como Cloud Platform Google (GCP) 
organiza os recursos e vincula o uso desses recursos a um 
sistema de faturamento. Este capítulo apresenta a hierarquia organizacional do GCP, que consiste
de organizações, pastas e projetos. Ele também discute as contas de serviço, que são maneiras 
de atribuir funções para computar recursos, de modo que possam executar funções em seu nome. 
Finalmente, o capítulo discute brevemente o faturamento. 
Como o GCP organiza projetos 
e contas 
Quando você usa o GCP, provavelmente inicia máquinas virtuais ou clusters, talvez crie intervalos para objetos de armazenamento e faça uso de serviços de computação sem servidor, como o App Engine 
e o Cloud Functions. A lista de recursos que você usa pode crescer rapidamente. Eles também podem mudar de 
formas dinâmicas e imprevisíveis, à medida que os serviços de escalonamento automático respondem à carga de trabalho. 
Se você executar um único aplicativo ou alguns serviços para o seu departamento, talvez seja possível
para rastrear todos os recursos visualizando listas de recursos em uso. À medida que o escopo do seu uso de GCP 
aumenta, você provavelmente terá vários departamentos, cada um com seus próprios administradores que 
precisam de privilégios diferentes. O GCP fornece uma maneira de agrupar recursos e gerenciá-los como uma 
única unidade. Isso é chamado de hierarquia de recursos. O acesso a recursos na 
hierarquia de recursos é controlado por um conjunto de políticas que você pode definir. 
Hierarquia de Recursos do GCP 
A abstração central para o gerenciamento de recursos do GCP é a hierarquia de recursos. Consiste em 
três níveis: 
■ Organização 
■ Pasta 
■ Projeto 
Vamos descrever como esses três componentes se relacionam entre si.
Como a GCP organiza projetos e contas 41 
Organização 
Uma organização é a raiz da hierarquia de recursos e normalmente corresponde a uma 
empresa ou organização. Domínios do G-suite e um mapa de contas do Cloud Identity para 
organizações do GCP . O G Suite é o pacote de produtividade de escritório do Google, que inclui o Gmail, o Documentos, o 
Drive, o Google Agenda e outros serviços. Se sua empresa usa o G Suite, você pode criar uma 
organização na hierarquia do GCP. Se sua empresa não usa o G Suite, você pode usar o 
Cloud Identity, a oferta de identidade como serviço (IDaaS) do Google (Figura 3.1). 
Figura 3.1 Você pode criar contas do Cloud Identity e gerenciar usuários do G Suite no 
formulário Identidade e Organização.
Uma única identidade na nuvem está associada a no máximo uma organização. As identidades da nuvem 
têm superadministradores e esses superadministradores atribuem a função de 
Gerenciamento de identidade e acesso (IAM) do administrador da organização aos usuários que gerenciam a organização. Além 
disso, o GCP concede automaticamente 
funções do Criador do Criador e do Criador de Contas de Faturamento ao IAM a todos os usuários no domínio. Isso permite que qualquer usuário crie projetos e ative o faturamento 
para o custo dos recursos usados. 
42 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
Os usuários com a função IAM do administrador da organização são responsáveis ​​pelo 
seguinte: 
■ Definir a estrutura da hierarquia de recursos
■ Definição de políticas de gerenciamento de acesso à identidade na hierarquia de recursos 
■ Delegação de outras funções de gerenciamento a outros usuários 
Quando um membro de uma organização do G Suite / conta do Cloud Identity cria uma 
conta ou projeto de faturamento , o GCP cria automaticamente um recurso da organização. Todos os projetos 
e contas de faturamento serão filhos do recurso da organização. Além disso, quando a 
organização é criada, todos os usuários dessa organização recebem as 
funções de Criador do Projeto e Criador da Conta de Faturamento. A partir desse momento, os usuários do G Suite terão acesso aos 
recursos do GCP . 
Pasta
Pastas são os blocos de construção de hierarquias organizacionais multicamadas. Organizações contêm pastas. As pastas podem conter outras pastas ou projetos. Uma única pasta pode conter 
pastas e projetos (veja a Figura 3.2). A organização de pastas geralmente é construída com base nos tipos 
de serviços fornecidos pelos recursos nos projetos contidos e nas políticas que controlam pastas e projetos. 
Figura 3.2 Projeto de pasta de organização genérica Pasta 
Organização 
Pasta de 
Projeto 
Pasta 
Projeto de Projeto 
Considere um exemplo de hierarquia de recursos. Uma organização possui quatro departamentos: finanças, 
marketing, desenvolvimento de software e jurídico. O departamento financeiro deve manter sua
Contas a receber e contas a pagar recursos separados, para que o administrador crie 
duas pastas dentro da pasta Finanças: Contas a Receber e Contas a Pagar. O 
desenvolvimento de software usa vários ambientes, incluindo Dev, teste, preparo e produção. 
O acesso a cada um dos ambientes é controlado por políticas específicas para esse ambiente, por 
isso faz sentido organizar cada ambiente em sua própria pasta. Marketing e jurídico podem 
ter todos os seus recursos compartilhados entre os membros do departamento, portanto, uma única pasta é 
suficiente para ambos os departamentos. A Figura 3.3 mostra a hierarquia da organização para 
essa organização. 
Como o GCP organiza projetos e contas 43
Figura 3.3 Exemplo de projeto de pasta organizacional 
Dev Test 
Organização 
Finanças Desenvolvimento de Software 
Contas a 
Pagar 
Contas a 
Receber 
Staging Prod 
Marketing & Legal 
Agora que temos uma organização definida e configuramos pastas que correspondem aos 
nossos departamentos e como diferentes grupos de recursos serão acessados, pode criar 
projetos Os 
projetos são, de certa forma, a parte mais importante da hierarquia. É em projetos que 
criamos recursos, usamos serviços GCP, gerenciamos permissões e gerenciamos opções de faturamento. 
O primeiro passo para trabalhar com um projeto é criar um. Qualquer pessoa com o gerenciador de recursos
.projects.create A permissão do IAM pode criar um projeto. Por padrão, quando uma organização é 
criada, todos os usuários no domínio recebem essa permissão. 
Sua organização terá uma cota de projetos que pode criar. A cota pode variar 
entre organizações. O Google toma decisões sobre cotas de projetos com base no uso típico, 
no histórico de uso do cliente e em outros fatores. Se você atingir seu limite de projetos e tentar 
criar outro, será solicitado que você solicite um aumento na cota. Você terá que 
fornecer informações como o número de projetos adicionais que você precisa e para que eles serão 
usados. 
Depois de criar sua hierarquia de recursos, você pode definir políticas que a governam. 
Políticas da Organização
O GCP fornece um Serviço de Política da Organização. Este serviço controla o acesso aos recursos de uma organização. O Serviço de Política da Organização complementa o serviço IAM. O 
IAM permite atribuir permissões para que usuários ou funções possam realizar operações específicas na 
nuvem. O serviço Política de Organização permite especificar limites para os recursos maneiras pode ser 
44 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
usado. Uma maneira de pensar na diferença é que o IAM especifica quem pode fazer as coisas e o 
Serviço de Política da Organização especifica o que pode ser feito com recursos. 
As políticas da organização são definidas em termos de restrições em um recurso. 
Restrições de Recursos
Restrições são restrições nos serviços. O GCP tem restrições de lista e restrições booleanas. 
Restrições de lista são listas de valores permitidos ou não permitidos para um recurso. A seguir estão alguns tipos de restrições de lista: 
■ Permitir um conjunto específico de valores 
■ Negar um conjunto específico de valores 
■ Negar um valor e todos os seus valores filhos 
■ Permitir todos os valores permitidos 
■ Negar todos os valores 
Booleano restringe a avaliação como verdadeiro ou falso e determina se a restrição é 
aplicada ou não. Por exemplo, se você quiser negar acesso a portas seriais em VMs, poderá definir 
restrições / compute.disableSerialPortAccess como TRUE. 
Avaliação de Políticas
As organizações podem ter políticas permanentes para proteger dados e recursos na nuvem. Por 
exemplo, pode haver regras que determinam quem na organização pode habilitar uma API de serviço ou 
criar uma conta de serviço. Seu departamento InfoSec pode exigir que todas as VMs desativem o 
acesso à porta serial . Você pode implementar controles em cada VM individual, mas isso é ineficiente 
e propenso a erros. Uma abordagem melhor é definir uma política que restrinja o que pode ser feito 
e anexar essa política a um objeto na hierarquia de recursos. 
Por exemplo, como o InfoSec deseja que todas as VMs desativem o acesso à porta serial, você pode especificar 
uma política que restrinja o acesso à porta serial e, em seguida, conecte-a à organização. Todas as pastas
e projetos abaixo da organização herdarão essa política. Como as políticas são herdadas e 
não podem ser desabilitadas ou substituídas por objetos inferiores na hierarquia, essa é uma maneira eficaz 
de aplicar uma política a todos os recursos organizacionais. 
As políticas são gerenciadas por meio do formulário Políticas da organização no formulário IAM e admin. 
A Figura 3.4 mostra um conjunto de políticas de exemplo. 
Várias políticas podem estar em vigor para uma pasta ou projeto. Por exemplo, se a organização tivesse uma política de acesso à porta serial e uma pasta contendo um projeto tivesse uma diretiva limitando quem pode criar contas de serviço, o projeto herdaria ambas as políticas e ambas 
restringiriam o que poderia ser feito com recursos nesse projeto. 
Como o GCP organiza projetos e contas 45
Figura 3.4 As políticas organizacionais são gerenciadas no console do IAM e admin. 
Gerenciando projetos 
Uma das primeiras tarefas que você executará ao iniciar uma nova iniciativa de nuvem é configurar um projeto. 
Isso pode ser feito com o Google Cloud Console. Supondo que você criou uma conta no 
GCP, navegue até o Google Cloud Console em https://console.cloud.google.com e faça login 
. Você verá a página inicial, que é semelhante à Figura 3.5. 

46 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
No menu Navegação, no canto superior esquerdo, selecione IAM e admin e, em seguida, selecione 
Funções e identidades 47 
Observe que, quando você cria um projeto, sua cota restante de projetos é exibida. Se vocês
Se você precisar de projetos adicionais, clique no link Gerenciar cotas para solicitar um aumento na sua cota. 
Funções e Identidades 
Além de gerenciar recursos, como engenheiro de nuvem, você terá que gerenciar o acesso a 
esses recursos. Isso é feito com o uso de papéis e identidades. 
Funções no GCP 
Uma função é uma coleção de permissões. As funções são concedidas aos usuários ao vincular um usuário a uma função. 
Quando falamos de identidades, queremos dizer o registro usamos para representar um usuário humano ou serviço 
48 Capítulo 3 ■ Projetos, Contas de Serviço, e Billing 
conta no GCP. Por exemplo, Alice é engenheira de software que desenvolve aplicativos na nuvem 
(o usuário humano) e tem uma identidade com um nome como alice@example.com. Papéis são
atribuído a alice@example.com no GCP para que Alice possa criar, modificar, excluir e usar 
recursos no GCP. 
Existem três tipos de funções no Google Cloud Platform: 
■ Funções primitivas 
■ Funções predefinidas ■ Funções 
personalizadas As funções 
primitivas incluem Proprietário, Editor e Visualizador. Esses são privilégios básicos que podem ser 
aplicados à maioria dos recursos. É uma prática recomendada usar funções predefinidas em vez de 
funções primitivas quando possível. Os papéis primitivos concedem amplos intervalos de permissões que nem sempre podem 
ser necessários por um usuário. Usando funções predefinidas, você pode conceder apenas as permissões que um usuário 
precisa para executar sua função. Esta prática de somente atribuir permissões necessárias
e não mais é conhecido como o princípio do menor privilégio. É uma das melhores 
práticas fundamentais em segurança da informação. 
As funções predefinidas fornecem acesso granular aos recursos no GCP e são específicas dos 
produtos do GCP. (Veja a Figura 3.10.) Por exemplo, as funções do Google App Engine incluem: 
■ appengine.appAdmin, que concede às identidades a capacidade de ler, gravar e modificar todas as 
configurações do aplicativo 
■ appengine.ServiceAdmin, que concede acesso somente leitura às configurações do aplicativo e 
acesso em nível de gravação às configurações no nível do módulo e no nível da versão 
■ appengine.appViewer, que concede acesso somente leitura aos aplicativos. 
Figura 3.10 Uma amostra de lista de funções em 
Papéis e Identidades do GCP 49
Funções personalizadas permitem que administradores de nuvem criem e administrem suas próprias funções. 
As funções personalizadas são montadas usando permissões definidas no IAM. Embora você possa usar a maioria das 
permissões em uma função personalizada, algumas, como iam.ServiceAccounts.getAccessToken, 
não estão disponíveis em funções personalizadas. 
Concedendo funções a identidades 
Depois de determinar quais funções você deseja fornecer aos usuários, atribua funções 
aos usuários por meio do console do IAM. É importante saber que as permissões não podem ser 
atribuídas aos usuários. Eles podem ser atribuídos apenas a funções. As funções são então atribuídas aos usuários. 
No console do IAM, você pode selecionar um projeto que exibirá uma interface de permissão, permissões do 
F igure 3.11 IAM
A partir daí, selecione a opção Adicionar para exibir outro diálogo que solicite nomes de usuários 
e funções (veja a Figura 3.12). 
Figura 3.12 Adicionando um usuário 
Capítulo 3 ■ Projetos, contas de serviço e 
contas do serviço de faturamento As 
identidades geralmente são associadas a usuários individuais. Às vezes, é útil ter aplicativos ou VMs agindo em nome de um usuário ou executar operações que o usuário não tem 
permissão para executar. 
Por exemplo, você pode ter um aplicativo que precisa acessar um banco de dados, mas 
não deseja permitir que os usuários do aplicativo acessem o banco de dados diretamente. Em vez disso, todo usuário
solicitações para o banco de dados devem passar pelo aplicativo. Uma conta de serviço pode ser criada com acesso ao banco de dados. Essa conta de serviço pode ser atribuída ao aplicativo 
para que o aplicativo possa executar consultas em nome dos usuários sem precisar conceder 
acesso ao banco de dados a esses usuários. 
As contas de serviço são um tanto incomuns, pois às vezes as tratamos como recursos 
e, às vezes, como identidades. Quando atribuímos uma função a uma conta de serviço, estamos tratando-a como 
uma identidade. Quando damos aos usuários permissão para acessar uma conta de serviço, estamos tratando-a como 
um recurso. 
Existem dois tipos de contas de serviço, contas de serviço gerenciadas pelos usuários e contas de serviço do Google gerenciadas. Os usuários podem criar até 100 contas de serviço por projeto. Quando
você cria um projeto com a API do Compute Engine ativada, uma 
conta de serviço do Compute Engine é criada automaticamente. Da mesma forma, se você tiver um aplicativo do App Engine em seu 
projeto, o GCP criará automaticamente uma conta de serviço do App Engine. As 
contas de serviço do Compute Engine e do Google App Engine recebem funções de editor nos projetos em que 
são criadas. Você também pode criar contas de serviço personalizadas em seus projetos. 
O Google também pode criar contas de serviço que ele gerencia. Essas contas são usadas com 
vários serviços do GCP. 
As contas de serviço podem ser gerenciadas como um grupo de contas no nível do projeto ou no 
nível da conta de serviço individual. Por exemplo, se você conceder iam.serviceAccountUser
para um usuário para um projeto específico, esse usuário pode gerenciar todas as contas de serviço no 
projeto. Se você preferir limitar os usuários a gerenciar somente contas de serviço específicas, você poderá 
conceder iam.serviceAccountUser para uma conta de serviço específica. 
Contas de serviço são criadas automaticamente quando os recursos são criados. Por exemplo, uma 
conta de serviço será criada para uma VM quando a VM for criada. Pode haver situações 
em que você gostaria de criar uma conta de serviço para um dos seus aplicativos. Nesse 
caso, você pode navegar para o IAM e o Admin Console e selecionar Contas de serviço. A partir 
daí, você pode clicar em Criar Conta de Serviço no topo, como mostra a Figura 3.13. 
Faturamento 51
Figura 3.13 Listagem de contas de serviço no console do IAM e admin 
Isso abre um formulário que solicita as informações necessárias para criar uma 
conta de serviço . 
Faturamento O 
uso de recursos como VMs, armazenamento de objetos e serviços especializados geralmente envolve 
cobranças. A API de faturamento do GCP fornece uma maneira de gerenciar como você paga pelos 
recursos usados. 
Contas de 
faturamento As contas de cobrança armazenam informações sobre como pagar taxas pelos recursos usados. Uma 
conta de faturamento está associada a um ou mais projetos. Todos os projetos devem ter uma conta de faturamento, a 
menos que usem apenas serviços gratuitos. 
As contas de faturamento podem seguir uma estrutura semelhante à hierarquia de recursos. Se você é
Ao trabalhar com uma pequena empresa, você pode ter apenas uma única conta de faturamento. Nesse caso, todos os 
custos de recursos são cobrados para essa conta. Se a sua empresa é semelhante ao exemplo 
do início do capítulo, com 
departamentos de finanças, marketing, jurídico e de desenvolvimento de software , convém ter várias contas de faturamento. Você pode ter uma 
conta de faturamento para cada departamento, mas isso pode não ser necessário. Se finanças, marketing 
e jurídico pagarem por seus serviços na nuvem da mesma parte do orçamento de sua empresa, 
eles poderão usar uma única conta de faturamento. Se os serviços de desenvolvimento de software forem pagos a partir de uma 
parte diferente do orçamento da sua empresa, ele poderá usar uma conta de faturamento diferente.
No Google Cloud Console principal, você pode navegar até o console de faturamento (veja a 
Figura 3.14), que lista as contas de faturamento existentes. 
52 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
F igura 3.14 Formulário de cobrança principal listando contas de faturamento existentes 
A partir daqui, você pode criar uma nova conta de faturamento, como mostra a Figura 3.15. 
F igura 3.15 O formulário para criar uma nova conta de faturamento 
Na página Visão geral de faturamento, você pode visualizar e modificar projetos vinculados a 
contas de faturamento . 
Existem dois tipos de contas de faturamento: autoatendimento e faturamento. As contas de autoatendimento são 
pagas com cartão de crédito ou débito direto em uma conta bancária. Os custos são cobrados automaticamente.
O outro tipo é uma conta de cobrança faturada, na qual contas ou faturas são enviadas aos clientes. 
Esse tipo de conta é comumente usado por empresas e outros grandes clientes. 
Diversas funções estão associadas ao faturamento. É importante conhecê-los para o exame. As 
funções de faturamento são as seguintes: 
■ Criador da conta de faturamento, que pode criar novas contas de faturamento de autoatendimento 
■ Administrador da conta de faturamento, que gerencia contas de faturamento mas não pode criá-las 
■ Usuário da conta de faturamento, que permite que um usuário vincule projetos a contas de faturamento 
■ Visualizador de contas de faturamento, que permite ao usuário visualizar o custo e as transações da conta de faturamento. 
Poucos usuários provavelmente terão o Criador de contas de cobrança, e aqueles que tiverem provavelmente terão um
papel financeiro na organização. Os administradores da nuvem podem ter o Administrador da conta de faturamento 
para gerenciar as contas. Qualquer usuário que possa criar um projeto deve ter o 
Usuário da conta de faturamento para que novos projetos possam ser vinculados à conta de faturamento apropriada. Conta de faturamento 
Faturamento 53 
Viewer é útil para alguns, como um auditor que precisa ser capaz de ler conta de cobrança 
de informações, mas não alterá-la. 
Orçamentos e alertas de 
faturamento O serviço de faturamento do GCP inclui uma opção para definir um orçamento e definir alertas de faturamento. 
Você pode navegar até o formulário de orçamento no menu principal do console, selecionando Faturamento e, em 
seguida, Orçamentos e alertas (veja a Figura 3.16).
Figura 3.16 O formulário de orçamento permite que você receba avisos quando determinadas 
porcentagens de seu orçamento foram gastas em um determinado mês. 
54 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
No formulário de orçamento, você pode nomear seu orçamento e especificar uma conta de faturamento para monitorar. 
Observe que um orçamento está associado a uma conta de faturamento, não a um projeto. Um ou mais projetos 
podem ser vinculados a uma conta de faturamento, portanto, o orçamento e os alertas especificados devem ser baseados no 
que você espera gastar em todos os projetos vinculados à conta de faturamento. 
Você pode especificar um valor específico ou especificar que seu orçamento é o valor gasto no 
mês anterior.
Com um orçamento, você pode definir três porcentagens de alerta. Por padrão, três porcentagens são definidas: 
50%, 90% e 100%. Você pode alterá-los para porcentagens que funcionam 
melhor para você. Se você quiser mais de três alertas, clique em Adicionar item na seção Definir 
alertas do orçamento para adicionar limites de alerta adicionais. 
Quando esse percentual de um orçamento for gasto, ele notificará os administradores de 
faturamento e os usuários da conta de faturamento por e-mail. Se você quiser responder a alertas programaticamente, 
poderá enviar notificações para um tópico de Pub / Sub marcando a caixa apropriada nas 
seções Gerenciar Notificação. 
Exportando dados de faturamento
Você pode exportar dados de faturamento para análise posterior ou por motivos de conformidade. Os dados de faturamento podem ser 
exportados para um banco de dados do BigQuery ou para um arquivo do Cloud Storage. 
Para exportar dados de cobrança para o BigQuery, navegue até a seção Faturamento do console e 
selecione Exportação de faturamento no menu. No formulário exibido, selecione a conta de faturamento que você 
deseja exportar e escolha BigQuery Export ou File Export (consulte a Figura 3.17). 
F igura 3.17 Faturamento para formulário de exportação 
Faturamento 55 
Para o BigQuery, clique em Editar configuração. Selecione os projetos que você deseja incluir. Você precisará 
criar um conjunto de dados do BigQuery para conter os dados. Clique em Ir para o BigQuery para abrir um BigQuery
Formato. Isso criará um conjunto de dados de exportação de faturamento, que será usado para armazenar os dados exportados. 
(Consulte a Figura 3.18.) Para obter informações adicionais sobre como usar o BigQuery, consulte o Capítulo 12. 
F igura 3.18 Exportando para o BigQuery 
Como alternativa, você pode exportar dados de faturamento para um arquivo armazenado no Cloud Storage. No 
formulário Exportação de Faturamento, selecione a guia Exportar Arquivo para exibir um formulário conforme mostrado na Figura 3.19. 
F IGURA 3.19 dados de faturamento exportar para um arquivo 
56 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
Ao exportar para um arquivo, você precisará especificar um nome de balde e um prefixo relatório. Você tem a opção de escolher o formato de arquivo CSV ou JSON. Pode haver 
dúvidas sobre as opções de formato de arquivo disponíveis. Lembre-se dessas duas opções.
Ativando APIs O 
GCP usa APIs para tornar os serviços acessíveis por meio de programação. Por exemplo, quando você usa um 
formulário para criar uma VM ou um intervalo do Cloud Storage, nos bastidores, as funções da API são executadas para criar a VM ou o intervalo. Todos os serviços do GCP têm APIs associadas a eles. A maioria, 
no entanto, não está habilitada por padrão em um projeto. 
Para habilitar as APIs de serviço, você pode selecionar APIs e Serviços no menu principal do console. 
Isso exibirá um painel, conforme mostrado na Figura 3.20. 
Figura 3.20 Um exemplo de painel de serviços API 
Se você clicar no link Ativar APIs e Serviços, verá uma lista de serviços que você pode 
ativar, conforme mostrado na Figura 3.21. 
Ativando APIs 57 
F igure 3.21 Serviços que podem ter suas APIs ativadas
Este formulário é uma forma conveniente de ativar as APIs que você sabe que precisará. Se você tentar uma 
operação que requeira uma API que não esteja habilitada, poderá ser solicitado que você decida se 
deseja habilitar a API. 
Além disso, observe na Figura 3.20 a lista de APIs e seu status. As APIs ativadas terão uma 
opção Desativar. Você pode clicar para desativar a API. Você também pode clicar no nome de uma API 
na lista para detalhar detalhes sobre o uso da API, como mostra a Figura 3.22. 
58 Capítulo 3 ■ Projetos, contas de serviço e faturamento 
F igura 3.22 Detalhes sobre o uso da API 
Provisionamento de espaços de trabalho do Stackdriver 
Quando você está configurando organizações e projetos, você gasta tempo nas tarefas
descrito neste capítulo, como criar identidades, atribuir funções e configurar 
contas de cobrança . Outra coisa que você deve fazer é criar um Stackdriver Workspaces. (Essas eram 
chamadas anteriormente de contas do Stackdriver, portanto, você pode ver esse termo algumas vezes.) O 
Stackdriver é um conjunto de serviços para monitorar, registrar, rastrear e depurar 
aplicativos e recursos (veja a Figura 3.23). Para monitorar e registrar dados a serem salvos 
no Stackdriver, você precisa criar um espaço de trabalho para salvá-lo. Você pode fazer isso selecionando 
Stackdriver no menu principal do console. 
Provisioning Stackdriver Workspaces 59 
F igure 3.23 O painel principal do Stackdriver
Na parte superior do painel, o nome do projeto atual é exibido. Clique no ícone suspenso ao lado do nome do projeto para exibir uma lista de opções administrativas. Um 
deles é o Create Workspace (Veja a Figura 3.24). 
F igura 3.24 Funções administrativas para o gerenciamento de espaços de trabalho do Stackdriver 
Se você clicar em Criar Área de Trabalho, verá um formulário como este na Figura 3.25. Selecione um projeto na lista que aparece quando você clica na caixa do projeto do Google Cloud Platform e 
, em seguida, clique em Criar espaço de trabalho. Isso criará um espaço de trabalho e o associará ao projeto. 
Agora você poderá usar o monitoramento, o registro em log e outros serviços do Stackdriver com seu 
projeto. 
60 Capítulo 3 ■ Projetos, contas de serviço e faturamento
Você pode encontrar mais detalhes sobre o Stackdriver no Capítulo 18. 
F igure 3.25 Caixa de diálogo Criar espaço de trabalho 
Fundamentos do exame 
Entenda a hierarquia de recursos do GCP. Todos os recursos são organizados em sua 
hierarquia de recursos . Você pode definir a hierarquia de recursos usando uma organização e várias pastas e projetos. As pastas são úteis para agrupar departamentos e outros grupos gerenciam 
seus projetos separadamente. Os projetos contêm recursos, como VMs e repositórios de armazenamento em nuvem. 
Os projetos devem ter contas de faturamento associadas a eles para usar mais que serviços gratuitos. 
Entenda as políticas da organização. As políticas da organização restringem recursos na 
hierarquia de recursos . Políticas incluem restrições, que são regras que definem o que pode ou não ser
feito com um recurso. Por exemplo, uma restrição pode ser definida para bloquear o acesso à porta serial 
em todas as VMs em um projeto. Além disso, entenda o processo de avaliação de políticas e como substituir as políticas herdadas. 
Entenda as contas de serviço e como elas são usadas. Contas de serviço são identidades que 
não estão associadas a um usuário específico, mas podem ser atribuídas a um recurso, como uma VM. Recursos 
que são atribuídos a uma conta de serviço podem executar operações que a conta de serviço tem permissão para executar. Entenda as contas de serviço e como criá-las. 
Entenda o Faturamento do GCP. O faturamento do GCP deve estar ativado para usar serviços e recursos 
além dos serviços gratuitos. O faturamento associa um método de faturamento, como um cartão de crédito ou faturamento
informação, com um projeto. Todos os custos associados aos recursos em um projeto são faturados para a 
conta de faturamento do projeto. Uma conta de faturamento pode ser associada a mais de um projeto. 
Você gerencia seu faturamento por meio da API de faturamento. 
Saiba como ativar APIs e criar espaços de trabalho do Stackdriver. Um formulário conveniente permite 
ativar as APIs que você sabe que precisa. Você também pode mostrar uma lista de APIs e seu status. 
O Stackdriver é um conjunto de serviços para monitorar, registrar, rastrear e depurar aplicativos e recursos. Para monitorar e registrar dados para salvar no Stackdriver, você precisa criar um 
espaço de trabalho. 
Neste capítulo, você aprenderá sobre cada uma das 
opções de computação disponíveis no Google Cloud Platform (GCP) e quando
para usá-los. Também discutiremos máquinas virtuais preemptivas 
e quando elas podem ajudar a reduzir seus custos gerais de computação. 
O Compute Engine 
Compute Engine é um serviço que fornece VMs executadas no GCP. Geralmente, nos referimos a uma 
VM em execução como uma instância. Quando você usa o Compute Engine, cria e gerencia uma ou mais 
instâncias. 
Instâncias de 
Imagens de Máquina Virtual executam imagens, que contêm sistemas operacionais, bibliotecas e outros códigos. Você pode 
optar por exibir uma imagem pública fornecida pelo Google (Figura 4.1). Ambas as 
imagens do Linux e do Windows estão disponíveis. Além das imagens mantidas pelo Google, há outras 
imagens públicas fornecidas por projetos de código aberto ou fornecedores terceirizados.
Fig ure 4.1 Um subconjunto de imagens do sistema operacional disponíveis no Compute Engine 
Compute Engine 69 
As imagens públicas incluem uma variedade de sistemas operacionais, como o CentOS, Container 
Optimized OS do Google, Debian, Red Hat Enterprise Linux, SUSE Enterprise Linux 
Server, Ubuntu, e o Windows Server. 
Se não houver imagem pública que atenda às suas necessidades, você poderá criar uma imagem personalizada a 
partir de um disco de inicialização ou iniciando com outra imagem. Para criar uma VM no console, 
navegue até o Compute Engine e instâncias de VM. Você verá uma tela semelhante à da 
Figura 4.2. 
Fig ure 4.2 Criando uma VM no Compute Engine 
A partir daí, clique em Criar Instância para criar uma VM. Escolha uma imagem próxima de
o que você precisa e criar a VM. Em seguida, faça as alterações necessárias na imagem, como a 
instalação de bibliotecas ou outros pacotes de software. Depois de criar a VM e fazer 
as alterações 
desejadas , navegue até o menu do Google Compute Engine no Google Cloud Console e selecione Instantâneos, como mostra a Figura 4.3. 
Fig ura 4.3 O primeiro passo para criar um instantâneo 
Clique em Create Snapshot. No formulário exibido, você pode especificar um nome para o 
instantâneo, uma descrição e, o mais importante, o disco que é a fonte do instantâneo. Na Figura 4.4, o disco de inicialização de uma VM chamada myvm está selecionado. Depois de selecionar 
70 Capítulo 4 ■ Introdução à computação no Google Cloud
opções, clique no botão Criar para salvar o instantâneo, que pode ser usado como 
imagem para outras VMs. 
Fig ure 4.4 Criando uma captura instantânea no Compute Engine 
Imagens personalizadas são especialmente úteis se você precisar configurar um sistema operacional e 
instalar software adicional em cada instância de uma VM executada. Em vez de 
configurar e instalar repetidamente o software para cada instância, você poderia configurar e instalar uma vez 
e depois criar uma imagem personalizada a partir do disco de inicialização da instância. Em seguida, você especifica essa 
imagem personalizada ao iniciar outras instâncias, que terão a configuração e o software disponíveis sem etapas adicionais. 
Pode haver casos em que você tenha uma imagem personalizada em seu ambiente ou dados locais
Centro. Você pode importar uma imagem desse tipo usando a ferramenta de importação de disco virtual fornecida pelo 
Google. Este utilitário faz parte da ferramenta de linha de comando gcloud, que será descrita em 
mais detalhes no próximo capítulo. 
Compute Engine 71 
Imagens personalizadas devem ser compatíveis com o GCP. No momento da escrita, os seguintes 
sistemas operacionais base estão disponíveis para criar imagens personalizadas que serão executadas no Compute Engine: 
■ Sistemas operacionais Linux 
■ CentOS 6 
■ CentOS 7 
■ Debian 8 
■ Debian 9 
■ Red Hat Enterprise Linux 6 
■ Red Hat Enterprise Linux 7 
■ Ubuntu 14.04 LTS 
■ Ubuntu 15.04 LTS 
■ Sistemas operacionais 
Windows ■ Windows Server 2008 R2
■ Windows Server 2012 R2 
■ Núcleo do Windows Server 2012 R2 
■ Windows Server 2016 
■ As 
máquinas virtuais principais do Windows Server 2016 estão contidas em projetos 
Ao criar uma instância, você especifica um projeto para conter a instância. Como você deve se lembrar, os 
projetos fazem parte da hierarquia de recursos do GCP. Projetos são a estrutura de nível mais baixo na 
hierarquia. Os projetos permitem que você gerencie recursos relacionados com políticas comuns. 
Ao abrir o Google Cloud Console, você verá na parte superior do formulário o 
nome de um projeto ou a frase Selecionar um projeto, conforme mostrado na Figura 4.5. 
Fig ure 4.5 O nome do projeto atual ou a opção para selecionar um é exibido no 
Google Cloud Console.
72 Capítulo 4 ■ Introdução à computação no Google Cloud 
Quando você escolhe Selecionar um projeto, um formulário como esse na Figura 4.6 é exibido. A partir daí, 
você pode selecionar o projeto que deseja armazenar seus recursos, incluindo VMs. 
Fig ure 4.6 Escolhendo um projeto de projetos existentes em uma conta 
As máquinas virtuais são executadas em uma região e região 
Além de ter um projeto, as instâncias de VMs têm uma zona atribuída. As zonas são 
recursos similares ao data center, mas podem ser constituídas por um ou mais datacenters acoplados. Eles 
estão localizados dentro das regiões. Uma região é uma localização geográfica, como asia-east1, europewest2 e us-east4. As zonas dentro de uma região são vinculadas por 
conexões de rede de baixa latência e alta largura de banda .
Você especifica uma região e uma zona ao criar uma VM. Como você pode ver na Figura 4.7, o 
formulário Criar VM inclui listas suspensas das quais você pode selecionar a região e a zona. 
Fig ure 4.7 Seleção de uma região e zona no formulário Criar VM 
Compute Engine 73 
Você pode querer considerar vários fatores ao escolher onde executar o seu VM, 
incluindo o seguinte: 
Custo ■, que pode variar entre as regiões. 
■ Regulamentação de localidade de dados, como a manutenção de dados sobre cidadãos da 
União Europeia na União Europeia. 
■ Alta disponibilidade. Se você estiver executando várias instâncias, poderá desejá-las em 
zonas diferentes e possivelmente em regiões diferentes. Se uma das zonas ou regiões ficar inacessível,
as instâncias em outras zonas e regiões ainda podem fornecer serviços. 
■ Latência, que é importante se você tiver usuários em diferentes partes do mundo. Manter as 
instâncias e os dados geograficamente próximos dos usuários do aplicativo pode ajudar a reduzir a latência. 
■ Necessidade de plataformas de hardware específicas, que podem variar por região. Por exemplo, no 
momento em que escrevo, a europe-west1 tem o Intel Xeon E5, também conhecido como Sandy Bridge, plataformas, 
mas o Europe-west2 não. 
Os usuários precisam de privilégios para criar máquinas virtuais 
Para criar recursos do Compute Engine em um projeto, os usuários devem ser membros da equipe no 
projeto ou um recurso específico e ter as permissões apropriadas para executar tarefas específicas. 
Os usuários podem ser associados a projetos da seguinte maneira:
■ Usuários individuais 
■ Um grupo do Google 
■ Domínio do AG Suite 
■ Uma conta de serviço 
Depois que um usuário ou conjunto de usuários é adicionado a um projeto, você pode atribuir permissões concedendo 
funções ao usuário ou ao grupo de usuários. Esse processo é explicado em detalhes no Capítulo 17. As 
funções predefinidas são especialmente úteis porque agrupam as permissões que geralmente são necessárias juntas 
para que um usuário execute um conjunto de tarefas. Veja alguns exemplos de funções predefinidas: 
Usuários do Compute Engine Admin com essa função têm controle total sobre as 
instâncias do Compute Engine . 
Administrador de rede do Compute Engine Os usuários com essa função podem criar, modificar e excluir a maioria
recursos de rede e fornece acesso somente leitura a regras de firewall e certificações SSL. Esta função não dá ao usuário permissão para criar ou alterar instâncias. 
Administrador de segurança do Compute Engine Os usuários com essa função podem criar, modificar e excluir 
certificados SSL e regras de firewall. 
Compute Engine Viewer Os usuários com essa função podem obter e listar recursos do Compute Engine, 
mas não podem ler dados desses recursos. 
Quando os privilégios são concedidos aos usuários no nível do projeto, essas permissões se aplicam a 
todos os recursos em um projeto. Por exemplo, se um usuário receber a 
função de administrador do Compute Engine no nível do projeto, essa pessoa poderá administrar todas as instâncias do Compute Engine em
o projeto. A Figura 4.8 mostra uma listagem de exemplo de usuários e funções. 
74 Capítulo 4 ■ Introdução à Computação no Google Cloud 
Fig ure 4.8 Um exemplo de listagem de usuários e funções 
Uma maneira alternativa de conceder permissões é anexar diretivas do IAM diretamente a recursos. 
Dessa maneira, os privilégios podem ser personalizados para recursos específicos, em vez de para todos os recursos em um 
projeto. Por exemplo, você pode especificar que o usuário Alice tenha a função Administrador do Compute Engine 
em uma instância e Bob tenha a mesma função em outra instância. Alice e Bob poderiam 
administrar suas próprias instâncias de VM, mas não poderiam administrar outras instâncias. 
Máquinas virtuais preemptivas
Considere se você tem uma carga de trabalho que é o oposto de precisar de alta disponibilidade. As 
VMs preemptivas são instâncias de computação de curta duração adequadas para executar determinados tipos de cargas de trabalho - 
principalmente para aplicativos que executam 
operações de modelagem financeira, renderização, big data, integração contínua e rastreamento da web. Essas VMs oferecem as mesmas opções de configuração 
que as instâncias de computação regulares e persistem por até 24 horas. Se um aplicativo for tolerante a falhas 
e puder suportar possíveis interrupções de instâncias (com um aviso de 30 segundos), o uso de instâncias de VM preemptivas poderá reduzir significativamente os custos do Google Compute Engine. 
Reformatar imagens 
Um aplicativo móvel que permite aos usuários fazer upload de fotos também reformata essas imagens
uma variedade de formatos. Embora seja importante que a imagem original seja carregada rapidamente, não 
é necessário que os outros formatos sejam criados rapidamente. Se levasse 
75 
minutos para o Compute Engine , isso ainda atenderia aos requisitos do aplicativo. Esse é um bom caso de uso 
para máquinas preemptivas. 
Quando um arquivo é carregado, ele aciona uma função de nuvem (descrita em detalhes no Capítulo 10), 
que inicia o processo de reformatação em uma VM preemptiva. Quando a reformatação 
é concluída, a imagem reformatada é gravada no armazenamento. Se a máquina desligar 
durante a reformatação de uma imagem, essa imagem poderá ser reformatada novamente quando outra
VM é iniciado. Quando o aplicativo de reformatação é iniciado, ele verifica se há imagens que 
não tenham todas as versões reformatadas. Se algumas imagens estiverem faltando algumas 
opções reformatadas , ele pode começar a reformatá-las. Esse processo pode ser executado em intervalos regulares para 
verificar se alguma imagem não foi reformatada. Dessa forma, podemos usar VMs preemptivas e ainda atender aos objetivos de nível de serviço. 
Algumas tarefas de análise de big data são executadas em clusters de servidores que executam softwares como o Hadoop 
e o Spark. As plataformas são projetadas para serem resistentes a falhas. Se um nó ficar inativo no 
meio de um job, a plataforma detectará a falha e moverá a carga de trabalho para outros nós
no servidor. Você pode ter trabalhos analíticos bem atendidos por uma combinação de VMs confiáveis ​​e VMs preemptivas. Com uma porcentagem de VMs confiáveis, você sabe que 
pode processar suas tarefas dentro de suas limitações de tempo, mas se adicionar VMs de baixo custo e preemptivas, muitas vezes você pode concluir seus trabalhos mais rapidamente e com um custo geral mais baixo. 
Limitações de máquinas virtuais preemptivas 
Conforme você decide onde usar VMs preemptivas, lembre-se de suas limitações e diferenças em comparação com as instâncias de VM convencionais no GCP. VMs preemptivas têm as seguintes características: 
■ Podem ser encerradas a qualquer momento. Se eles terminarem dentro de 10 minutos após o início, você 
não será cobrado por esse período. 
■ Será terminado dentro de 24 horas.
■ Pode nem sempre estar disponível. A disponibilidade pode variar entre zonas e regiões. 
■ Não é possível migrar para uma VM comum. 
■ Não pode ser definido para reiniciar automaticamente. 
■ Não são cobertos por nenhum contrato de nível de serviço (SLA). 
76 Capítulo 4 ■ Introdução à Computação no Google Cloud 
personalizado Tipos de máquinas 
Compute Engine tem mais de 25 tipos de máquina predefinidos agrupados em tipos padrão, 
máquinas de alta de memória, máquinas de alta CPU, tipo núcleo compartilhada e otimizada de memória 
máquinas. Esses tipos de máquinas predefinidos variam no número de CPUs virtuais (vCPUs) e na 
quantidade de memória. Aqui estão alguns exemplos: 
■ n1-standard-1 tem 1 vCPU e 3.75GB de memória. 
■ n1-standard-32 possui 32 vCPUs e 120GB de memória.
■ n1-highmem-32 possui 32 vCPUs e 208GB de memória. 
N1-highcpu-32 tem 32 vCPUs e 28,8 GB de memória. 
As opções predefinidas para VMs atendem às necessidades de muitos casos de uso, mas pode haver 
momentos em que sua carga de trabalho pode ser executada de maneira mais econômica e mais rápida em uma configuração 
que ainda não esteja definida. Nesse caso, você pode querer usar um tipo de máquina personalizado. 
Para criar uma imagem personalizada, selecione a opção Criar VM no console. Clique no 
link Personalizar na seção Tipo de Máquina. Isso expande a seção Tipo de Máquina, conforme 
mostrado na Figura 4.9. A partir daí, você pode ajustar os controles deslizantes para aumentar ou diminuir o número de CPUs e a quantidade de memória necessária.
Figura 4.9 Personalização de uma VM ajustando o número de CPUs e a quantidade de memória do 
App Engine 77 
Os tipos de máquina personalizados podem ter entre 1 e 64 vCPUs e até 6,5 GB de memória 
por vCPU. O preço de uma configuração personalizada é baseado no número de vCPUs e na 
memória alocada. 
Casos de uso para máquinas virtuais do 
Compute Engine O Compute Engine é uma boa opção quando você precisa ter o máximo controle sobre instâncias de VM. 
Com o Compute Engine, você pode fazer o seguinte: 
■ Escolher a imagem específica a ser executada na instância. 
■ Instalar pacotes de software ou bibliotecas personalizadas. 
■ Tenha um controle refinado sobre quais usuários têm permissões na instância.
■ Possuir controle sobre certificados SSL e regras de firewall para a instância. 
Em relação a outros serviços de computação no GCP, o Google Compute Engine fornece 
o mínimo de gerenciamento. O Google fornece imagens públicas e um conjunto de configurações de VM 
, mas você, como administrador, deve fazer escolhas sobre qual imagem 
usar, o número de CPUs, a quantidade de memória a ser alocada, como configurar o 
armazenamento persistente e como configurar as configurações de rede . 
Em geral, quanto mais controle sobre um recurso você tiver no GCP, mais responsabilidade 
você terá para configurar e gerenciar o recurso. 
App Engine
O App Engine é um serviço de computação PaaS que fornece uma plataforma gerenciada para executar aplicativos. Quando você usa o App Engine, seu foco está no seu aplicativo e não nas VMs 
que executam o aplicativo. Em vez de configurar as VMs, você especifica alguns 
requisitos básicos de recursos junto com o código do aplicativo, e o Google gerenciará os recursos 
necessários para executar o código. Isso significa que os usuários do App Engine têm menos para gerenciar, mas 
também têm menos controle sobre os recursos de computação usados ​​para executar o aplicativo. 
Como as instâncias de VM, os aplicativos no App Engine são criados dentro de um projeto. 
Estrutura de um aplicativo do App Engine Os aplicativos do 
App Engine têm uma estrutura comum e consistem em serviços. Serviços
fornecer uma função específica, como calcular o imposto sobre vendas em um aplicativo da web de varejo ou atualizar o 
inventário, pois os produtos são vendidos em um site. Os serviços têm versões e isso permite que várias versões sejam executadas ao mesmo tempo. Cada versão de um serviço é executada em uma instância gerenciada pelo 
App Engine (consulte a Figura 4.10). 
78 Capítulo 4 ■ Introdução à Computação no Google Cloud 
Fig ure 4.10 A estrutura de um aplicativo do App Engine 
Aplicativo 
Serviço 
Versão Versão 
Instância Instância 
Versão 
Instância 
Versão 
Instância 
Serviço Serviço 
O número de instâncias usadas para fornecer um aplicativo depende de sua configuração
para a aplicação e a carga atual no aplicativo. À medida que a carga aumenta, o Google 
pode adicionar mais instâncias para atender à necessidade. Da mesma forma, se a carga 
diminuir , as instâncias poderão ser encerradas para economizar no custo de instâncias não utilizadas. Esse tipo de escalonamento automático está disponível com 
instâncias dinâmicas. 
Além das instâncias dinâmicas, o App Engine também fornece instâncias residentes. Essas 
instâncias são executadas continuamente. Você pode adicionar ou remover instâncias residentes manualmente. 
Quando o número de instâncias implementadas muda com freqüência, pode ser difícil 
estimar os custos da execução de instâncias. Felizmente, o GCP permite que os usuários configurem 
limites de gastos diários , além de criar orçamentos e definir alarmes.
Ambientes padrão e flexível do 
App Engine O App Engine oferece dois tipos de ambientes de tempo de execução: padrão e flexível . O ambiente padrão fornece tempos de execução de linguagem, enquanto o ambiente flexível é uma 
plataforma de execução de contêiner mais generalizada. 
Ambiente padrão do App Engine 
O ambiente padrão é o ambiente original do App Engine. Consiste em um tempo de execução pré-configurado e específico para cada idioma. Existem atualmente duas gerações do 
ambiente padrão . A segunda geração melhora o desempenho da primeira geração 
e tem menos limitações. 
Atualmente, os usuários do ambiente padrão do Google App Engine podem escolher entre os seguintes idiomas suportados: 
App Engine 79 
First Generation
■ Python 2.7 
■ PHP 5.5 
■ Go 1.9 
Segunda Geração 
■ Java 8 
■ Python 3.7 (beta) 
■ PHP 7.2 (beta) 
■ Node.js 8 (beta) e 10 (beta) 
■ Go 1.11 (beta) 
Com a segunda geração ambiente padrão, os desenvolvedores podem usar qualquer 
extensão de linguagem , mas na primeira geração somente um conjunto selecionado de extensões e bibliotecas na lista de permissões 
é permitido. O acesso à rede é restrito na primeira geração, mas os usuários têm 
acesso total à rede na segunda geração. 
Ambiente flexível do 
App Engine O ambiente flexível do App Engine oferece mais opções e controle aos desenvolvedores que
Gostaríamos dos benefícios de uma plataforma como serviço (PaaS), como o App Engine, mas sem as restrições de linguagem e personalização do ambiente padrão do App Engine (Figura 4.11). 
O ambiente flexível do App Engine usa contêineres como a 
abstração básica do bloco de construção . Os usuários podem personalizar seus ambientes de tempo de execução configurando um contêiner. 
O ambiente flexível usa contêineres do Docker, portanto, os desenvolvedores familiarizados com os arquivos do Docker 
podem especificar imagens do sistema operacional de base, bibliotecas e ferramentas adicionais e ferramentas personalizadas. 
Ele também possui suporte nativo para Java 8, Eclipse Jetty 9, Python 2.7 e Python 3.6, Node.js, 
Ruby, PHP, núcleo .NET e Go. 
De certa forma, o ambiente flexível do App Engine é semelhante ao Kubernetes
Engine, que será discutido na próxima seção. Ambos os produtos do Google podem 
executar contêineres Docker personalizados. O ambiente flexível do App Engine fornece uma 
PaaS totalmente gerenciada e é uma boa opção quando você pode empacotar seu aplicativo e 
serviços em um pequeno conjunto de contêineres. Esses contêineres podem então ser escalonados automaticamente de acordo com a carga. O Kubernetes Engine, como veremos a seguir, foi desenvolvido para gerenciar contêineres que estão sendo 
executados em um cluster controlado por você. Com o Kubernetes Engine, você tem controle sobre 
o cluster, mas deve monitorar e gerenciar esse cluster usando ferramentas como o Stackdriver 
Monitoring e o Autoescalonamento. Com o ambiente flexível do App Engine, a saúde de
Os servidores do App Engine são monitorados pelo Google e corrigidos conforme necessário, sem qualquer intervenção de sua parte. 
80 Capítulo 4 ■ Introdução à Computação no Google Cloud 
Fig ure 4.11 Interface para criar um cluster Kubernetes no Kubernetes Engine 
Casos de Uso para App Engine 
O produto App Engine é uma boa opção para uma plataforma de computação quando você tem pouca 
necessidade de configurar e controlar sistema operacional ou sistema de armazenamento. O Google App 
Engine gerencia VMs e contêineres subjacentes e alivia desenvolvedores e 
profissionais do DevOps 
Kubernetes Engine de algumas tarefas comuns de administração do sistema, como 
servidores de patch e monitoramento . 
 Quando usar o ambiente padrão do App Engine
 O ambiente padrão do App Engine é projetado para aplicativos escritos em um dos 
idiomas suportados. O ambiente padrão fornece um tempo de execução específico da linguagem que 
vem com suas próprias restrições. As restrições são menores no 
ambiente padrão do App Engine de segunda geração . 
 Se você estiver iniciando um novo esforço de desenvolvimento e planeja usar o 
ambiente padrão do App Engine, é melhor escolher 
instâncias de segunda geração . As instâncias de primeira geração continuarão sendo suportadas, mas 
esse tipo de instância deve ser usado apenas para aplicativos que já existem 
e foram projetados para essa plataforma. 
 Quando usar o ambiente flexível do App Engine
 O ambiente flexível do Google App Engine é adequado para aplicativos que podem ser decompostos 
em serviços e em que cada serviço pode ser contêinerizado. Por exemplo, um serviço poderia 
usar um aplicativo Django para fornecer uma interface de usuário do aplicativo, outro poderia incorporar a 
lógica de negócios para armazenamento de dados e outro serviço poderia agendar o processamento em lote de dados 
enviados por meio do aplicativo. Se você precisar instalar software adicional ou executar comandos durante a inicialização, poderá especificar aqueles no Dockerfi le. Por exemplo, você poderia adicionar 
um comando run a um Dockerfi le para executar o apt-get update para obter a versão mais recente dos 
pacotes instalados . Os arquivos do Docker são arquivos de texto com comandos para confi- gurar um contêiner, como
especificando uma imagem base para começar e especificando comandos do gerenciador de pacotes, como 
apt-get e yum, para instalar pacotes. 
 O ambiente padrão do Google App Engine diminui para nenhuma instância em execução se não 
houver carga, mas esse não é o caso do ambiente flexível. Sempre haverá pelo menos 
um contêiner funcionando com o seu serviço, e você será cobrado por esse tempo, mesmo que não 
haja carga no sistema. 
O Kubernetes Engine 
 Compute Engine permite criar e gerenciar VMs individualmente ou em grupos 
chamados de grupos de instâncias. Grupos de instâncias permitem gerenciar VMs semelhantes como uma única unidade. Isso 
é útil se você tiver um grupo de servidores que executem o mesmo software e tenham o mesmo
ciclo de vida operacional. O software moderno, no entanto, é frequentemente construído como uma coleção de serviços, 
às vezes chamados de microservices. Serviços diferentes podem exigir diferentes configurações de VMs, mas você ainda pode querer gerenciar as várias instâncias como um único recurso 
ou cluster. Você pode usar o Kubernetes Engine para isso. 
82 Capítulo 4 ■ Introdução à computação no Google Cloud O 
Kubernetes é uma ferramenta de código aberto criada pelo Google para administrar clusters de 
máquinas virtuais e bare-metal. (O Kubernetes às vezes é abreviado como K8s.) O Kubernetes é um serviço de orquestração de contêineres que ajuda você. Ele permite que você faça o seguinte: 
■ Crie clusters de VMs que executam o software de orquestração do Kubernetes para contêineres
■ Implantar aplicativos em contêiner no cluster 
■ Administrar o cluster 
■ Especificar políticas, como escalonamento automático 
■ Monitorar a integridade do cluster O 
Kubernetes Engine é o serviço de Kubernetes gerenciado pelo GCP. Se você quisesse, poderia 
implantar um conjunto de VMs, instalar o Kubernetes em suas VMs e gerenciar a plataforma Kubernetes 
. Com o Kubernetes Engine, você obtém os benefícios do Kubernetes sem a sobrecarga administrativa. 
Funcionalidade do 
Kubernetes O Kubernetes é projetado para suportar clusters que executam uma variedade de aplicativos. Isso é diferente de outras plataformas de gerenciamento de cluster que fornecem uma maneira de executar um aplicativo 
em vários servidores. O Spark, por exemplo, é uma plataforma de análise de big data que executa o Spark
serviços em um cluster de servidores. O Spark não é uma plataforma de gerenciamento de cluster de uso geral, 
como o Kubernetes. 
O Kubernetes Engine fornece as seguintes funções: 
■ Balanceamento de carga nas VMs do Compute Engine implantadas em um 
cluster Kubernetes 
■ Escalonamento automático de nós (VMs) no cluster 
■ Atualização automática do software de cluster conforme necessário 
■ Monitoramento de nó e reparos de integridade 
■ Logging 
■ Suporte para conjuntos de nós, que são conjuntos de nós, todos com a mesma configuração 
Kubernetes Cluster Architecture 
Um cluster Kubernetes inclui um nó principal de cluster e um ou mais nós de trabalhador. Estes 
são referidos como o mestre e nós, respectivamente.
O nó principal gerencia o cluster. Os serviços de cluster, como o 
servidor da API do Kubernetes , os controladores de recursos e os agendadores, são executados no mestre. O Kubernetes API Server 
é o coordenador de todas as comunicações para o cluster. O mestre determina quais contêineres e cargas de trabalho são executados em cada nó. 
Quando um cluster do Kubernetes é criado a partir do Google Cloud Console ou de uma 
linha de comando , vários nós também são criados. Estas são VMs do Compute Engine. O 
tipo de VM padrão do 
Kubernetes Engine 83 é n1-standard-1 (1 vCPU e 3.75GB de memória), mas você pode especificar um 
tipo de máquina diferente ao criar o cluster. 
 O Kubernetes implementa contêineres em grupos chamados de pods. Recipientes dentro de um único compartilhamento de conjunto
armazenamento e recursos de rede. Os contêineres de um pod compartilham um endereço IP e um espaço de porta. Um 
pod é uma unidade logicamente única para fornecer um serviço. Os contêineres são implantados e escalados como uma unidade. 
 É importante notar que alguma sobrecarga é dedicada à execução do 
software Kubernetes nos nós. Alguma quantidade de CPU e memória é 
alocada para o Kubernetes e, portanto, não está disponível para 
processamento de carga de trabalho . O Kubernetes Engine reserva recursos de memória da seguinte maneira: 
 ■ 25% dos primeiros 4 GB de memória 
 ■ 20% dos próximos 4 GB de memória, até 8 GB 
 ■ 10% dos próximos 8 GB de memória, até 16 GB 
 ■ 6% do próximo 112 GB de memória, até 128 GB 
 ■ 2% de qualquer memória acima de 128 GB
 Os recursos da CPU são reservados da seguinte forma: 
 ■ 6% do primeiro núcleo 
 ■ 1% do próximo núcleo (até dois núcleos) 
 ■ 0,5% dos próximos dois núcleos (até quatro núcleos) 
 ■ 0,25% de todos os núcleos acima de quatro núcleos 
 Kubernetes alta Disponibilidade 
 Uma maneira Kubernetes mantém a saúde cluster é desligando vagens que ficam sedentos 
por recursos. O Kubernetes suporta algo chamado políticas de despejo que definem limites para 
recursos. Quando um recurso é consumido além do limite, o Kubernetes começará a 
encerrar os pods. 
 Outra maneira pela qual o Kubernetes fornece alta confiabilidade é executando vários
vagens. Um grupo de execução de pods idênticos é chamado de implantação. Os pods idênticos são 
chamados de réplicas. 
 Quando implantações são lançadas, elas podem estar em um dos três estados. 
 ■ Progresso, o que significa que a implantação está em processo de execução de uma tarefa. 
 ■ Concluída, o que significa que a distribuição de contêineres está completa e todos os pods estão executando 
a versão mais recente dos contêineres. 
 ■ Falha, que indica que o processo de implantação encontrou um problema 
recuperar de 
 Existem considerações adicionais ao executar aplicativos com estado versus 
aplicativos sem estado . Esses problemas serão abordados no 

Capítulo 7. 
84 Capítulo 4 ■ Introdução à computação no Google Cloud
Kubernetes Engine Use Cases O 
Kubernetes Engine é uma boa opção para aplicações de grande escala que exigem alta disponibilidade e alta confiabilidade. O Kubernetes Engine suporta o conceito de pods e 
conjuntos de implantação , que permitem que desenvolvedores e administradores de aplicativos gerenciem serviços como uma unidade lógica. Isso pode ajudar se você tiver um conjunto de serviços que suporte uma interface de usuário, outro 
conjunto que implemente lógica de negócios e um terceiro conjunto que forneça serviços de back-end. Cada um 
desses diferentes grupos de serviços pode ter diferentes ciclos de vida e requisitos de escalabilidade. 
O Kubernetes ajuda a gerenciá-los em níveis de abstração que fazem sentido para usuários, desenvolvedores e profissionais de DevOps. 
Funções de nuvem
O Cloud Functions é uma plataforma de computação sem servidor projetada para executar partes 
de código de finalidade única em resposta a eventos no ambiente do GCP. Não há necessidade de provisionar ou 
gerenciar VMs, contêineres ou clusters ao usar o Cloud Functions. Código escrito em 
Node.js 6, Node.js 8 ou Python 3.7 pode ser executado em Cloud Functions. 
O Cloud Functions não é uma plataforma de computação de uso geral, como o Compute Engine 
ou o App Engine. O Cloud Functions fornece a “cola” entre serviços que são de outra forma 
independentes. 
Por exemplo, um serviço pode criar um arquivo e enviá-lo para o Cloud Storage, e outro serviço precisa coletar esses arquivos e executar algum processamento no arquivo. Ambos os serviços
pode ser desenvolvido de forma independente. Não há necessidade de saber sobre o outro. No entanto, 
você precisará de alguma maneira de detectar que um novo arquivo foi gravado no Cloud Storage e, em seguida, 
o outro aplicativo poderá começar a processá-lo. Não queremos escrever aplicativos de maneiras que 
façam suposições sobre outros processos que possam fornecer entrada ou consumir saída. Os serviços 
podem mudar independentemente uns dos outros. Não devemos ter que acompanhar as dependências 
entre serviços, se pudermos evitá-lo. O Cloud Functions nos ajuda a evitar essa situação. 
Ambiente de execução de funções de nuvem
O GCP gerencia tudo o que é necessário para executar seu código em um ambiente seguro e isolado. É claro que, abaixo da abstração sem servidor, existem servidores virtuais e físicos 
executando seu código, mas você, como engenheiro de nuvem, não precisa administrar nenhuma dessas infraestruturas. Três pontos principais a serem lembrados sobre as Funções na nuvem são as seguintes: 
■ As funções são executadas em um ambiente de execução seguro e isolado. 
■ Compute a escala de recursos conforme necessário para executar quantas instâncias do Cloud Functions, conforme 
necessário, sem precisar fazer nada para controlar o dimensionamento. 
■ A execução de uma função é independente de todas as outras. Os ciclos de vida das 
funções de nuvem não dependem uns dos outros. 
Resumo 85
Há um corolário importante para esses pontos-chave. Ou seja, as Cloud Functions podem estar 
sendo executadas em várias instâncias ao mesmo tempo. Se dois usuários do aplicativo para dispositivos móveis fizessem o upload de um arquivo de imagem 
para processamento ao mesmo tempo, duas instâncias diferentes do Cloud Functions seriam executadas mais 
ou menos ao mesmo tempo. Você não precisa fazer nada para evitar conflitos entre as 
duas instâncias; eles são independentes. 
Como cada chamada de uma Cloud Function é executada em uma instância separada, as funções não 
compartilham memória ou variáveis. Em geral, isso significa que as Cloud Functions devem ser sem estado. 
Isso significa que a função não depende do estado da memória para calcular sua saída.
Essa é uma restrição razoável em muitos casos, mas às vezes é possível otimizar o processamento 
se você puder salvar o estado entre as chamadas. O Cloud Functions oferece algumas maneiras de fazer 
isso, que serão descritas no Capítulo 11. 
Funções de 
nuvem Casos de Uso As Funções de Nuvem são adequadas para o processamento baseado em eventos e de execução curta. Se seus fluxos de trabalho fizerem 
upload, modificarem ou alterarem arquivos no Cloud Storage ou usarem filas de mensagens para enviar 
trabalho entre serviços, o serviço Cloud Functions será uma boa opção para executar o código 
que inicia a próxima etapa do processamento. Algumas áreas de aplicação que se encaixam nesse padrão incluem 
: 
■ Internet das coisas (IoT), na qual um sensor ou outro dispositivo pode enviar informações sobre
o estado de um sensor. Dependendo dos valores enviados, o Cloud Functions pode acionar um 
alerta ou iniciar o processamento de dados que foram enviados pelo sensor. 
■ As aplicações móveis que, como aplicativos da Internet das coisas, enviam dados para a nuvem para o processamento de 
fluxos de trabalho assíncronos ■ em que cada etapa começa em algum momento depois das etapas anteriores 
concluída, mas não há suposições sobre quando as etapas de processamento irá completar 
Resumo 
GCP oferece várias computing opções. As opções variam no nível de controle que você, 
como usuário do GCP, tem sobre a plataforma de computação. Geralmente, com mais controle, 
mais responsabilidade e sobrecarga de gerenciamento. Seu objetivo ao escolher um computador
a plataforma é escolher uma que atenda aos seus requisitos, minimizando a sobrecarga 
e o custo do DevOps . 
O Compute Engine é o serviço GCP que permite provisionar VMs. Você pode escolher 
entre configurações predefinidas ou criar uma configuração personalizada com a melhor 
combinação de CPUs virtuais e memória para suas necessidades. Se você puder tolerar alguma interrupção no funcionamento da VM, poderá economizar uma quantia significativa de dinheiro usando VMs preemptivas. 
O Google App Engine é a oferta de PaaS do Google. Esta é uma das opções sem servidor. Você fornece 
o código do aplicativo e, no caso do ambiente flexível App Engine, uma especificação para um 
86 Capítulo 4 ■ Introdução à Computação no Google Cloud
Contêiner do Docker para executar seu aplicativo. O ambiente padrão do App Engine é apropriado para aplicativos que podem ser executados em caixas de proteção específicas do idioma. 
Aplicativos de software modernos são criados em vários serviços que podem ter diferentes 
requisitos de computação e mudar em diferentes ciclos de vida. O Kubernetes Engine executa clusters 
de servidores que podem ser usados ​​para executar uma variedade de serviços e, ao mesmo tempo, alocar o trabalho aos 
servidores conforme necessário. O Kubernetes Engine também fornece monitoramento, dimensionamento e correção 
quando algo dá errado com uma VM no cluster. 
Aplicativos fracamente acoplados podem ser agrupados para implementar fluxos de trabalho complexos. 
Frequentemente, queremos que cada componente seja independente dos outros. Em tais casos, muitas vezes precisamos
para executar o código "cola" que move a carga de trabalho de um estágio para outro. Cloud Functions é 
a opção de computação sem servidor projetada para atender a essa necessidade. 
Fundamentos do exame 
Entenda como as imagens são usadas para criar instâncias de VMs e como as VMs são organizadas 
em projetos. Instâncias executam imagens, que contêm sistemas operacionais, bibliotecas e outros 
códigos. Ao criar uma instância, você especifica um projeto para conter a instância. 
Saiba que o GCP tem várias regiões geográficas e as regiões têm uma ou mais zonas. VMs são 
executadas em zonas. Uma região é uma localização geográfica, como asia-east1, europe-west2 e 
us-east4. As zonas dentro de uma região são vinculadas por 
conexões de rede de baixa latência e alta largura de banda .
Entenda o que são as VMs preemptivas e quando elas são apropriadas para uso. 
Entenda também quando não usá-los. O GCP oferece uma opção chamada VM pré-preemptiva para 
cargas de trabalho que podem ser interrompidas sem criar problemas. 
Entenda a diferença entre o ambiente padrão do Google App Engine e os ambientes flexíveis. 
O ambiente padrão executa uma plataforma específica de idioma e o 
ambiente flexível do App Engine permite que você execute contêineres personalizados. 
Saiba que o Kubernetes é uma plataforma de orquestração de contêineres. Também executa contêineres em um 
cluster. 
Entenda o Kubernetes. Ele fornece balanceamento de carga, dimensionamento automático, registro e 
verificações e reparos de integridade do nó .
Entenda as funções da nuvem. Esse serviço é usado para executar programas em resposta a eventos, 
como upload de arquivo ou uma mensagem sendo incluída em uma fila. 
Perguntas de revisão 87 Perguntas de 
revisão 
Neste capítulo, você aprenderá sobre o Google Cloud Console, 
uma interface gráfica do usuário para trabalhar com o Google Cloud 
Platform (GCP). Você aprenderá como instalar o Google Cloud 
SDK e usá-lo para criar instâncias de máquinas virtuais e como usar o Cloud Shell como uma 
alternativa para instalar o Google Cloud SDK localmente. 
Criando e configurando 
máquinas virtuais com o console 
Vamos criar uma VM no Compute Engine. Nós temos três opções para fazer isso: podemos usar
Google Cloud Console, Google Cloud SDK ou Google Cloud Shell. Vamos começar com o 
console. 
O Google Cloud Console é uma interface gráfica do usuário baseada na Web para criar, configurar 
e gerenciar recursos no Google Cloud. Neste capítulo, vamos usá-lo para criar uma VM. 
Para abrir o console, navegue em seu navegador para https://console.cloud.google.com 
e faça login. A Figura 5.1 mostra um exemplo do formulário principal no console. 
Figuração 5.1 A principal forma inicial do Google Cloud Console 
Criação e configuração de máquinas virtuais com o console 93 
Na seção superior esquerda do formulário, clique na opção Selecionar um projeto para exibir os 
projetos existentes. Você também pode criar um novo projeto a partir deste formulário, mostrado em
Figura 5.2. 
F igur e 5.2 O formulário de projeto permite que você escolha o projeto para trabalhar ao criar 
VMs. Você também pode criar um novo projeto aqui. 
Depois de selecionar um projeto existente ou criar um novo projeto, você pode retornar ao 
painel principal do console. Na primeira vez que você tentar trabalhar em uma VM, será necessário criar uma conta de faturamento, 
caso ainda não tenha sido criada. A Figura 5.3 mostra uma mensagem e um botão no 
painel principal para criar uma conta de faturamento. 
Quando uma conta de faturamento não existe para um projeto, você terá a 
opção de criar uma conta de faturamento quando tentar criar uma VM. 

94 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine
Clique em Ativar faturamento e preencha as informações de faturamento, como nome, endereço e 
cartão de crédito . Quando o faturamento estiver ativado, você retornará ao painel principal (veja a Figura 5.4). 
F igur e 5.4 O painel inicial para criar uma VM 
Clique no botão Criar na caixa de diálogo para exibir uma configuração de VM, conforme mostrado na 
Figura 5.5. 
F igur 5.5 Parte do formulário de configuração principal para criar VMs no Compute Engine 
Criando e configurando máquinas virtuais com o console 95 
Principais detalhes da configuração da máquina virtual 
Dentro do console, você pode especificar todos os detalhes necessários sobre a configuração da 
VM que você está criando, incluindo o seguinte: 
■ Nome da VM
■ Região e zona em que a VM será executada 
■ Tipo de máquina, que determina o número de CPUs e a quantidade de memória na 
VM 
■ Disco de inicialização, que inclui o sistema operacional que a VM executará 
Você pode escolher o nome da sua VM. Isto é principalmente para o seu uso. O Google Cloud usa 
outros identificadores internamente para gerenciar VMs. 
Você precisará especificar uma região. As regiões são grandes áreas geográficas. Uma lista parcial de 
regiões é mostrada na Figura 5.6. 
F igur e 5.6 Uma lista parcial de regiões que fornecem serviços do Compute Engine 
Depois de selecionar uma região, você pode selecionar uma zona. Lembre-se, uma zona é uma 
instalação semelhante a um datacenter dentro de uma região. A Figura 5.7 mostra uma lista de exemplos de zonas disponíveis no us-east-1
região. 
F igur e 5.7 Uma lista de zonas dentro da região us-east-1 
Depois de especificar uma região e zona, o Google Cloud pode determinar as VMs disponíveis 
nessa zona. Nem todas as zonas têm a mesma disponibilidade. A Figura 5.8 mostra uma lista de exemplos de 
tipos de máquinas disponíveis na zona us-east1-b. 
96 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine 
F iguração 5.8 Uma lista de tipos de máquina disponíveis na zona us-east1-b 
A seção Boot Disk Option (Opção de disco de inicialização) lista uma configuração padrão. Clicar no botão Alterar 
exibe a caixa de diálogo Opção de disco de inicialização, conforme mostrado na Figura 5.9. 
F igur e 5.9 Caixa de diálogo para configurar o disco de inicialização da VM 
Criando e configurando máquinas virtuais com o console 97
Aqui você pode escolher o sistema operacional que deseja usar. Você também pode escolher o 
tipo de disco de inicialização, que pode ser Disco Persistente Padrão ou Disco Permanente SSD. Você 
também pode especificar o tamanho do disco. 
Após a seção Boot Disk, é a seção Identity and API Access. Aqui você pode 
especificar uma conta de serviço para a VM e definir o escopo do acesso à API. Se você deseja que os processos em execução nesta VM usem apenas algumas APIs, você pode usar essas opções para limitar o 
acesso da VM a APIs específicas. 
Configuração e configurações do Identity e do API Access e Firewall 
Na próxima seção, você pode selecionar se deseja que a VM aceite 
tráfego HTTP ou HTTPS . 
Detalhes adicionais de configuração
Clique em Gerenciamento, Segurança, Discos, Rede e Alocação Única para expor 
opções adicionais de configuração. 
98 Capítulo 5 ■ Computação com o Compute Engine Máquinas Virtuais 
Guia Gerenciamento 
A guia Gerenciamento do formulário (Figura 5.11) fornece um espaço onde você pode descrever 
a VM e seu uso. Você também pode criar rótulos, que são pares de valores-chave. Você pode atribuir 
qualquer rótulo que desejar. Os rótulos e uma descrição geral geralmente são usados ​​para ajudar a gerenciar suas 
VMs e entender como elas estão sendo usadas. Os rótulos são particularmente importantes quando 
o número de servidores aumenta. É uma prática recomendada incluir uma descrição e rótulos para todas as 
VMs. 
F igur e 5.11 A primeira parte da guia Gerenciamento do formulário de criação da VM
Se você quiser forçar uma confirmação extra antes de excluir uma instância, poderá selecionar a 
opção de proteção de exclusão. Se alguém tentar excluir a instância, a operação falhará. 
Você pode especificar um script de inicialização para ser executado quando a instância for iniciada. Copie o conteúdo do 
script de inicialização para a caixa de texto do script. Por exemplo, você pode colar um 
script bash ou Python diretamente na caixa de texto. 
A seção Metadados permite que você especifique pares de valor-chave associados à instância. 
Esses valores são armazenados em um servidor de metadados, que está disponível para consulta usando a 
API do Compute Engine. Tags de metadados são especialmente úteis se você tiver um script comum
deseja executar na inicialização ou no encerramento, mas deseja que o comportamento do script varie de acordo 
com alguns valores de metadados. 
A política de disponibilidade define três parâmetros. 
■ Preempção, que, quando ativada, permite que o Google encerre o servidor com um 
aviso de 30 segundos. Em troca, o custo de um servidor preempitável é muito menor do que o de 
um servidor não preempível. 
Criando e configurando máquinas virtuais com o Console 99 
■ Reinício automático, que indica se o servidor parar devido a uma falha de hardware, 
evento de manutenção, ou algum outro evento não controlado pelo usuário 
■ Na manutenção de acolhimento, que indica se o servidor virtual deve ser migrado para 
outro servidor físico quando ocorre um evento de manutenção
F igur e 5.12 A segunda parte da guia Gerenciamento do formulário de criação de VM 
Na seção Segurança, você pode especificar se deseja usar as 
chaves VMs Blindadas e Secure Shell (SSH). 
As VMs protegidas são configuradas para ter mecanismos de segurança adicionais que você pode 
optar por executar. Isso inclui o seguinte: 
■ Inicialização segura, que garante que somente o software do sistema operacional autenticado seja executado na 
VM. Ele faz isso verificando as assinaturas digitais do software. Se uma 
verificação de assinatura falhar, o processo de inicialização será interrompido. 
■ Virtual Trusted Platform Module (vTPM), que é uma versão virtualizada de um 
módulo de plataforma confiável (TPM). Um TPM é um chip de computador especializado projetado para proteger
recursos de segurança, como chaves e certificados. 
■ Monitoramento de integridade, que usa uma boa linha de base de medidas de inicialização para 
comparar com as medidas de inicialização recentes. Se a verificação falhar, haverá alguma diferença 
entre a medição da linha de base e as medições atuais. 
100 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine 
F igur e 5.13 É possível colocar controles de segurança adicionais nas VMs. 
O GCP suporta o conceito de chaves SSH em todo o projeto, que são usadas para fornecer aos usuários 
acesso em todo o projeto às VMs. Você pode bloquear esse comportamento na VM se usar 
chaves SSH em todo o projeto e não quiser que todos os usuários do projeto tenham acesso a essa máquina.
A próxima guia avançada é a guia Disco de inicialização. Aqui você pode especificar se o disco de inicialização 
deve ser excluído quando a instância for excluída. Você também pode selecionar como gostaria de 
gerenciar chaves de criptografia para o disco de inicialização. Por padrão, o Google gerencia essas chaves. 
Na guia de configuração do Boot Disk, você também tem a opção de adicionar um novo disco 
ou anexar um disco existente. A Figura 5.14 mostra a guia para adicionar um novo disco. 
Configuração do disco de inicialização 
Configuração e configuração de máquinas virtuais com o console 101 
Ao adicionar um disco existente, o formulário de diálogo é exibido, como na Figura 5.15. Observe que 
o menu suspenso Disco tem uma lista de discos existentes que você pode escolher. Você pode fazer o
disco somente leitura ou leitura / gravação. Você também pode indicar se deseja que o disco seja excluído quando a 
instância for excluída. Usar um disco existente no modo somente leitura é uma boa maneira de replicar 
dados de referência em várias instâncias de VMs. 
F igur e 5.15 Diálogo para adicionar um disco existente a uma VM 
Você também pode adicionar um novo disco usando a caixa de diálogo mostrada na Figura 5.16. Ao adicionar um novo 
disco, você precisa fornecer as seguintes informações: 
■ Nome do disco 
■ Tipo de disco, padrão ou SSD Disco permanente 
■ Imagem de origem, se não for um disco vazio 
■ Indicação de se deseja excluir o disco quando o disco a instância é excluída 
■ Tamanho em gigabytes 
■ Como as chaves de criptografia serão gerenciadas
102 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine 
F igura e 5.16 Caixa de diálogo para adicionar um novo disco a uma VM 
Na guia Rede, você pode ver as informações da interface de rede, incluindo o 
endereço IP da VM. Se você tiver várias redes, terá a opção de adicionar outra 
interface de rede a essa outra rede. Esse uso de interfaces de rede dupla pode ser útil se você estiver executando algum tipo de proxy ou servidor que atua como um controle para o fluxo de algum 
tráfego entre as redes. Além disso, você também pode adicionar tags de rede nessa caixa de diálogo (consulte a 
Figura 5.17). 
F igur e 5.17 Caixa de diálogo para configuração de rede de uma VM 
Se você precisa garantir que suas máquinas virtuais sejam executadas em um servidor somente com suas outras VMs, então
você pode especificar a locação exclusiva. A guia Inquilino único permite que você especifique rótulos referentes ao 
arrendamento exclusivo para o servidor (consulte a Figura 5.18). 
Criando e configurando máquinas virtuais com o SDK da nuvem 109 
Figurar 5.18 formulário de configuração do contrato único 
Criando e configurando 
máquinas virtuais com o Cloud SDK 
Uma segunda maneira de criar e configurar VMs é com o Google Cloud SDK, que fornece uma 
interface de linha de comando. Para usar o Cloud SDK, primeiro você precisa instalá-lo no seu 
dispositivo local . 
Instalando o Cloud SDK 
Você tem três opções para interagir com os recursos do Google Cloud: 
■ Usando uma interface de linha de comando 
■ Usando uma interface RESTful 
■ Usando o Cloud Shell
Antes de usar uma das duas primeiras opções do seu sistema local, você precisará 
instalar o Cloud SDK em sua máquina. O Cloud Console é uma interface gráfica do usuário que você pode 
acessar por meio de um navegador em https://console.cloud.google.com. 
O Cloud SDK pode ser instalado em computadores Linux, Windows ou Mac. 
104 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine 
Instalação do Cloud SDK no Linux 
Se você estiver usando o Linux, poderá instalar o Cloud SDK usando o gerenciador de pacotes do seu sistema operacional 
. O Ubuntu e outras distribuições Debian usam o apt-get para instalar pacotes. O Red 
Hat Enterprise, o CentOS e outras distribuições do Linux usam o yum. Para obter instruções sobre o uso do 
apt-get, consulte https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu. Para
instruções sobre como instalar no Red Hat Enterprise ou no CentOS, consulte https://cloud.google 
.com / sdk / docs / quickstart-redhat-centos.Installing. 
Cloud SDK no Mac OS As 
instruções para instalação em um Mac e o arquivo de instalação do Cloud SDK estão disponíveis em https://cloud.google.com/sdk/docs/quickstart-macos. O primeiro passo é 
verificar se você tem o Python 2.7 instalado. Existem duas versões do Cloud SDK, uma 
para o macOS de 32 bits e outra para o macOS de 64 bits. 
Instalando o Cloud SDK no Windows 
Para instalar o Cloud SDK em uma plataforma Windows, você precisará baixar o instalador apropriado. Você pode encontrar instruções em https://cloud.google.com/sdk/docs/ 
quickstart-windows. 
Exemplo de instalação no Ubuntu Linux
A primeira etapa na instalação do Cloud SDK é obter a versão apropriada do pacote para o 
seu sistema operacional. Os seguintes comandos são para instalar o Cloud SDK no Ubuntu. 
Consulte https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu para obter atualizações para 
este procedimento. 
Você precisa identificar qual versão do sistema operacional está usando, pois a 
convenção de nomenclatura do Google para o Cloud SDK faz referência ao nome do sistema operacional. O comando a seguir cria uma variável de ambiente com o nome do pacote do Cloud SDK para o sistema operacional atual: 
export CLOUD_SDK_REPO = "cloud-sdk - $ (lsb_release -c -s)" 
Observe que, se você receber uma mensagem de erro que o comando lsb_release Não foi encontrado,
você pode instalá-lo com os seguintes comandos: 
sudo apt-get update 
sudo apt-get install lsb-core 
É possível ver o valor da variável CLOUD_SDK_REPO usando o seguinte comando: 
echo $ CLOUD_SDK_REPO 
Isso exibirá um valor como cloud-sdk- biônico. Bionic é o codinome do 
Ubuntu 18.04. 
Agora o Cloud SDK está instalado e você pode executar comandos usando-o. O primeiro passo é 
inicializar o Cloud SDK usando o comando gcloud init, conforme mostrado aqui: 
gcloud init 
Quando você receber um link de autenticação, copie-o para o navegador. Você será solicitado a se 
autenticar com o Google quando acessar esse URL. Em seguida, um código de resposta aparece em seu
navegador. Copie isso para sua janela de terminal e cole-o em resposta ao prompt que 
deve aparecer. 
Em seguida, você será solicitado a inserir um projeto. Se os projetos já existirem na sua conta, eles 
serão listados. Você também tem a opção de criar um novo projeto neste momento. O projeto 
selecionado ou criado por você será o projeto padrão usado ao emitir comandos por meio do Cloud SDK. 
Criando uma máquina virtual com o Cloud SDK 
Para criar uma VM a partir da linha de comando, você usará o comando gcloud. Você usa esse 
comando para muitas tarefas de gerenciamento de nuvem, incluindo as seguintes: 
■ Compute Engine 
■ Instâncias do Cloud SQL 
■ Mecanismo do Kubernetes 
■ Cloud Dataproc 
■ Cloud DNS
■ Implantação na nuvem 
O comando gcloud é organizado em uma hierarquia de grupos, como o 
grupo de computação dos comandos do Compute Engine. Discutiremos outros grupos nos próximos capítulos; o 
foco aqui é no Compute Engine. 
Um comando típico gcloud começa com o grupo, como mostrado aqui: 
gcloud computar 
106 Capítulo 5 ■ Computing com Compute Engine Máquinas Virtuais 
Um subgrupo é usado em Compute Engine comandos para indicar que tipo de computação 
recurso que você está trabalhando. Para criar uma instância, você usa este comando: 
gcloud compute instances 
E a ação que você quer tomar é criar uma instância, então você usaria isso: 
gcloud compute instances crie ace-instance-1, ace-instance-2
Se você não especificar parâmetros adicionais, como uma zona, o Google Cloud usará suas 
informações do seu projeto padrão. Você pode visualizar as informações do seu projeto usando o 
seguinte comando gcloud: 
gcloud compute info do projeto 
descrit Para criar uma VM na zona us-central1-a, adicione o parâmetro zone como este: 
gcloud compute instances create ace-instance-1 ace-instance -2 -–zone 
us-central1-a 
Você pode listar as VMs criadas usando: 
gcloud compute instances list 
Aqui estão os parâmetros mais usados ​​com o comando create instance: 
■ --boot-disk-size é o tamanho do arquivo. disco de inicialização para um novo disco. O tamanho do disco pode estar entre 
10 GB e 2 TB.
■ --boot-disk-type é o tipo de disco. Use a lista gcloud compute disk-types para obter uma lista 
de tipos de discos disponíveis na zona em que a VM foi criada. 
■ --labels é a lista de pares de valores-chave no formato KEY = VALUE. 
■ --machine-type é o tipo de máquina a ser usada. Se não for especificado, ele usa n1-standard-1. 
Use a lista de tipos de máquinas gcloud compute para visualizar uma lista de tipos de máquinas disponíveis na 
zona que você está usando. 
■ --preempreitável, se incluído, especifica que a VM será preemptiva. 
Para obter parâmetros adicionais, consulte a documentação de criação da instância glcoud compute em 

Para criar uma VM padrão com 8 CPUs e 30 GB de memória, você pode especificar n1-standard-8 como o tipo de máquina.
gcloud compute instances create ace-instance-n1s8 --machine-type = n1-standard-8 
Se você quiser tornar essa instância preemptiva, adicione o parâmetro preemptible: 
gcloud compute instances create --machine-type = n1-standard-8 --prepreptible aceinstance-1 
Criando uma máquina virtual com o Cloud Shell 
Uma alternativa para executar os comandos do gcloud localmente é executá-los em uma 
instância de nuvem . O Cloud Shell fornece esse recurso. Para usar Nuvem Shell, inicie-o a partir Nuvem 
Básico de Manejo Virtual Machine 107 
Console clicando no ícone do escudo no canto superior direito do navegador, como mostrado 
na Figura 5.19. 
Figuração 5.19 O Cloud Shell é ativado pelo Cloud Console.
O Cloud Shell fornece uma linha de comando do Linux, conforme mostrado na Figura 5.20, e o Cloud SDK 
já está instalado. Todos os comandos do glcoud que você pode inserir em seu dispositivo local com o Cloud 
SDK instalado podem ser usados ​​no Cloud Shell. 
F igur e 5.20 O Cloud Shell abre uma janela de linha de comando no navegador. 
Gerenciamento básico de máquinas 
virtuais Quando as VMs estão em execução, você pode executar tarefas básicas de gerenciamento usando o console ou 
usando comandos gcloud. 
Iniciando e parando instâncias 
No console, você visualiza uma lista de instâncias selecionando Compute Engine e, em seguida, 
instâncias de VM no painel do lado esquerdo do console. Você pode então selecionar uma VM para operar em 
Máquinas Virtuais.
e listar as opções de comando clicando nos três ícones de pontos à direita. A Figura 5.21 mostra um 
exemplo. 
F igur e 5.21 Operações básicas em VMs podem ser realizadas usando um menu pop-up no 
console. 
Observe que você pode iniciar uma instância interrompida usando o comando start ativado no 
pop-up para instâncias interrompidas. 
Você também pode usar o gcloud para interromper uma instância com o seguinte comando, onde 
INSTANCE-NAME é o nome da instância: 
gcloud compute instances stop INSTANCE-NAME 
Acesso de rede a máquinas virtuais 
Como engenheiro de nuvem, às vezes você precisa fazer login em um VM para executar algumas tarefas de administração. A maneira mais comum é usar o SSH ao fazer login em um servidor Linux ou
Protocolo de Área de Trabalho Remota (RDP) ao efetuar login em um servidor Windows. 
A Figura 5.22 mostra o conjunto de opções para usar o SSH no console. Esta lista de opções 
aparece quando você clica no botão SSH associado a uma VM. 
F igur e 5.22 A partir do console, você pode iniciar uma sessão SSH para efetuar login em um servidor Linux. 
Gestão Virtual Machine Básico 109 
Escolhendo a opção janela do navegador aberta Em abrirá uma nova janela do navegador e 
exibir uma janela de terminal para acessar a linha de comando no servidor. 
F igur 5.23 Uma janela de terminal é aberta em uma nova janela do navegador ao usar o Cloud 
Shell. 
Monitorando uma máquina virtual 
Enquanto sua VM está em execução, você pode monitorar a carga da CPU, do disco e da rede, visualizando a
Página de monitoramento na página Detalhes da instância da VM. 
Para acessar informações de monitoramento no console, selecione uma instância de VM na 
página Instância de VM clicando no nome da VM que você deseja monitorar. Isso mostrará a 
página Detalhes da VM. Selecione a opção Monitoramento perto da parte superior da página para visualizar 
detalhes de monitoramento. 
As figuras 5.24, 5.25 e 5.26 mostram as informações exibidas sobre a CPU, a 
utilização da rede e as operações do disco. 
F igur 5.24 A guia Monitoramento da página Detalhes da Instância da VM mostra a 
utilização da CPU . 
110 Capítulo 5 ■ Computação com máquinas virtuais do Compute Engine 
F igur e 5.25 A guia Monitoramento da página Detalhes da instância da VM também mostra a 
utilização da rede .
F igur e 5.26 A utilização do disco está incluída na guia Monitoramento da 
página Detalhes da instância da VM . 
Diretrizes para o planejamento, implantação e gerenciamento de máquinas virtuais 111 
Custo de máquinas virtuais 
Parte do gerenciamento básico de uma VM está rastreando os custos das instâncias que você está executando. Se você quiser acompanhar os custos automaticamente, ative o faturamento do Cloud Platform e 
configure a Exportação de faturamento. Isso produzirá relatórios diários sobre o uso e o custo das VMs. 
A seguir, os itens mais importantes a serem lembrados sobre os custos de VM: 
■ As VMs são cobradas em incrementos de 1 segundo. 
■ O custo é baseado no tipo de máquina. Quanto mais CPUs e memória forem usadas, maior será 
o custo. 
■ O Google oferece descontos para uso contínuo.
■ As VMs são cobradas por no mínimo 1 minuto de uso. 
■ As VMs preemptivas podem economizar até 80% do custo de uma VM. 
Diretrizes para planejamento, implantação 
e gerenciamento de máquinas virtuais 
Considere as diretrizes a seguir para ajudar a simplificar seu trabalho com as VMs. Essas 
diretrizes se aplicam ao trabalho com um pequeno número de VMs. Os capítulos posteriores fornecerão diretrizes adicionais para trabalhar com clusters e grupos de instâncias, que são conjuntos de 
VMs configuradas de maneira semelhante . 
■ Escolha um tipo de máquina com o menor número de CPUs e a menor quantidade de memória que 
ainda atenda aos seus requisitos, incluindo a capacidade de pico. Isso minimizará o custo da 
VM.
■ Use o console para administração ad hoc de VMs. Use scripts com comandos gcloud 
para tarefas que serão repetidas. 
■ Use scripts de inicialização para executar atualizações de software e outras tarefas que devem ser executadas na inicialização. 
■ Se você fizer muitas modificações em uma imagem da máquina, considere salvá-la e usá-la 
com novas instâncias, em vez de executar o mesmo conjunto de modificações em cada nova 
instância. 
■ Se você puder tolerar interrupções não planejadas, use VMs preemptivas para reduzir custos. 
■ Use SSH ou RDP para acessar uma VM para executar tarefas no nível do sistema operacional. 
■ Use o Cloud Console, o Cloud Shell ou o Cloud SDK para executar tarefas no nível da VM. 
112 Capítulo 5 ■ Computação com o 
Resumo de Máquinas Virtuais do Compute Engine
O Google Cloud Console é uma interface gráfica do usuário baseada na web para o gerenciamento de 
recursos do GCP . O Cloud SDK é um pacote de linha de comando que permite que engenheiros gerenciem 
recursos de nuvem a partir da linha de comando de seu dispositivo local. O Cloud Shell é uma 
interface de terminal baseada na Web para VMs. O Cloud SDK está instalado no Cloud Shell. 
Ao criar uma VM, você precisa especificar vários parâmetros, incluindo um nome 
para a VM, uma região e uma zona em que a VM será executada, um tipo de máquina que especifique o 
número de vCPUs e a quantidade de memória e um disco de inicialização. que inclui um 
sistema operacional . 
O gcloud é o comando de nível superior da estrutura de comando hierárquico no Cloud SDK.
Tarefas comuns ao gerenciar VMs estão iniciando e parando instâncias, usando o SSH para 
acessar um terminal na VM, monitorando e rastreando o custo da VM. 
Fundamentos do exame 
Entenda como usar o Cloud Console e o Cloud SDK para criar, iniciar e interromper as 
VMs. Os parâmetros que você precisará fornecer ao criar uma VM incluem nome, 
tipo de máquina, região, zona e disco de inicialização. Entenda a necessidade de criar uma VM em um 
projeto. 
Saiba como configurar uma VM preemptiva usando o Cloud Console e os comandos gcloud. Saiba quando usar uma VM preemptiva e quando não usar. Saiba que as 
VMs preemptivas custam até 80% menos do que as VMs não-preempíveis. 
Conheça o objetivo das opções avançadas, incluindo VMs protegidas e disco de inicialização avançado
configurações. Saiba que as opções avançadas fornecem segurança adicional. Entenda os 
tipos de proteções fornecidas. 
Saiba como usar os comandos da instância gcloud compute para listar, iniciar e interromper as 
VMs. Conheça a estrutura dos comandos do gcloud. Os comandos gcloud começam com gcloud 
seguido por um serviço, como compute, seguido por um tipo de recurso, como instâncias, seguido por um comando ou verbo, como create, list ou describe. 
Entenda como monitorar uma VM. Saiba onde encontrar a utilização da CPU, monitoramento de rede e monitoramento de disco nas páginas de instâncias de VM do console. Conheça a diferença 
entre listar e descrever instâncias com um comando gcloud.
Conheça os fatores que determinam o custo de uma VM. Saiba que o Google cobra pelo segundo com um mínimo de 1 minuto. Entenda que os custos de um tipo de máquina podem ser diferentes em locais diferentes. Saiba que o custo é baseado no número de vCPUs e memória. 

Depois de criar máquinas virtuais, um engenheiro de nuvem precisará 
trabalhar com instâncias únicas de máquinas virtuais (VMs) 
e grupos de VMs que executam a mesma configuração. Os últimos 
são chamados de grupos de instâncias e são introduzidos neste capítulo. 
Este capítulo começa com uma descrição das tarefas comuns de gerenciamento e como 
concluí-las no console, seguida de uma descrição de como concluí-las no 
Cloud Shell ou com a linha de comando do Cloud SDK. Em seguida, você aprenderá como configurar
e gerenciar grupos de instâncias. O capítulo termina com uma discussão sobre diretrizes para o 
gerenciamento de VMs. 
Gerenciando 
Instâncias Únicas de Máquina Virtual 
Começamos discutindo como gerenciar uma única instância de uma VM. Por instância única, queremos 
dizer um criado por si mesmo e não em um grupo de instâncias ou outro tipo de cluster. Lembre-se 
de capítulos anteriores de que existem três maneiras de trabalhar com instâncias: no Cloud Console, 
no Cloud Shell e com a linha de comando do Cloud SDK. As 
linhas de comando do Cloud Shell e do Cloud SDK usam comandos gcloud. Por isso, descreveremos o Cloud Shell e o 
Cloud SDK juntos nesta seção. 
Gerenciando Instâncias Únicas de Máquina Virtual 
no Console
As tarefas básicas de gerenciamento de VMs com as quais um engenheiro de nuvem deve estar familiarizado são a 
criação, a parada e a exclusão de instâncias. Nós cobrimos a criação de instâncias no 
capítulo anterior , então vamos nos concentrar nas outras tarefas aqui. Você também deve estar familiarizado com a listagem de 
VMs, anexando unidades de processamento gráfico (GPUs) a VMs e trabalhando com instantâneos e 
imagens. 
Iniciando, parando e excluindo instâncias 
Para começar a trabalhar, abra o console e selecione Compute Engine. Em seguida, selecione instâncias de VM. 
Isso exibirá uma janela como na Figura 6.1, mas com diferentes VMs listadas. Neste 
exemplo, existem três VMs. 
Gerenciando Instâncias Únicas de Máquina Virtual 119
Figura 6.1 O painel Instância de VM na seção Compute Engine do Cloud Console 
As três instâncias na Figura 6.1 estão todas em execução. Você pode parar as instâncias 
clicando no ícone de três pontos no lado direito da linha listando os atributos da VM. Esta 
ação exibe uma lista de comandos. A Figura 6.2 mostra a lista de comandos disponíveis para 
instancech06-instance-1. 
Figura 6.2 Lista de comandos disponíveis no console para alterar o estado de 
uma VM 
Se você selecionar Parar no menu de comando, a instância será interrompida. Quando uma 
instância é interrompida, ela não está consumindo recursos de computação, portanto, você não será cobrado. A 
instância ainda existe e pode ser iniciada novamente quando você precisar dela. A figura 6.3 mostra um aviso
formulário que indica que você está prestes a interromper uma VM. Você pode clicar na caixa de diálogo no canto inferior 
esquerdo para suprimir essa mensagem. 
120 Capítulo 6 ■ Gerenciando Máquinas Virtuais 
 Figura 6.3 A mensagem de aviso que podem aparecer sobre a parada de uma máquina virtual 
 Quando você parar um VM, a marca de seleção verde sobre as mudanças deixado para um círculo cinza com um 
quadrado branco, ea opção SSH está desativado, como mostrado na Figura 6.4. 
 figura 6.4 Quando as VMs são paradas, o ícone à esquerda muda e o SSH não está mais 
disponível. 
 Para iniciar uma VM parada, clique no ícone de três pontos à direita para exibir o menu de comandos disponíveis. Observe na Figura 6.5 que Start agora está disponível, mas Stop e Reset não estão.
 figura 6.5 Quando as VMs estão paradas, Stop e Reset não estão mais disponíveis, mas Start 
está disponível como um comando. 
 O comando Reset reinicia uma VM. As propriedades da VM não serão alteradas, mas os dados 
na memória serão perdidos. 
  
 Quando uma VM é reiniciada, o conteúdo da memória é perdido. Se você precisar 
preservar dados entre as reinicializações ou para uso em outras VMs, salve os dados em um 
disco permanente ou no Cloud Storage. 
Gerenciando Instâncias Únicas de Máquina Virtual 121 
Quando você terminar com uma instância e não precisar mais dela, poderá excluí-la. A exclusão de uma 
VM a remove do Cloud Console e libera recursos, como o armazenamento usado para manter a 
imagem da VM quando parado. A exclusão de uma instância do Cloud Console exibirá uma mensagem
como na Figura 6.6. 
Figura 6.6 A exclusão de uma instância do console exibirá uma mensagem de aviso 
como essa. 
Visualização do inventário de máquinas virtuais 
A página Instâncias de VMs do Cloud Console mostrará uma lista de VMs, se houver alguma no projeto atual. Se você tiver um grande número de instâncias, pode ajudar a filtrar a lista para ver apenas as 
instâncias de interesse. Faça isso usando a caixa Filter VM Instances acima da lista de VMs, como 
mostra a Figura 6.7. 
Figura 6.7 Lista de instâncias filtradas por critérios de pesquisa 
Neste exemplo, especificamos que queremos ver apenas a instância denominada 
ch06-instance-2. Além de especificar nomes de instâncias, você também pode filtrar 
o seguinte: 
■ Etiquetas
■ IP interno ■ IP 
externo 
■ Status 
■ Zona 
■ Rede 
122 Capítulo 6 ■ Gerenciando máquinas virtuais 
■ Proteção de exclusão 
■ Membro do grupo 
de instâncias gerenciadas ■ Membro do grupo de instâncias não gerenciadas 
Se você definir várias condições de filtro, todas devem ser verdadeiras para uma VM ser listado, a menos que 
você indique explicitamente o operador OR. 
Anexar GPUs a uma instância 
GPUs é usado para aplicativos intensivos em matemática, como visualizações e aprendizado de máquina. 
As GPUs realizam cálculos matemáticos e permitem que alguns trabalhos sejam descarregados da CPU para 
a GPU. 
Para adicionar uma GPU a uma instância, você deve iniciar uma instância em que as bibliotecas da GPU
foi instalado ou será instalado. Por exemplo, você pode usar uma das imagens do Google Cloud 
Platform (GCP) que possui bibliotecas de GPU instaladas, incluindo as 
imagens do Deep Learning , conforme mostrado na Figura 6.8. Você também deve verificar se a instância será executada em uma zona 
que tenha GPUs disponíveis. 
Figura 6.8 Ao anexar as GPUs, é melhor usar uma imagem que tenha as bibliotecas necessárias 
instaladas. Você pode usar uma imagem fornecida pelo GCP ou uma imagem personalizada com as bibliotecas necessárias. 
Você também precisará personalizar a configuração para o tipo de máquina; A Figura 6.9 
mostra o formulário. 
Gerenciando instâncias de máquina virtual única 123 
F igure 6.9 O formulário do Cloud Console para configurar o tipo de máquina
Clique em Personalizar. Isso expandirá o conjunto de parâmetros do tipo de máquina, conforme mostrado na 
Figura 6.10. 
Figura 6.10 Este formulário é usado ao criar um tipo de máquina personalizado. 
Selecione o número de GPUs para anexar. As opções são Nenhum, 1, 2 ou 4 (veja a Figura 6.11). 
Em seguida, selecione o tipo de GPU, conforme mostrado na Figura 6.12. 
Figura 6.11 Selecionando o número de GPUs para anexar à VM 
124 Capítulo 6 ■ Gerenciando máquinas virtuais 
Figura 6.12 Selecionando o tipo de GPUs para anexar à VM 
Há algumas restrições sobre o uso de GPUs. A CPU deve ser compatível com a 
GPU selecionada. Por exemplo, se você estiver executando uma VM em um servidor com um Intel Skylake ou
mais tarde CPU, então você não pode usar o GPU Tesla K80. As GPUs não podem ser anexadas a 
máquinas de memória compartilhada . Para obter a documentação mais recente sobre as restrições da GPU e uma lista de zonas 
com GPUs, consulte https://cloud.google.com/compute/docs/gpus/. 
Além disso, se você adicionar uma GPU a uma VM, deverá definir a instância para ser finalizada durante a manutenção. Isso é definido na seção Políticas de disponibilidade do formulário de configuração da VM (consulte a 
Figura 6.13). 
Figura 6.13 Políticas de disponibilidade recomendadas para VMs com GPUs anexadas 
Trabalhando com Instantâneos Os 
instantâneos são cópias de dados em um disco permanente. Você usa instantâneos para salvar dados em um disco 
para poder restaurá-lo. Essa é uma maneira conveniente de criar vários discos permanentes com os 
mesmos dados.
Quando você cria um snapshot pela primeira vez, o GCP fará uma cópia completa dos dados no disco permanente. Na próxima vez que você criar um snapshot a partir desse disco, o GCP copiará apenas os 
dados que foram alterados desde o último snapshot. Isso otimiza o armazenamento enquanto mantém o 
instantâneo atualizado com os dados que estavam no disco na última vez que uma operação de instantâneo 
ocorreu. 
Se você estiver executando um banco de dados ou outro aplicativo que possa armazenar em buffer os dados na memória 
antes de gravar no disco, limpe os buffers de disco antes de criar o instantâneo; caso contrário, os dados na memória que devem ser gravados no disco podem ser perdidos. A maneira de liberar os 
buffers de disco varia de acordo com o aplicativo. Por exemplo, o MySQL tem uma instrução FLUSH.
Para trabalhar com instantâneos, um usuário deve ser atribuído à função Administrador de Armazenamento de Cálculo. Vá 
para a página Gerenciamento de Identidade de Acesso (IAM), selecione Funções e especifique o 
endereço de e - mail de um usuário a quem será atribuída a função. Selecione a função na lista de funções, conforme mostrado na 
Figura 6.14. 
Gerenciando instâncias de máquinas virtuais únicas 125 
F igure 6.14 Para trabalhar com instantâneos, um usuário precisa ter a 
função Administrador do Cloud Storage . 
Para criar um instantâneo no Cloud Console, exiba as opções do Compute Engine e 
selecione Instantâneos no painel à esquerda, conforme mostrado na Figura 6.15. 
Figura 6.15 Criando um instantâneo usando o Cloud Console 
126 Capítulo 6 ■ Gerenciando máquinas virtuais
Em seguida, clique em Create Snapshot para exibir o formulário na Figura 6.16. Especifique e nomeie e, 
opcionalmente, uma descrição. Você também pode adicionar rótulos ao instantâneo. É uma boa prática 
rotular todos os recursos com uma convenção de rotulagem consistente. No caso de instantâneos, os rótulos 
podem indicar o tipo de dados no disco e o aplicativo que usa os dados. 
Figura 6.16 Formulário para criar um instantâneo 
Se você estiver criando um instantâneo de um disco em um servidor Windows, marque a caixa Ativar VSS 
para criar um instantâneo consistente com o aplicativo sem precisar encerrar a instância. 
Trabalhando com Imagens As 
imagens são semelhantes aos instantâneos, pois são cópias do conteúdo do disco. A diferença é
os instantâneos são usados ​​para disponibilizar dados em um disco, enquanto as imagens são usadas para criar 
VMs. As imagens podem ser criadas a partir do seguinte: 
■ Disco 
■ Instantâneo 
■ Arquivo de armazenamento em nuvem 
■ Outra imagem 
Gerenciando instâncias de máquina virtual única 127 
Para criar uma imagem, escolha a opção Imagem na página do Compute Engine no Cloud 
Console, como mostra a Figura 6.17. Isso lista as imagens disponíveis. 
Figura 6.17 Imagens disponíveis. A partir daqui, você pode criar imagens adicionais. 
Selecione Create Image para mostrar o formulário na Figura 6.18. Isso permite criar uma nova 
imagem especificando nome, descrição e rótulos. Imagens possuem um atributo opcional
chamado Família, que permite agrupar imagens. Quando uma família é especificada, a imagem mais recente e 
não reprovada da família é usada. 
128 Capítulo 6 ■ Gerenciamento de máquinas virtuais 
Figura 6.18 Formulário do Cloud Console para criar uma imagem 
O formulário fornece uma lista suspensa de opções para a origem da imagem, conforme mostrado na 
Figura 6.19. 
Figura 6.19 Opções para a origem de uma imagem 
Quando Disco é selecionado como a origem, você pode escolher entre discos em VMs, conforme mostrado na 
Figura 6.20. 
Gerenciando instâncias de máquinas virtuais únicas 129 
F igure 6.20 Opções ao usar um disco como fonte de uma imagem 
Quando você escolhe Imagem como o tipo de fonte, pode escolher uma imagem a partir da imagem atual.
projeto ou outros projetos (ver Figura 6.21). 
Figura 6.21 Ao usar uma imagem como fonte, você pode escolher uma imagem de origem de 
outro projeto. 
Se você escolher um arquivo do Cloud Storage como fonte, poderá navegar no 
intervalo do Cloud Storage para encontrar um arquivo para usar como fonte (consulte a Figura 6.22). 
Figura 6.22 Ao usar um arquivo do Cloud Storage como fonte, você procura seus intervalos de armazenamento 
para um arquivo. 
Depois de criar uma imagem, você pode excluí-la ou depreciá-la marcando a caixa 
ao lado do nome da imagem e selecionando Excluir ou Desprovar na linha de comandos acima 
da lista, conforme mostrado na Figura 6.23. Você pode excluir e preterir apenas imagens personalizadas, não 
imagens fornecidas pelo GCP.
130 Capítulo 6 ■ Gerenciamento de máquinas virtuais 
F igura 6.23 Os comandos Excluir e Deprecar estão disponíveis quando uma das suas 
imagens personalizadas é selecionada. 
Excluir remove a imagem, enquanto Descontinuado marca a imagem como não mais suportada 
e permite que você especifique uma imagem de substituição a ser usada no futuro. As 
imagens preteridas do Google estão disponíveis para uso, mas não podem ser corrigidas por falhas de segurança ou outras atualizações. 
A suspensão de uso é uma maneira útil de informar aos usuários da imagem que ela não é mais suportada 
e que eles devem planejar testar seus aplicativos com as versões mais recentes e suportadas 
da imagem. Por fim, as imagens reprovadas não estarão mais disponíveis e os usuários das 
imagens obsoletas precisarão usar versões diferentes.
Depois de criar uma imagem, você pode criar uma instância usando essa imagem, selecionando a opção Criar instância na linha de comandos acima da listagem de imagens. 
Além de gerenciar VMs por meio do console, você pode gerenciar recursos de computação 
usando a linha de comando. 
Gerenciando uma única instância de máquina virtual com o Cloud 
Shell e a linha de comando 
Além de gerenciar VMs por meio do console, você pode gerenciar recursos de computação usando 
a linha de comando. Os mesmos comandos podem ser usados ​​no Cloud Shell ou em seu ambiente local após a instalação do Google Cloud SDK, abordado no Capítulo 5. 
Esta seção descreve os comandos mais importantes para trabalhar com instâncias.
Comandos têm seus próprios conjuntos específicos de parâmetros; No entanto, todos os comandos do gcloud suportam conjuntos de sinalizadores. Eles são chamados de sinalizadores gcloud-wide, também conhecidos como 
sinalizadores globais gcloud , e incluem o seguinte: 
■ --account especifica uma conta do GCP para usar a substituição da conta padrão. 
■ - configuração usa um arquivo de configuração nomeado que contém pares de valor-chave. 
■ --flatten gera registros separados de valor-chave quando uma chave possui vários valores. 
Gerenciando única máquina virtual Instâncias 131 
■ --format especifica um formato de saída, como um padrão (legível) CSV, JSON, 
YAML, texto, ou outras opções possíveis. 
■ --help exibe uma mensagem de ajuda detalhada.
■ --project especifica um projeto do GCP a ser usado, substituindo o projeto padrão. 
■ --quiet desabilita os prompts interativos e usa os padrões. 
■ --verbosity especifica o nível de mensagens de saída detalhadas. As opções são debug, info, 
warning e error. 
Ao longo desta seção, os comandos podem ter um parâmetro opcional --zone. Assumimos que 
uma zona padrão foi definida quando você executou o gcloud init. 
Iniciando Instâncias 
Para iniciar uma instância, use o comando gcloud, especificando que você está trabalhando especificamente com 
um serviço de computação e instâncias. Você também precisa indicar que 
iniciará uma instância especificando start, seguido pelo nome de uma ou mais instâncias. 
A sintaxe do comando é a seguinte:
gcloud compute instances start INSTANCE_NAMES 
Um exemplo é o seguinte: 
gcloud compute instances start ch06-instance-1 ch06-instance-2 
O comando de início da instância também recebe parâmetros opcionais. O parâmetro --async 
exibe informações sobre a operação de início. A opção --verbose em muitos 
comandos do Linux fornece funcionalidade semelhante. Um exemplo é o seguinte: 
gcloud compute instances start ch06-instance-1 ch06-instance-2 --async O 
GCP precisa saber em qual zona criar uma instância. Isso pode ser especificado com o 
parâmetro --zone da seguinte forma: 
gcloud compute instances start ch06-instance-1 ch06-instance-2 --zone us-central1-c 
Você pode obter uma lista de regiões com o seguinte comando:
gcloud compute zones list 
Se nenhuma zona for especificada, o comando solicitará uma. 
Parando Instâncias 
Para parar uma instância, use gcloud compute instances e especifique stop seguido do 
nome de uma ou mais instâncias. 
A sintaxe do comando é a seguinte: 
gcloud compute instances pare INSTANCE_NAMES 
132 Capítulo 6 ■ Gerenciando máquinas virtuais 
Um exemplo é o seguinte: 
gcloud compute instances pare ch06-instance-3 ch06-instance-4 
Como o comando start da instância, o comando stop toma opcional parâmetros. O 
parâmetro --async faz com que as informações sobre a operação de início sejam exibidas: 
gcloud compute instances pare ch06-instance-1 ch06-instance-2 -async
O GCP precisa saber qual zona contém a instância a ser interrompida. Isso pode ser especificado com 
o parâmetro --zone da seguinte forma: 
gcloud compute instances parar ch06-instance-1 ch06-instance-2 --zone us-central1-c 
Você pode obter uma lista de zonas com o seguinte comando: 
gcloud compute zones lista 
Excluindo Instâncias 
Quando terminar de trabalhar com uma VM, você poderá excluí-la com o comando delete. 
Veja um exemplo: 
gcloud compute instances delete ch06-instance-1 
O comando delete usa o parâmetro --zone para especificar onde a VM a ser excluída está 
localizada. Veja um exemplo: 
gcloud compute instances delete ch06-instance-1 --zone us-central2-b
Quando uma instância é excluída, os discos na VM podem ser excluídos ou salvos usando 
os parâmetros --delete-disks e --keep-disks, respectivamente. Você pode especificar todos para 
manter todos os discos, inicializar para especificar a partição do sistema de arquivos raiz e dados para especificar 
discos não-inicialização. 
Por exemplo, o comando a seguir mantém todos os discos: 
gcloud compute instances delete ch06-instance-1 --zone us-central2-b --keepdisks = all 
enquanto o seguinte exclui todos os discos não-inicialização: 
gcloud compute instances delete ch06-instance-1 - -zone us-central2-b --deletedisks = dados 
Exibindo inventário de VM 
O comando para exibir o conjunto de VMs em seu inventário é o seguinte: 
gcloud compute instances list
Este comando recebe um nome opcional de uma instância. Para listar VMs em uma determinada zona, 
você pode usar o seguinte: 
gcloud compute instances list --filter = "zona: ZONE" 
onde ZONE é o nome de uma zona. Você pode listar várias zonas usando uma lista separada por vírgulas. 
Gestão única Virtual Machine Instances 133 
O parâmetro --limit é usada para limitar o número de VMs listado, ea --sort-by 
parâmetro é usado para reordenar a lista de VMs, especificando um campo de recursos. Você pode ver os 
campos de recursos de uma VM executando o seguinte: 
gcloud compute instances describe 
Trabalhando com snapshots 
Você pode criar um snapshot de um disco usando o seguinte comando:
gcloud compute disks captura instantânea DISK_NAME --snapshot-names = NAME, em 
que DISK_NAME é o nome de um disco e NAME é o nome do instantâneo. Para visualizar uma lista 
de instantâneos, use o seguinte: 
gcloud compute snapshots list 
Para obter informações detalhadas sobre um instantâneo, use o seguinte: 
gcloud compute snapshots descreve SNAPSHOT_NAME em 
que SNAPSHOT_NAME é o nome do instantâneo a ser descrito. Para criar um disco, use: 
gcloud compute disks crie DISK_NAME --source-snapshot = SNAPSHOT_NAME 
Você também pode especificar o tamanho do disco e do tipo de disco usando os parâmetros --size e 
-. Veja um exemplo: 
gcloud compute disks create ch06-disk-1 --source-snapshot = ch06-snapshot 
--size = 100 --type = pd-standard
Isso criará um disco de 100 GB usando o snapshot ch06 usando um disco permanente padrão. 
Trabalhando com imagens O 
GCP fornece uma ampla gama de imagens para usar ao criar uma VM; no entanto, talvez seja 
necessário criar uma imagem especializada. Isso pode ser feito com o seguinte 
comando: 
gcloud compute images crie IMAGE_NAME, em 
que IMAGE_NAME é o nome dado às imagens. A origem das imagens é especificada 
usando um dos parâmetros de origem, que são os seguintes: 
■ --source-disk 
■ --source-image 
■ --source-image-family 
■ --source-snapshot 
■ --source- uri
Os parâmetros disco de origem, imagem de origem e instantâneo de origem são usados ​​para criar uma imagem usando um disco, imagem e instantâneo, respectivamente. O 
parâmetro source-image-family usa a versão mais recente de uma imagem na família. As famílias são grupos de relacionado 
134 Capítulo 6 ■ Gerenciando Máquinas Virtuais 
imagens, que geralmente são diferentes versões da mesma imagem subjacente. O 
parâmetro source-uri permite especificar uma imagem usando um endereço da web. 
Uma imagem pode ter uma descrição e um conjunto de rótulos. Estes são atribuídos usando os 
parâmetros --description e --labels. 
Aqui está um exemplo de como criar uma nova imagem a partir de um disco: 
gcloud compute images crie ch06-image-1 –-source-disk ch06-disk-1
Você também pode excluir imagens quando elas não forem mais necessárias usando: 
gcloud compute images delete IMAGE_NAME 
Geralmente, é útil armazenar imagens no Cloud Storage. Você pode exportar uma imagem para o Cloud 
Storage com o seguinte comando: 
gcloud compute images export --destination-uri DESTINATION_URI --imagem IMAGE_NAME em 
que DESTINATION_URI é o endereço de um intervalo do Cloud Storage para armazenar a imagem. 
Introdução aos grupos de 
instâncias Os grupos de instâncias são conjuntos de VMs gerenciados como uma única entidade. Qualquer 
comando gcloud ou console aplicado a um grupo de instâncias é aplicado a todos os membros do grupo de instâncias. 
O Google fornece dois tipos de grupos de instâncias: gerenciados e não gerenciados.
Grupos gerenciados consistem em grupos de VMs idênticas. Eles são criados usando um 
modelo de instância, que é uma especificação de uma configuração de VM, incluindo 
tipo de máquina , imagem de disco de inicialização, zona, rótulos e outras propriedades de uma instância. Os 
grupos de instâncias gerenciadas podem dimensionar automaticamente o número de instâncias em um grupo e ser usados 
com balanceamento de carga para distribuir cargas de trabalho no grupo de instâncias. Se uma instância em um 
grupo falhar, ela será recriada automaticamente. Grupos gerenciados são o tipo preferido 
de grupo de instâncias. 
Grupos não gerenciados devem ser usados ​​somente quando você precisa trabalhar com diferentes configurações dentro de diferentes VMs dentro do grupo. 
Criando e removendo grupos e modelos de instâncias
Para criar um grupo de instâncias, você deve primeiro criar um modelo de grupo de instâncias. Para criar um 
modelo de instância, use o seguinte comando: 
gcloud compute instance-templates create INSTANCE 
Você pode especificar uma VM existente como a origem do modelo de instância usando o 
parâmetro --source-instance (o GCP usará uma imagem n1-standard1 por padrão). Veja um 
exemplo: 
gcloud compute exemplo-templates cria ch06-instance-template-1 --sourceinstance = ch06-instance-1 
Introdução a grupos de 
instâncias 135 Os modelos de grupo de instâncias também podem ser criados no console usando a 
página Modelo de grupo de instâncias , conforme mostrado na Figura 6.24. 
F igure 6.24 Os modelos de grupo de instâncias podem ser criados no console usando um formulário
semelhante ao formulário de instância de criação. 
Grupos de instâncias podem conter instâncias em uma única zona ou em uma região. O primeiro 
é chamado de zonal conseguiu grupo de instâncias, eo segundo é chamado conseguiu regionais 
136 Capítulo 6 ■ Gerenciando Máquinas Virtuais 
grupo de instâncias. Os grupos de instâncias gerenciadas regionais são recomendados porque essa configuração distribui a carga de trabalho entre as zonas, aumentando a resiliência. 
Você pode remover modelos de instância excluindo-os da 
página Modelo de grupo de instâncias no console. Selecione o modelo do grupo de instâncias marcando a caixa na lista de 
modelos e, em seguida, exclua-a clicando no ícone de exclusão, conforme mostrado na Figura 6.25. 
F igure 6.25 Os modelos de grupo de instâncias podem ser excluídos no console.
Você também pode excluir um modelo de grupo de instâncias usando o seguinte comando: 
gcloud compute instance-templates delete NAME em 
que INSTANCE-TEMPLATE-NAME é o nome do modelo a ser excluído. 
Para excluir grupos de instâncias no console, selecione o grupo de instâncias a ser excluído da lista 
de grupos de instâncias e clique no ícone de exclusão, conforme mostrado na Figura 6.26. 
Figura 6.26 O grupo de instâncias pode ser excluído no console. 
Exclua os grupos de instâncias da linha de comando usando o seguinte: 
gcloud compute instance-groups managed delete-instances NOME em 
que INSTANCE-GROUP-NAME é o nome do grupo de instâncias a ser excluído. 
Para listar modelos e grupos de instâncias, use o seguinte: 
gcloud compute instance-templates list
gcloud calcular exemplo grupos conseguiu list-instâncias 
diretrizes para o gerenciamento Virtual Machines 137 
 Para listar as instâncias em um grupo de exemplo, use o seguinte: 
 gcloud calcular exemplo grupos gerenciados list-casos INSTÂNCIA-GROUP-NAME 
 Instância Grupos Load Balancing e Autoscaling 
 Para implantar um aplicativo escalonável e altamente disponível, você pode executar esse aplicativo em um conjunto de instâncias com balanceamento de carga. O GCP oferece vários tipos de balanceamento de carga e todos 
exigem o uso de um grupo de instâncias. 
 Além do balanceamento de carga, os grupos de instâncias gerenciadas podem ser configurados para o escalonamento automático . 
Você pode configurar uma política de escalonamento automático para acionar a adição ou remoção de instâncias com base em
Utilização da CPU, métrica de monitoramento, capacidade de balanceamento de carga ou cargas de trabalho baseadas em fila. 
 Não Mais planejamento de capacidade de pico 
 Antes do advento da nuvem, as organizações de TI geralmente tinham que planejar suas 
compras de hardware em torno da carga máxima esperada. Isso é chamado de planejamento de capacidade de pico. Se 
houver pouca variação na carga, o planejamento da capacidade de pico é uma boa abordagem. Empresas 
com cargas de trabalho altamente variáveis, como varejistas nos Estados Unidos que têm alta 
demanda durante os dois últimos meses do ano, teriam que suportar capacidade ociosa por 
meses do ano. A computação em nuvem e o escalonamento automático eliminaram a necessidade de 
planejamento de capacidade máxima. Servidores adicionais são adquiridos em minutos, não em semanas ou meses.
Quando a capacidade não é necessária, ela é descartada. Grupos de instâncias automatizam o processo de adicionar e remover VMs, permitindo que os engenheiros da nuvem sintonizem quando adicionar e quando 
remover as VMs. 
 
 No escalonamento automático, garanta tempo suficiente para as VMs inicializarem ou 
desligarem antes de acionar outra mudança na configuração do cluster. Se 
o tempo entre as verificações for muito pequeno, você poderá descobrir que uma 
VM adicionada recentemente não está totalmente iniciada antes que outra seja adicionada. Isso pode levar a mais VMs 
sendo adicionadas do que as realmente necessárias. 
 Diretrizes para gerenciar máquinas virtuais 
 Aqui estão algumas diretrizes para o gerenciamento de VMs: 
 ■ Use rótulos e descrições. Isso ajudará você a identificar o propósito de uma instância e
também ajuda ao filtrar listas de instâncias. 
■ Gerenciando máquinas virtuais 
■ Use grupos de instâncias gerenciadas para habilitar o escalonamento automático e o balanceamento de carga. Essas são a chave 
para implantar serviços escalonáveis ​​e altamente disponíveis. 
■ Use GPUs para processamento intensivo de números, como aprendizado de máquina e 
computação de alto desempenho . Para algumas aplicações, as GPUs podem oferecer maior benefício de desempenho do que adicionar 
outra CPU. 
■ Use instantâneos para salvar o estado de um disco ou para fazer cópias. Estes podem ser salvos no 
Cloud Storage e agem como backups. 
■ Use instâncias preemptivas para cargas de trabalho que possam tolerar a interrupção. Isso reduzirá 
o custo da instância em até 80%. 
Resumo
Neste capítulo, você aprendeu como criar instâncias de uma VM gerenciada e grupos de instâncias. 
Instâncias únicas de VM podem ser criadas, configuradas, interrompidas, iniciadas e excluídas usando o Cloud 
Console ou usando comandos gcloud do Cloud Shell ou de sua máquina local, caso você tenha o 
SDK instalado. 
Instantâneos são cópias de discos e são úteis como backups e para copiar dados para outras 
instâncias. Imagens são cópias de discos que estão em um formato adequado para a criação de VMs. 
O comando principal usado para gerenciar VMs é o comando gcloud compute instances. 
O gcloud usa uma estrutura hierárquica para ordenar os elementos de comando. O comando começa 
com gcloud, seguido por um recurso do GCP, como computação para o Compute Engine, seguido
por um tipo de entidade, como instâncias ou instantâneos. Uma ação é especificada, como 
criar, excluir, listar ou descrever. 
GPUs podem ser anexadas a instâncias com bibliotecas de GPU instaladas no sistema operacional. As GPUs são usadas para tarefas de computação intensiva, como a construção de modelos de aprendizado de máquina. 
Grupos de instâncias são grupos de instâncias que são gerenciados juntos. 
Grupos de instâncias gerenciadas têm instâncias iguais. Esses grupos suportam balanceamento de carga e 
escalonamento automático. 
Fundamentos do exame 
Entenda como navegar no Cloud Console. O Cloud Console é a interface gráfica 
para trabalhar com o GCP. Você pode criar, configurar, excluir e listar instâncias de 
VMs na área do Compute Engine do console.
Entenda como instalar o Cloud SDK. O Cloud SDK permite configurar variáveis ​​de ambiente padrão, como uma zona preferencial, e emitir comandos a partir da linha de comando. 
Se você usa o Cloud Shell, o Cloud SDK já está instalado. 
Fundamentos do exame 139 
Saiba como criar uma VM no console e na linha de comando. Você pode especificar o 
tipo de máquina, escolher uma imagem e configurar discos com o console. Você pode usar comandos na linha de comando para listar e descrever, e você pode encontrar as mesmas informações 
no console. Entenda quando usar imagens personalizadas e como desaprová-las. 
Imagens são cópias do conteúdo de um disco e são usadas para criar VMs. Deprecado marca 
uma imagem como não mais suportada.
Entenda porque as GPUs são usadas e como anexá-las a uma VM. As GPUs são usadas para 
operações intensivas de computação; Um caso de uso comum para o uso de GPUs é o aprendizado de máquina. É 
melhor usar uma imagem que tenha bibliotecas de GPU instaladas. Entenda como determinar quais 
locais têm GPUs disponíveis, porque há algumas restrições. A CPU deve ser compatível com a GPU selecionada e as GPUs não podem ser conectadas a máquinas de memória compartilhada. 
Saiba como os custos da GPU são cobrados. 
Compreenda imagens e instantâneos. Os instantâneos salvam o conteúdo dos discos para 
fins de backup e compartilhamento de dados. As imagens salvam o sistema operacional e as configurações relacionadas para que você 
possa criar cópias idênticas da instância.
Entenda grupos de instâncias e modelos de grupos de instâncias. Grupos de 
instâncias são conjuntos de instâncias gerenciados como uma única entidade. Os modelos de grupo de instâncias especificam a configuração de 
um grupo de instâncias e as instâncias nele. Os grupos de instâncias gerenciadas suportam escalonamento automático 
e balanceamento de carga. 
140 Capítulo 6 ■ Gerenciando máquinas virtuais 
Este capítulo apresenta o Kubernetes, um 
sistema de orquestração de contêiner criado e aberto pelo Google. Você aprenderá 
sobre a arquitetura do Kubernetes e as formas como gerencia as 
cargas de trabalho nos nós de um cluster. Você também aprenderá 
a gerenciar os recursos do Kubernetes com o Cloud Console, o Cloud Shell e o Cloud SDK. o
O capítulo também aborda como implantar conjuntos de aplicativos (uma estrutura do Kubernetes) e monitorar 
e registrar recursos do Kubernetes. 
Introdução ao Kubernetes Engine O 
Kubernetes Engine é o serviço Kubernetes gerenciado pelo Google Cloud Platform (GCP). Com 
esse serviço, os clientes do GCP podem criar e manter seus próprios clusters do Kubernetes sem 
ter que gerenciar a plataforma Kubernetes. 
O Kubernetes executa contêineres em um cluster de máquinas virtuais (VMs). Ele determina onde 
executar contêineres, monitora a integridade dos contêineres e gerencia o ciclo de vida completo das 
instâncias da VM . Esta coleção de tarefas é conhecida como orquestração de contêineres. 
Pode parecer que um cluster do Kubernetes é semelhante a um grupo de instâncias, que foi
discutido no Capítulo 6. Existem algumas semelhanças. Ambos são conjuntos de VMs que podem ser 
gerenciados como um grupo. Grupos de instâncias, no entanto, são muito mais restritos. Todas as VMs geralmente 
executam a mesma imagem em um grupo de instâncias. Esse não é o caso do Kubernetes. Além disso, os 
grupos de instâncias não têm mecanismo para suportar a implantação de contêineres. Os contêineres oferecem um 
meio leve e altamente portátil de distribuir e dimensionar seus aplicativos ou cargas de trabalho, como VMs, sem replicar o sistema operacional convidado. Eles podem iniciar e parar muito mais rápido (geralmente em segundos) e usar menos recursos. Você pode pensar em um contêiner como semelhante ao envio de 
contêineres para aplicativos e cargas de trabalho. Como contêineres que podem andar em navios,
trens e caminhões sem reconfiguração, contêineres de aplicativos podem ser movidos de laptops de desenvolvimento para servidores de teste e produção sem reconfiguração. Isso teria que 
ser feito manualmente. Os grupos de instâncias têm algum monitoramento e podem reiniciar instâncias que 
falham, mas o Kubernetes tem muito mais flexibilidade com relação à manutenção de um cluster de servidores. 
Vamos dar uma olhada na arquitetura do Kubernetes, que consiste em vários objetos e um conjunto 
de controladores. 
Lembre-se: ao usar o Kubernetes Engine, você gerenciará o Kubernetes e seus 
aplicativos e cargas de trabalho em contêineres na plataforma Kubernetes. 
Arquitetura de cluster do Kubernetes
Um cluster do Kubernetes consiste em um mestre de cluster e um ou mais nós, que são os 
trabalhadores do cluster. O mestre de cluster controla o cluster e pode ser replicado e 
distribuído para alta disponibilidade e tolerância a falhas. 
Introdução ao Kubernetes Motor 147 
O mestre conjunto administra os serviços prestados por Kubernetes, como o Kubernetes 
API, controladores e programadores. Todas as interações com o cluster são feitas através do 
mestre usando a API do Kubernetes. O mestre do cluster emite o comando que executa uma 
ação em um nó. Os usuários também podem interagir com um cluster usando o comando kubectl. 
Os nós executam as cargas de trabalho executadas no cluster. Nós são VMs que executam contêineres
configurado para executar um aplicativo. Os nós são controlados principalmente pelo mestre do cluster, mas 
alguns comandos podem ser executados manualmente. Os nós executam um agente chamado kubelet, que é o 
serviço que se comunica com o mestre do cluster. 
Ao criar um cluster, você pode especificar um tipo de máquina, cujo padrão é n1-standard-1 
com 1 vCPU e 3.75GB de memória. Essas VMs executam sistemas operacionais especializados 
otimizados para executar contêineres. Parte da memória e da CPU é reservada para o Kubernetes e, 
portanto, não está disponível para aplicativos em execução no nó. 
O Kubernetes organiza o processamento em cargas de trabalho. Existem vários objetos de organização 
que compõem a funcionalidade principal de como o Kubernetes processa as cargas de trabalho. 
Objetos do Kubernetes
As cargas de trabalho são distribuídas entre nós em um cluster do Kubernetes. Para entender como o trabalho é 
distribuído, é importante entender alguns conceitos básicos, especialmente os seguintes: 
■ Pods 
■ Serviços 
■ Volumes 
■ Namespaces 
Cada um desses objetos contribui para a organização lógica das cargas de trabalho. 
Pods 
Pods são instâncias únicas de um processo em execução em um cluster. Os pods contêm pelo menos um contêiner. 
Eles geralmente executam um único contêiner, mas podem executar vários contêineres. Vários contêineres são 
usados ​​quando dois ou mais contêineres precisam compartilhar recursos. Os pods também usam rede e 
armazenamento compartilhados em contêineres. Cada pod recebe um endereço IP exclusivo e um conjunto de portas. Recipientes
conectar-se a uma porta. Vários contêineres em um pod se conectam a diferentes portas e podem se comunicar em um 
host local. Essa estrutura é projetada para suportar a execução de uma instância de um aplicativo 
dentro do cluster como um pod. Um pod permite que seus contêineres se comportem como se estivessem sendo executados em uma 
VM isolada, compartilhando armazenamento comum, um endereço IP e um conjunto de portas. Ao fazer isso, você 
pode implementar várias instâncias do mesmo aplicativo ou instâncias diferentes de diferentes aplicativos no mesmo nó ou em diferentes nós, sem precisar alterar sua configuração. 
Os pods tratam os vários contêineres como uma única entidade para fins de gerenciamento. 
Os pods geralmente são criados em grupos. As réplicas são cópias de pods e constituem um grupo
de pods gerenciados como uma unidade. Os pods também suportam escalonamento automático. Vagens são consideradas 
efêmeras; isto é, espera-se que eles terminem. Se um pod não estiver íntegro, por exemplo, se 
estiver preso em um modo de espera ou travando repetidamente, ele será encerrado. O mecanismo que 
gerencia o dimensionamento e o monitoramento da integridade é conhecido como um controlador. 
Você pode perceber que os pods são semelhantes aos grupos de instâncias gerenciadas do Compute Engine. Uma 
diferença importante é que os pods são para executar aplicativos em contêineres e podem ser colocados em vários 
nós no cluster, enquanto todos os grupos de instâncias gerenciadas executam o mesmo código de aplicativo no 
cluster.
cada um dos nós. Além disso, você mesmo gerencia grupos de instâncias executando comandos 
no Cloud Console ou por meio da linha de comando. Os pods geralmente são gerenciados por um controlador. 
Serviços 
Como os pods são efêmeros e podem ser finalizados por um controlador, outros serviços que dependem de 
pods não devem ser fortemente acoplados a pods específicos. Por exemplo, mesmo que os pods tenham 
endereços IP exclusivos, os aplicativos não devem depender desse endereço IP para acessar um aplicativo. 
Se o pod com esse endereço for terminado e outro for criado, ele poderá ter outro 
endereço IP . O endereço IP pode ser atribuído novamente a outro pod que esteja executando um contêiner diferente. 
O Kubernetes fornece um nível de indireção entre aplicativos executados em pods e
outros aplicativos que os chamam: é chamado de serviço. Um serviço, na terminologia do Kubernetes, 
é um objeto que fornece pontos de extremidade da API com um endereço IP estável que permite que os aplicativos 
descubram os pods que executam um aplicativo específico. Os serviços são atualizados quando são feitas alterações 
nos pods, portanto, eles mantêm uma lista atualizada de pods executando um aplicativo. 
ReplicaSet 
A ReplicaSet é um controlador usado por uma implantação que garante o número correto 
de pods idênticos em execução. Por exemplo, se um pod for considerado não-íntegro, um controlador 
encerrará esse pod. O ReplicaSet detectará que não há pods suficientes para esse aplicativo 
ou carga de trabalho em execução e criará outro. Os ReplicaSets também são usados ​​para atualizar e
excluir pods. 
Implantação 
Outro conceito importante no Kubernetes é a implantação. Implantações são conjuntos de pods idênticos. Os membros do conjunto podem ser alterados à medida que alguns pods são finalizados e outros 
iniciados, mas todos executam o mesmo aplicativo. Todos os pods executam o mesmo aplicativo porque são criados usando o mesmo modelo de pod. 
Um modelo de pod é uma definição de como executar um pod. A descrição de como definir o 
pod é chamada de especificação de pod. O Kubernetes usa essa definição para manter um pod no estado 
especificado no modelo. Ou seja, se a especificação tiver um número mínimo de pods que 
devem estar na implantação e o número cair abaixo disso, os pods adicionais serão
adicionado à implantação chamando um ReplicaSet. 
As 
implementações do StatefulSet são adequadas para aplicativos sem estado. Essas são aplicações que não 
precisam acompanhar seu estado. Por exemplo, um aplicativo que chama uma API para executar um 
cálculo nos valores de entrada não precisa controlar as chamadas ou cálculos anteriores. 
Um aplicativo que chama essa API pode alcançar um pod diferente sempre que fizer uma chamada. 
Há momentos, no entanto, em que é vantajoso ter um único pod respondendo a todas as chamadas 
de um cliente durante uma única sessão. 
Os StatefulSets são como implantações, mas atribuem identificadores exclusivos a pods. Isso permite
Kubernetes para rastrear qual pod é usado por qual cliente e mantê-los juntos. StatefulSets 
são usados ​​quando um aplicativo precisa de um identificador de rede exclusivo ou armazenamento persistente estável. 
Implantando Kubernetes Clusters 149 
Job 
Um trabalho é uma abstração sobre uma carga de trabalho. Os trabalhos criam pods e os executam até que o aplicativo conclua uma carga de trabalho. As especificações do trabalho são especificadas em um arquivo de configuração e 
incluem especificações sobre o contêiner a ser usado e qual comando executar. 
Agora que você está familiarizado com a organização do Kubernetes e como as cargas de trabalho são executadas, 
abordaremos como implantar um cluster do Kubernetes usando o Kubernetes Engine. 
Implantando clusters do Kubernetes
Os clusters do Kubernetes podem ser implantados usando o Cloud Console, a linha de comando no 
Cloud Shell ou o ambiente local, se o Cloud SDK estiver instalado. 
Implantando clusters do Kubernetes usando o Cloud Console 
Para usar o Kubernetes Engine, você precisará ativar a API do Kubernetes Engine. Depois de 
ativar a API, você pode navegar para a página do Kubernetes Engine no Cloud Console. 
A Figura 7.1 mostra um exemplo da página Visão geral. 
Figura 7.1 A página Visão geral da seção Mecanismo do Kubernetes do Cloud Console 

150 Capítulo 7 ■ Computação com o Kubernetes 
Na primeira vez que você usa o Kubernetes Engine, pode ser necessário criar credenciais. Você pode 
fazer isso clicando no botão Criar Credenciais, na parte superior da página Visão Geral. Um formulário
como mostrado na Figura 7.2. Você pode especificar qual API está usando 
e depois gerar suas credenciais. 
Figura 7.2 A forma de criar credenciais necessárias para usar o Kubernetes Engine 
Depois de criar credenciais, se necessário, você pode criar um cluster. A Figura 7.3 mostra a primeira 
página na etapa de criação do cluster. 
F IGURA 7.3 A primeira forma para a criação de um cluster Kubernetes em nuvem Console 
Implantando Kubernetes Clusters 151 
Quando você clique em Criar Cluster, você será presenteado com a opção de escolher entre 
vários modelos, como mostrado na Figura 7.4. Os modelos variam no número de vCPUs, 
memória e uso de GPUs. Por exemplo, o modelo de cluster padrão usa três nós
com uma vCPU e 3,75 GB de memória, enquanto o modelo CPU Intensive usa quatro vCPUs 
e 3,6 GB de memória. 
Figura 7.4 Modelos para criar um cluster do Kubernetes 
Você pode modificar os parâmetros fornecidos no modelo. Por exemplo, se você deseja 
executar VMs em diferentes zonas para melhorar a disponibilidade, é possível especificar vários conjuntos de nós. 
Os pools de nós são grupos de instâncias em um cluster do Kubernetes. Eles são muito parecidos com um 
grupo de instâncias gerenciadas , mas não são iguais. 
152 Capítulo 7 ■ Computando com o Kubernetes 
Pode levar alguns minutos para criar um cluster. Quando o cluster é criado, ele aparecerá na 
lista de clusters, como na Figura 7.5. 
Figura 7.5 A listagem de cluster mostra o número de instâncias, núcleos totais e total
memória. 
A partir da listagem de clusters, você pode editar, excluir e conectar-se a um cluster. Ao 
clicar em Conectar, você recebe um comando gcloud para se conectar ao cluster a partir da 
linha de comando . Você também tem a opção de visualizar a página Cargas de Trabalho, conforme mostrado na Figura 7.6. 
Figura 7.6 Você pode se conectar ao cluster usando um comando gcloud na linha de 
comando ou visualizando a página Cargas de Trabalho. 
O Kubernetes executa várias cargas de trabalho para gerenciar o cluster. Você pode visualizar as 
cargas de trabalho em execução no momento na página Cargas de trabalho da seção Kubernetes Engine 
do Cloud Console. A Figura 7.7 mostra um subconjunto das cargas de trabalho em execução em um 
cluster recém- iniciado. 
Implantando clusters do Kubernetes 153
Figura 7.7 A página Cargas de Trabalho lista as cargas de trabalho atualmente em execução. 
Implantando clusters do Kubernetes usando o Cloud Shell e o 
Cloud SDK 
Assim como outros serviços do GCP, o Kubernetes Engine pode ser gerenciado usando a linha de comando. O 
comando básico para trabalhar com o Kubernetes Engine é o seguinte comando 
gcloud : gcloud beta container 
Observe que os comandos do Kubernetes Engine incluem a palavra beta. O Google indica um 
serviço que ainda não está em disponibilidade geral ao incluir a palavra alfa ou beta no 
comando gcloud. No momento em que você ler isso, o Kubernetes Engine poderá estar disponível 
em geral e, nesse caso, o termo beta não será mais usado. 
Este comando do gcloud tem muitos parâmetros, incluindo os seguintes:
■ Projeto 
■ Zona 
■ Tipo de máquina 
tipo ■ Imagem 
Tipo ■ Disk 
■ Disk tamanho 
■ Número de nós 
154 Capítulo 7 ■ Computing com Kubernetes 
Um comando básico para a criação de um cluster se parece com isso: 
clusters de recipiente gcloud criar CH07-fragmentação --num-nodes = 3 --region = us-central1 Os 
comandos para criar clusters podem se tornar bastante longos. Por exemplo, aqui está o comando para criar um cluster usando o modelo padrão: 
gcloud beta container --projecto "ferrous-depth-220417" clusters create 
"standard-cluster-2" --zone "us-central1-a" - nome de usuário "admin" 
--cluster-version "1.9.7-gke.6" --machine-type "n1-standard-1"
--image-type "COS" --disk-type "pd-standard" --disk-size "100" --scopes 
HttpLoadBalancing, KubernetesDashboard --able-autoupgrade --enable-autorepair 
Em vez de escrever este tipo de comando de scratch, você pode usar o Cloud Console para 
selecionar um modelo e, em seguida, usar a opção para gerar a linha de comando equivalente a partir do 
formulário Create Cluster. 
Implantando Pods de Aplicativo 
Agora que você criou um cluster, vamos implantar um aplicativo. 
Na página Cluster do Kubernetes Engine on Cloud Console, selecione Criar 
Implantação. Uma forma como a da Figura 7.8 aparece. Nesse formulário, você pode 
especificar o seguinte: 
■ Imagem do contêiner 
■ Variáveis ​​de ambiente 
■ Comando inicial
■ Nome do aplicativo 
■ Rótulos 
■ Namespace 
■ Cluster a ser implantado no 
Implantando pods de aplicativos 167 
F igure 7.8 A opção Criar Implantação fornece um formulário para especificar um contêiner a ser 
executado e um comando inicial para iniciar o aplicativo em execução. 
156 Capítulo 7 ■ Computando com o Kubernetes 
Depois de especificar uma implantação, você pode exibir a 
especificação YAML correspondente , que pode ser salva e usada para criar implantações a partir da linha de comando. 
A Figura 7.9 mostra um exemplo de arquivo YAML de implementação. A saída é sempre exibida no 
formato YAML. 
F igure 7.9 Especificação YAML para uma implantação do Kubernetes 
Além de instalar o Cloud SDK, você precisará instalar o Kubernetes
ferramenta de linha de comando kubectl para trabalhar com clusters a partir da linha de comando. Você pode fazer 
isso com o seguinte comando: 
gcloud components install kubectl 
Monitorando o Kubernetes 157 
  
 Se o Cloud SDK Manager estiver desabilitado, você poderá receber um erro ao 
executar o guboud components install kubectl. Se isso ocorrer, você 
poderá usar o gerenciador de componentes, seguindo as instruções em 

outro gerenciador de pacotes. Se você quiser usar o 
gerenciador de componentes , você pode instalá-lo usando um destes métodos: 

 Pacotes adicionais estão disponíveis em nossos repositórios deb e yum; todos os mesmos 
componentes estão disponíveis e você só precisa usar o 
gerenciador de pacotes existente para instalá-los.

 Você pode então usar o kubectl para executar uma imagem do Docker em um cluster usando o 
comando kubectl run . Aqui está um exemplo: 
 kubectl run ch07-app-deploy --image = ch07-app --port = 8080 
 Isso executará uma imagem do Docker chamada ch07-app e tornará sua rede acessível na porta 
8080. Se depois de algum tempo você quiser Para aumentar o número de réplicas na implantação, 
você pode usar o comando de 
 escala kubectl : implementação da escala kubectl ch07-app-deploy --replicas = 5 
 Este exemplo criaria cinco réplicas. 
Monitoramento O Kubernetes 
 Stackdriver é o abrangente produto de monitoramento, registro e alerta do GCP. Pode ser 
usado para monitorar clusters do Kubernetes.
 Ao criar um cluster, ative o monitoramento e o registro em log do Stackdriver selecionando Opções avançadas no formulário Criar cluster no Cloud Console. Em 
Recursos Adicionais , escolha Ativar Serviço de Registro em Log e Ative o Serviço de Monitoramento, conforme mostrado na 
Figura 7.10. 
158 Capítulo 7 ▪ Computar com o Kubernetes 
F igure 7.10 Ao expandir as Opções avançadas na caixa de diálogo Criar cluster, serão exibidas 
duas caixas de seleção para ativar o registro e o monitoramento do Stackdriver. 
Para configurar o Stackdriver no Cloud Console, selecione Stackdriver no menu de nível superior 
à esquerda. Inicialmente, você precisará criar um espaço de trabalho em seu projeto selecionando uma nova área de 
trabalho e iniciando o monitoramento quando solicitado (veja a Figura 7.11). Uma vez uma área de trabalho
é criado, você pode monitorar seus recursos do GCP, incluindo os clusters do Kubernetes. 
Os espaços de trabalho são recursos para monitoramento e podem suportar até 100 projetos monitorados. 
Os espaços de trabalho contêm painéis, políticas de alerta, definições de grupo e 
verificações de notificação . 
Figura 7.11 Uma caixa de diálogo inicial para criar um espaço de trabalho no Stackdriver 
Depois de criar um espaço de trabalho, abra o Stackdriver e ele exibe a 
página Visão Geral de Monitoramento , mostrada na Figura 7.12. 
Monitorando o Kubernetes 159 
F igure 7.12 Página Visão geral do Stackdriver Monitoring 
Na página Visão geral, clique em Recursos e selecione Instâncias para listar as instâncias no 
cluster. Isso exibe uma lista como na Figura 7.13.
Figura 7.13 Lista de instâncias em um cluster do 
Kubernetes 
Clique nos nomes de qualquer uma das instâncias para mostrar uma página detalhada de informações de monitoramento, como mostrado na Figura 7.14. 
Figura 7.14 Uma página de monitoramento detalhada típica de uma instância em execução em um 
cluster do Kubernetes 
Na página Detalhes, você pode visualizar uma visão geral dos detalhes sobre a instância e visualizar 
o uso da CPU, o E / S do disco e o tráfego da rede. Você também pode criar políticas de alerta para notificá-lo 
se alguma condição, como alta utilização da CPU, ocorrer na instância. Quando você cria 
alertas, eles podem ser aplicados a uma instância individual no cluster ou a todas as instâncias no 
cluster. 
Monitorando o Kubernetes 161
Na página detalhada do Stackdriver, crie um alerta clicando no botão Criar política de alerta 
. Isso exibe uma caixa de diálogo, como na Figura 7.15, a partir da qual você pode criar condições, 
notificações e documentação. Você também pode nomear a política. 
Figura 7.15 Ao criar uma política de alerta, este formulário permite que você especifique 
componentes da política. 
Quando você adiciona uma condição, um formulário como o mostrado na Figura 7.16 aparece. 
162 Capítulo 7 ■ Computing com o Kubernetes 
F igura 7.16 O Stackdriver suporta vários tipos de condição. 
Selecione Métrica Limite para exibir um formulário como a Figura 7.17, que mostra como especificar 
um alerta sobre a utilização da CPU acima de 80 por cento por 5 minutos. 
Monitorando o Kubernetes 163
Figura 7.17 As condições de limite da métrica do Stackdriver baseiam-se em um conjunto de 
recursos monitorados , como a utilização da CPU. 
O Stackdriver precisará saber como notificá-lo se um alerta for acionado. Você pode especificar 
sua escolha de canais de notificação no formulário Criar Nova Política de Alerta, conforme mostrado na 
Figura 7.18. Os canais incluem email, webhooks e mensagens de texto SMS, bem como ferramentas de terceiros, como PagerDuty, Campfire e Slack. 
O Stackdriver também oferece suporte a alertas mais avançados, incluindo integridade do processo, 
verificações de tempo de atividade , limites agregados de grupos e taxas de mudança de métricas. 
Vamos percorrer um exemplo de criação de uma política para monitorar a utilização da CPU. 
164 Capítulo 7 ■ Computando com o Kubernetes
 figura 7.18 O Stackdriver suporta vários tipos de condição. 
 
 Para obter mais detalhes sobre monitoramento, consulte o Capítulo 18. Para criar uma política para monitorar a utilização da CPU, navegue até a página de monitoramento no Stackdriver e 
clique em Criar Política. Isso exibirá o formulário para criar uma política, que é um 
processo de quatro etapas: criar uma condição, especificar um canal de notificação, adicionar uma 
descrição e nomear a política. (Consulte a Figura 7.19.) 
Monitorando o Kubernetes 165 
F igure 7.19 Criando uma política para monitorar a utilização da CPU 
166 Capítulo 7 ■ Computando com Kubernetes 
Clique em Add Condition para exibir um formulário como o mostrado na Figura 7.20. 
Figura 7.20 Adicionando uma condição a uma política
No parâmetro Filter, insira Contêiner GKE e Uso da CPU. Na 
seção Configuração , especifique 80 por cento como o limite e 2 minutos como o período de tempo. Salve a 
condição. Isso retornará ao formulário Criar Política. No parâmetro Notification, selecione 
Email na lista suspensa, como mostra a Figura 7.21. 
Monitorando o Kubernetes 167 
F igura 7.21 Escolhendo um canal de notificação 
Adicione uma descrição e um nome de política, como mostra a Figura 7.22. 
Figura 7.22 Um formulário de criação de política preenchido 
168 Capítulo 7 ■ Computação com Kubernetes 
Salve a especificação de política para exibir um resumo de monitoramento, conforme mostrado na Figura 7.23. 
Figura 7.23 Monitorando os resultados da política sobre o uso da CPU 
Resumo
O Kubernetes Engine é um sistema de orquestração de contêiner para implantar aplicativos para serem executados em 
clusters. O Kubernetes é arquitetado com um único gerenciador de cluster e nós de trabalho. 
O Kubernetes usa o conceito de pods que são instâncias executando um contêiner. É possível 
executar vários contêineres em um pod, mas isso ocorre com menos frequência do que os conjuntos de contêiner único 
. Os ReplicaSets são controladores para garantir que o número correto de pods esteja em execução. 
Implantações são conjuntos de pods idênticos. StatefulSets são um tipo de implantação usado para 
aplicativos com estado. 
Os clusters do Kubernetes podem ser implantados por meio do Cloud Console ou usando comandos do gcloud. 
Você implanta aplicativos agrupando o aplicativo em um contêiner e usando o console ou
o comando kubectl para criar uma implementação que executa o aplicativo no cluster. 
O Stackdriver é usado para monitorar instâncias em clusters. Você pode criar alertas e receber 
notificações em vários canais. 
Fundamentos do exame 
Entenda que o Kubernetes é um sistema de orquestração de contêineres. O Kubernetes Engine é um 
produto do GCP que fornece Kubernetes aos clientes do GCP. O Kubernetes gerencia contêineres 
executados em um conjunto de instâncias de VM. 
Fundamentos do exame 169 
Entenda que o Kubernetes usa um único mestre de cluster que controla nós que executam 
cargas de trabalho. O Kubernetes usa o mestre para coordenar a execução e monitorar a integridade de
vagens. Se houver um problema com um pod, o mestre pode corrigir o problema e reprogramar 
o trabalho interrompido. 
Ser capaz de descrever pods. Pods são instâncias únicas de um processo em execução, os serviços fornecem 
um nível de indireção entre pods e clientes chamando serviços nos pods, um ReplicaSet 
é um tipo de controlador que garante que o número correto de pods esteja em execução e uma 
implementação é um conjunto de pods vagens idênticas. 
Os Kubernetes podem ser implantados usando o Cloud Console ou usando comandos gcloud. Os 
comandos do gcloud manipulam o serviço do Kubernetes Engine, enquanto os comandos do kubectl são usados 
para gerenciar o estado interno dos clusters a partir da linha de comando. O comando base para
Trabalhar com o Kubernetes Engine é gcloud container. Observe que o gcloud e o kubectl possuem 
diferentes sintaxes de comando. Os comandos kubectl especificam um verbo e, em seguida, um recurso, como na 
implementação da escala kubectl ..., enquanto gcloud especifica um recurso antes do verbo, como nos 
clusters de contêiner gcloud, criar. Implantações são criadas usando o Cloud Console ou na 
linha de comando usando uma especificação YAML. 
Implantações são conjuntos de pods idênticos. StatefulSets são um tipo de implantação usado para 
aplicativos com estado. O Kubernetes é monitorado usando o Stackdriver. O Stackdriver pode ser 
configurado para gerar alertas e notificá-lo em vários canais. Para monitorar o estado
de um cluster, você pode criar uma política que monitora uma métrica, como a utilização da CPU, e 
envia notificações para o e-mail ou outros canais. 
170 Capítulo 7 Computando com o Kubernetes 
Este capítulo descreve como executar tarefas básicas de gerenciamento do Kubernetes, incluindo as seguintes: 
■ Visualização do status dos clusters do Kubernetes 
■ Visualização de repositórios de imagem e detalhes da imagem 
■ Adição, modificação e remoção de nós 
■ Adição, modificação e removendo pods 
■ Adicionando, modificando e removendo serviços 
Você verá como realizar cada uma dessas tarefas usando o Google Cloud Console e o Cloud 
SDK, que você pode usar localmente em suas máquinas de desenvolvimento, em máquinas virtuais do GCP 
e usando o Cloud Shell.
Visualizando o status de um 
cluster do Kubernetes 
Supondo que você criou um cluster usando as etapas descritas no Capítulo 7, você pode visualizar o 
status de um cluster do Kubernetes usando o Google Cloud Console ou os comandos do gcloud. 
Visualizando o status dos clusters do Kubernetes Usando o 
Cloud Console 
A partir da página inicial do Cloud Console, abra o menu de navegação clicando no 
ícone de três linhas empilhadas no canto superior esquerdo. Isso exibe a lista de serviços do GCP, conforme 
mostrado na Figura 8.1. 
Visualizando o status de um cluster do Kubernetes 177 
Figura 8.1 Menu de navegação no Console do Google Cloud 
Selecione o Kubernetes Engine nas listas de serviços, como mostra a Figura 8.2.
Figura 8.2 Selecionando o Kubernetes Engine no menu de navegação 
180 Capítulo 8 ■ Gerenciando clusters do Kubernetes 
Fixando serviços na parte superior do menu de navegação 
Na Figura 8.2, o Kubernetes Engine foi “fixado”, de forma que é exibido na parte superior. Você pode 
fixar qualquer serviço no menu de navegação passando o mouse sobre o produto e clicando no 
ícone de alfinete que aparece, como na Figura 8.3. Nessa figura, o Compute Engine e o Kubernetes Engine 
já estão fixados e as Cloud Functions podem ser fixadas clicando no ícone de alfinete cinza. 
Figura 8.3 Fixando um serviço no topo do menu de navegação 
Após clicar no Kubernetes Engine no menu de navegação, você verá uma lista de
clusters, como na Figura 8.4, que mostra um único cluster chamado cluster padrão-1. 
Figura 8.4 Exemplo de lista de clusters no Kubernetes Engine 
Passe o mouse sobre o nome do cluster para destacá-lo, como na Figura 8.5, e clique no nome 
para exibir os detalhes do cluster, como na Figura 8.6. 
Figura 8.5 Clique no nome de um cluster para exibir seus detalhes. 
Visualizando o status de um cluster do Kubernetes 179 
Figura 8.6 A primeira parte da página Detalhes do cluster descreve a configuração do 
cluster. 
Clicar nos links Complementos e Permissões exibe informações como as mostradas na 
Figura 8.7. A seção Complementos exibe o status dos recursos complementares opcionais de um cluster.
A seção Permissões mostra quais APIs de serviço do GCP estão ativadas para o cluster. 
180 Capítulo 8 ■ Gerenciamento de clusters do Kubernetes 
F igure 8.7 Detalhes de complemento e permissão para um cluster A 
Figura 8.8 mostra detalhes de exemplo de pools de nós, que são grupos de instâncias separadas em execução em um cluster do Kubernetes. Os detalhes nesta seção incluem a imagem do nó 
em execução nos nós, o tipo de máquina, o número total de vCPUs (listado como Núcleos Totais), o 
tipo de disco e se os nós são preemptivos. 
Abaixo do nome do cluster, há uma lista horizontal de três opções: Detalhes, Armazenamento e 
Nós. Até agora, descrevemos o conteúdo da página Detalhes. Clique em Armazenamento para exibir
informações como na Figura 8.9, que exibe volumes persistentes e as classes de armazenamento 
usadas pelo cluster. 
Este cluster não possui volumes persistentes, mas usa armazenamento padrão. Volumes persistentes são discos duráveis ​​gerenciados pelo Kubernetes e implementados usando 
discos permanentes do Compute Engine. Uma classe de armazenamento é um tipo de armazenamento com um conjunto de políticas que especifica a 
qualidade do serviço, a política de backup e um provisionador (que é um serviço que implementa o 
armazenamento). 
Visualizando o status de um cluster do Kubernetes 181 
Figura 8.8 Detalhes sobre os pools de nós no cluster 
F igura 8.9 Informações de armazenamento sobre um cluster 
182 Capítulo 8 ■ Gerenciando clusters do Kubernetes
Na opção Nós do menu de status do cluster, você pode ver uma lista de nós ou VMs 
em execução no cluster, conforme mostrado na Figura 8.10. A lista de nós mostra 
informações básicas de configuração . 
Figura 8.10 Listagem de nós no cluster 
Clique no nome de um dos nós para ver informações detalhadas sobre o status, como na 
Figura 8.11. Os detalhes do nó incluem utilização da CPU, consumo de memória e IO de disco. 
Há também uma lista de pods em execução no nó. 
Figura 8.11 Exemplo de detalhes de um nó em execução em um cluster 
do Kubernetes 183 
Clique no nome de um pod para ver seus detalhes. A exibição do pod é semelhante à exibição do nó
com estatísticas de CPU, memória e disco. Os detalhes da configuração incluem quando o pod foi criado, os rótulos atribuídos, os links para os logs e o status (que é mostrado como em execução na Figura 8.12). 
Outros status possíveis são pendentes, o que indica que o pod está baixando imagens; 
Sucedido, o que indica que o pod terminou com sucesso; Falhou, o que indica que pelo menos 
um contêiner falhou; e Desconhecido, o que significa que o mestre não pode alcançar o nó e o 
status não pode ser determinado. 
F igure 8.12 Exibição do status do pod, com status como 
Em execução Na parte inferior da exibição do pod, há uma lista de containers em execução. Clique no nome de um 
contêiner para ver seus detalhes. A Figura 8.13 mostra os detalhes do container chamado
evento-exportador. As informações incluem o status, a hora de início, o comando em 
execução e os volumes montados. 
184 Capítulo 8 ■ Gerenciando clusters do Kubernetes 
F igure 8.13 Detalhes de um contêiner em execução em um pod 
Usando o Cloud Console, você pode listar todos os clusters e exibir detalhes de suas configurações e 
status. Você pode então detalhar cada nó, pod e contêiner para visualizar seus detalhes. 
Visualizando o status dos clusters do Kubernetes Usando o Cloud 
SDK e o Cloud Shell 
Você também pode usar a linha de comando para visualizar o status de um cluster. O 
comando da lista de clusters do contêiner gcloud é usado para mostrar esses detalhes. 
Para listar os nomes e informações básicas de todos os clusters, use este comando:
gcloud container clusters list 
Produz a saída mostrada na Figura 8.14. 
Figura 8.14 Exemplo de saída do comando gcloud container clusters list 
Exibindo o status de um cluster do Kubernetes 185 
Por que os comandos não começam com gcloud kubernetes? 
Os comandos gcloud começam com a palavra gcloud seguida do nome do serviço, por 
exemplo, gcloud compute para comandos do Compute Engine e gcloud sql para 
comandos do Cloud SQL. Você pode esperar que os comandos do Kubernetes Engine iniciem com 
gcloud kubernetes, mas o serviço era originalmente chamado de Google Container Engine. 
Em novembro de 2017, o Google renomeou o serviço Kubernetes Engine, mas os 
comandos do gcloud continuaram os mesmos.
Para visualizar os detalhes de um cluster, use o comando gcloud container clusters describe. Você precisará passar o nome de uma zona ou região usando o 
parâmetro --zone ou --region . Por exemplo, para descrever um cluster chamado cluster padrão-1 localizado na zona 
us-central1-a, você usaria este comando: 
gcloud container clusters describe --zone us-central1-a-cluster-padrão-1 
Isso exibirá detalhes como os mostrados na Figura 8.15 e na Figura 8.16. Observe que 
o comando describe também exibe informações de autenticação, como certificado de cliente, 
nome de usuário e senha. Essa informação não é mostrada nas figuras. 
Figura 8.15 A parte 1 das informações exibidas pelos agrupamentos de contêineres do gcloud 
descreve o comando
186 Capítulo 8 ■ Gerenciamento de clusters do 
Kubernetes Figura 8.16 A parte 2 das informações exibidas pelos agrupamentos de contêiner do gcloud 
descreve o comando 
Para listar informações sobre nós e pods, use o comando kubectl. 
Primeiro, você precisa garantir que tenha um arquivo kubeconfig configurado corretamente, que 
contém informações sobre como se comunicar com a API do cluster. Execute o comando 
gcloud container clusters get-credentials com o nome de uma zona ou região e o 
nome de um cluster. Veja um exemplo: 
gcloud container clusters get-credenciais --zone us-central1-a-padrão-cluster-1 
Isso configurará o arquivo kubeconfig em um cluster denominado standard-cluster-1 no
use-central1-a zone. A Figura 8.17 mostra um exemplo de saída desse comando, que 
inclui o status de obtenção e configuração de dados de autenticação. 
Ver o estado de um Kubernetes cluster 187 
F igura 8,17 Exemplo de saída dos get-credenciais comando 
Pode listar os nós de um cluster usando o seguinte: 
 kubectl obter nodos 
Isto produz uma saída, tal como na Figura 8.18, o qual mostra o estado de três nós . 
Figura 8.18 Exemplo de saída do comando kubectl get nodes 
Da mesma forma, para listar pods, use o seguinte comando: 
kubectl get pods 
Produz saída, como na Figura 8.19, que lista pods e seu status. 
Figura 8.19 Exemplo de saída do comando kubectl get pods
188 Capítulo 8 ■ Gerir Kubernetes Clusters 
Para mais detalhes sobre os nós e vagens, utilizar estes comandos: 
kubectl descrever nodos 
kubectl descrever vagens 
Figuras 8,20 e 8,21 mostrar anúncios parciais dos resultados. Observe que o 
comando kubectl describe pods também inclui informações sobre contêineres, como nome, rótulos, 
condições, endereços de rede e informações do sistema. 
Figura 8.20 Lista parcial dos detalhes mostrados pelo 
comando kubectl describe nodes 
Visualizando o Status de um Kubernetes Cluster 191 
Figura 8.21 Listagem parcial dos detalhes mostrados pelo 
comando kubectl describe pods
Para visualizar o status de clusters a partir da linha de comando, use os comandos do contêiner gcloud, mas para obter informações sobre objetos gerenciados do Kubernetes, como nós, pods e 
contêineres, use o comando kubectl. 
190 Capítulo 8 ■ Gerenciando clusters Kubernetes 
Adicionando, modificando e removendo 
nós 
Você pode adicionar, modificar e remover nós de um cluster usando o Cloud Console ou o Cloud 
SDK em seu ambiente local, em uma máquina virtual GCP ou no Cloud Shell. 
Adicionando, modificando e removendo nós com o 
Cloud Console No 
Cloud Console, navegue até a página do Kubernetes Engine e exiba uma lista de clusters. 
Clique no nome de um cluster para exibir seus detalhes, como na Figura 8.22. Observe a opção Editar
perto do topo da tela. Clique para abrir um formulário de edição. 
Figura 8.22 Detalhes de um cluster no Cloud Console 
Role para baixo até a seção Node Pools, que lista o nome, tamanho, imagem do nó, 
tipo de máquina e outras informações sobre o cluster. O parâmetro de tamanho é opcional. No exemplo mostrado na Figura 8.23, o cluster possui três nós. 
Figura 8.23 ​​Detalhes de um pool de nós no Cloud Console 
Adicionando, modificando e removendo nós 191 
Para adicionar nós, aumente o tamanho para o número de nós que você deseja. Para remover os nós, 
diminua o tamanho para o número de nós que você gostaria de ter. 
Adicionando, modificando e removendo com o Cloud SDK e o 
Cloud Shell
O comando para adicionar ou modificar nós é o redimensionamento dos clusters de contêiner gcloud. O comando usa três parâmetros, conforme mostrado aqui: 
■ nome do cluster ■ nome do 
pool de nós 
■ tamanho do cluster 
Por exemplo, suponha que você tenha um cluster denominado cluster padrão 1, executando um 
pool de nós chamado pool padrão. Para aumentar o tamanho do cluster de 3 para 5, use este comando: 
gcloud container clusters resize standard-cluster-1 --node-pool default-pool 
--size 5 --region = us-central1 
Depois que um cluster for criado , você pode modificá-lo usando o comando gcloud container clusters 
update. Por exemplo, para ativar o escalonamento automático, use o comando update para especificar 
o número máximo e mínimo de nós. O comando para atualizar um cluster chamado
O cluster padrão 1 em execução em um pool de nós denominado pool padrão é o seguinte: 
gcloud cluster clusters atualização standard-cluster-1 --enable-autoscaling 
--min-nodes 1 \ 
--max-nodes 5 --zone us- central1-a --node-pool pool padrão 
Mantendo a demanda com escalonamento automático 
Frequentemente, é difícil prever a demanda em um serviço. Mesmo se houver padrões regulares, 
como grandes trabalhos em lote executados durante horários não comerciais, pode haver variação quando esses 
picos de carga forem executados. Em vez de continuar alterando manualmente o número de vCPUs em um cluster, 
ative o escalonamento automático para adicionar ou remover automaticamente nós, conforme necessário, com base na demanda. 
O escalonamento automático pode ser ativado ao criar clusters com o Cloud Console ou o gcloud.
Essa abordagem é mais resistente a picos inesperados e mudanças nos padrões de longo prazo de 
pico de uso. Isso também ajudará a otimizar o custo de seu cluster, não executando muitos servidores quando não for necessário. Ele também ajudará a manter o desempenho por ter nós suficientes para 
atender à demanda. 
192 Capítulo 8 ■ Gerenciando clusters Kubernetes 
Adicionando, modificando e 
removendo pods 
Você pode adicionar, modificar e remover pods de um cluster usando o Cloud Console ou o 
Cloud SDK em seu ambiente local, em uma VM do GCP ou no Cloud Shell. 
Considera-se uma prática recomendada não manipular os pods diretamente. O Kubernetes manterá 
o número de pods especificados para uma implantação. Se você gostaria de mudar o número de
pods, você deve alterar a configuração de implantação. 
Adicionar, modificar e remover pods com o 
Cloud Console 
Pods é gerenciado por meio de implantações. Uma implantação inclui um parâmetro de configuração 
chamado réplicas, que é o número de pods que executam o aplicativo especificado na 
implantação. Esta seção descreve como usar o Cloud Console para alterar o número de 
réplicas, o que, por sua vez, altera o número de pods. 
No Cloud Console, selecione as opções Cargas de trabalho no menu de navegação à esquerda. 
Isso exibe uma lista de implementações, como na Figura 8.24. 
Figura 8.24 Lista de implementações em um cluster 
Clique no nome da implantação que você deseja modificar; um formulário é exibido com detalhes
como na Figura 8.25. Observe a opção Ações no menu horizontal superior. 
Adicionando, modificando e removendo pods 193 
F igure 8.25 Vários formulários contêm detalhes de uma implantação e incluem um menu de 
ações que você pode executar na implantação. 
Clique em Ações para listar as opções, que são Autoscale, Expose, Rolling Update e 
Scale, conforme mostrado na Figura 8.26. 
Figura 8.26 Lista de ações disponíveis para implantações 
Selecione Escala para exibir uma caixa de diálogo que permite definir um novo tamanho para a carga de trabalho, conforme 
mostrado na Figura 8.27. Neste exemplo, o número de réplicas foi alterado para 2. 
Figura 8.27 Defina o número de réplicas para uma implantação.
Você também pode fazer com que o Kubernetes adicione e remova automaticamente réplicas (e pods), dependendo da necessidade, especificando o escalonamento automático. Escolha Escalonamento automático no menu para exibir o 
formulário mostrado na Figura 8.28. Você pode especificar um número mínimo e máximo de réplicas 
para execução aqui. 
194 Capítulo 8 ■ Gerenciamento de clusters do Kubernetes 
F igura 8.28 Habilite o escalonamento automático para adicionar e remover automaticamente as réplicas conforme necessário, 
dependendo da carga. 
O menu Action também fornece opções para expor um serviço em uma porta, conforme mostrado na 
Figura 8.29, e para especificar parâmetros para controlar atualizações contínuas no código implementado, conforme 
mostrado na Figura 8.30. Os parâmetros incluem o mínimo de segundos para aguardar antes
considerando o pod atualizado, o número máximo de pods acima do tamanho desejado permitido e 
o número máximo de pods não disponíveis. 
Figura 8.29 Formulário para expor serviços em execução em pods 
Adicionando, modificando e removendo pods 195 
Formulário do F igure 8.30 para especificar parâmetros para atualizações contínuas de código em execução em pods 
Adicionando, modificando e removendo pods com o Cloud SDK 
e o Cloud Shell 
Trabalhando com pods em O Cloud SDK e o Cloud Shell são feitos trabalhando com implantações; 
As implantações foram explicadas anteriormente na seção "Adicionando, modificando e removendo pods 
com o Cloud Console". Você pode usar o comando kubectl para trabalhar com implantações. 
Para listar implantações, use o seguinte comando: 
kubectl get deployments
Isso produzirá uma lista de implementações, como na Figura 8.31. 
Figura 8.31 Uma lista de implementações na linha de comando 
Para adicionar e remover pods, altere a configuração das implantações usando o 
comando kubectl scale deployment. Para este comando, você tem que especificar o nome da implementação 
196 Capítulo 8 ■ Gerenciando Kubernetes Clusters 
e número de réplicas. Por exemplo, para definir o número de réplicas como 5 para uma implantação 
denominada nginx-1, use: 
kubectl scale deployment nginx-1 --replicas 5 
Para que o Kubernetes gerencie o número de pods com base na carga, use o comando de autoescala. O comando a seguir adicionará ou removerá os conjuntos conforme necessário para atender à demanda
na utilização da CPU. Se o uso da CPU exceder 80%, até 10 pods ou réplicas 
adicionais serão adicionados. A implantação sempre terá pelo menos um pod ou réplica. 
kubectl implantação autoescala nginx-1 --max 10 --min 1 --cpu-porc 80 
Para remover uma implantação, use o comando delete deployment da seguinte forma: 
kubectl delete deployment nginx-1 
Adicionando, modificando e removendo serviços 
Você pode adicionar, modificar e remover serviços de um cluster usando o Cloud Console ou o 
Cloud SDK em seu ambiente local, em uma VM do GCP ou no Cloud Shell. 
Um serviço é uma abstração que agrupa um conjunto de conjuntos como um único recurso. 
Adicionando, modificando e removendo serviços com o 
Cloud Console
Os serviços são adicionados por meio de implantações. No Cloud Console, selecione a opção Cargas de trabalho 
no menu de navegação para exibir uma lista de implantações, como na Figura 8.32. Observe a 
opção Implantar no menu horizontal na parte superior da página. 
Figura 8.32 Lista de implementações junto com um comando Implantar para criar novos serviços 
Adicionando, modificando e removendo serviços 197 
Clique em Implantar para mostrar o formulário de implantação, como na Figura 8.33. 
Figura 8.33 Formulário para especificar uma nova implantação para um serviço 
No parâmetro Imagem do Contêiner, você pode especificar o nome de uma imagem ou selecionar uma 
do Repositório de Contêineres do Google. Para especificar um nome diretamente, especifique um caminho para a 
imagem usando um URL como este:
gcr.io/google-samples/hello-app:2.0 
Você pode especificar rótulos, o comando inicial a ser executado e um nome para seu aplicativo. 
Quando você clica no nome de uma implementação, como as listadas anteriormente na Figura 8.32, 
você verá detalhes dessa implementação, incluindo uma lista de serviços, como a mostrada na 
Figura 8.34. 
198 Capítulo 8 ■ Gerenciando Kubernetes Clusters 
Figura 8.34 Detalhes de um serviço em execução em uma implantação 
Clicar no nome de um serviço abre o formulário Detalhe do serviço, que inclui uma 
opção Excluir no menu horizontal, conforme mostrado na Figura 8.35. 
Figura 8.35 Navegue até a página Detalhes do serviço para excluir um serviço usando a 
opção Excluir no menu horizontal.
Adicionando, modificando e removendo serviços com o Cloud 
SDK e o Cloud Shell 
Use o comando kubectl get services para listar serviços. A Figura 8.36 mostra uma 
listagem de exemplo . 
Figura 8.36 Uma lista de serviços exibidos por um comando kubectl get services 
Visualizando o Repositório de Imagens e Detalhes da Imagem 199 
Para adicionar um serviço, use o comando kubectl run para iniciar um serviço. Por exemplo, para incluir 
um serviço chamado hello-server usando o aplicativo de amostra com o mesmo nome fornecido 
Google, use the following command:
kubectl run hello-server --image=gcr.io/google/samples/hello-app:1.0 --port 8080
This command will download and start running the image found at the path gcr.io/
google-samples/ called hello-app, version 1. It will be accessible on port 8080. Services
need to be exposed to be accessible to resources outside the cluster. This can be set using
the expose command, as shown here:
kubectl expose deployment hello-server --type="LoadBalancer"
This command exposes the services by having a load balancer act as the endpoint for
outside resources to contact the service.
To remove a service, use the delete service command, as shown here:
kubectl delete service hello-server
Visualizando o Repositório de 
Imagens e o 
Registro de Contêiner de Detalhes da Imagem é um serviço GCP para armazenar imagens de contêiner. Depois de criar um 
registro e enviar imagens para ele, você poderá visualizar o conteúdo do registro e os detalhes da imagem.
usando o Cloud Console, o Cloud SDK e o Cloud Shell. 
Visualizando o repositório de imagens e os detalhes da imagem com o 
Cloud Console 
No Cloud Console, selecione Registro de contêineres no menu de navegação para exibir o 
conteúdo de um registro. A Figura 8.37 mostra uma listagem de exemplo com três imagens para Nginx, 
Redis e WordPress. 
200 Chapter 8 ■ Managing Kubernetes Clusters
F igure 8.37 A listing of images in a Container Registry
To see the details of an image, click the image name. For example, Figure 8.38 shows
a listing for the Nginx image. This listing will list one entry for each version of the image.
Since there is only one version of the image, there is only one listed.
F igure 8.38 A list of versions for an image
To see the details of that version, click the version name. This displays a listing such as
in Figure 8.39, which includes the image type, size, and time created.
Viewing the Image Repository and Image Details 201
F igure 8.39 Details of a version of an image
202 Chapter 8 ■ Managing Kubernetes Clusters
Viewing the Image Repository and Image Details with
Cloud SDK and Cloud Shell
From the command line, you work with images in a registry using
gcloud container images commands. For example, to list the contents of a
registry, use this:
gcloud container images list
Esse comando produz uma lista de imagens, como na Figura 8.40. Você também pode listar 
contêineres do Google usando a lista de imagens do contêiner gcloud --repository gcr.io/ 
google-containers. 
F igure 8.40 List of images in a container repository
To view the details of an image, use the describe command and pass in the name of the
image as an argument. For example, the following command:
gcloud container images describe gcr.io/appengflex-project-1/nginx
will produce an output list such as that shown in Figure 8.41. You can also describe a
Google image with a command such as gcloud container images describe gcr.io/
google-containers/toolbox.
F igure 8.41 A listing of image details produced by the describe image command
Kubernetes Engine makes use of container images stored in a Container Repository. The
contents of the Container Repository can be viewed in summary and in detail using both
O Cloud Console e o Cloud SDK de linha de comando, inclusive no Cloud Shell. 
Fundamentos do exame 203 
Resumo 
Neste capítulo, você aprendeu a executar tarefas básicas de gerenciamento para trabalhar com
Kubernetes clusters, nós, pods e serviços. O capítulo também descreveu como listar o 
conteúdo dos repositórios de imagens de contêiner. Você aprendeu como fixar serviços no 
menu do Cloud Console, ver o status dos clusters do Kubernetes e visualizar os 
detalhes do repositório de imagens e da imagem usando os comandos do gcloud. Este capítulo também descreveu como modificar e remover 
nós e pods. Você também viu os benefícios do escalonamento automático em um cenário do mundo real. 
O Cloud Console e o Cloud SDK, incluindo o Cloud Shell, podem ser usados ​​para adicionar, remover 
e modificar nós, pods e serviços. Ambos podem ser usados ​​para revisar o conteúdo de um 
repositório de imagens. Alguns dos comandos mais úteis incluem clusters de contêiner gcloud
crie e gcloud clusters de contêiner redimensionar. O comando kubectl é usado para 
modificar recursos do Kubernetes, como implantações e pods. 
Fundamentos do Exame 
Saiba como visualizar o status de um cluster do Kubernetes. Use o Cloud Console para listar clusters 
e detalhar os clusters para ver os detalhes do cluster, incluindo os detalhes do nó, do pod e do contêiner 
. Conheça o comando gcloud container clusters e suas opções. 
Entenda como adicionar, modificar e remover nós. Use o Cloud Console para modificar os nós 
e saber como adicionar e remover nós, alterando as implantações. Use o comando de redimensionamento de clusters de contêiner do gcloud para adicionar e remover nós. 
Entenda como adicionar, modificar e remover pods. Use o Cloud Console para modificar os pods
e adicionar e remover pods alterando as implantações. Use o kubectl para obter implementações para 
listar implantações, implementação em escala kubectl para modificar o número de implementações e 
implementação em escala automática kubectl para habilitar escalonamento automático. 
Entenda como adicionar, modificar e remover serviços. Use o Cloud Console para modificar 
serviços e adicionar e remover serviços alterando as implantações. Use o kubectl run para iniciar os 
serviços e o kubectl exponha a implementação para tornar um serviço acessível fora do cluster. 
Exclua um serviço usando o comando kubectl delete service. 
Saiba como visualizar as imagens do Container Registry e seus detalhes. Navegue pelas 
páginas do Registro de contêiner no Cloud Console. Conheça a lista de imagens do contêiner gcloud e gcloud
imagens de contêiner descrevem comandos. 
204 Capítulo 8 ■ Gerenciando clusters do Kubernetes 

Este capítulo descreve como implantar aplicativos padrão do App Engine 
. Começamos revisando a estrutura de um aplicativo do App 
Engine e, em seguida, examinamos como especificar uma configuração de aplicativo. Em seguida, direcionaremos nossa atenção para o 
ajuste de aplicativos do App Engine por meio de escalonamento e divisão de tráfego. Também discutimos as 
versões do aplicativo do Google App Engine ao longo do caminho. 
O Google App Engine foi originalmente projetado para executar aplicativos em 
ambientes específicos de idioma . Desde a introdução do App Engine, o Google introduziu o App Engine 
Flexible, que pode ser usado para implantar tempos de execução personalizados em contêineres. Este capítulo descreve
como implantar aplicativos no ambiente original do App Engine, conhecido como 
padrão do Google App Engine . 
App Engine Components 
App Engine Os aplicativos padrão consistem em quatro componentes: 
■ Aplicativo 
■ Serviço 
■ Versão 
■ Instância 
Um aplicativo do App Engine é um recurso de alto nível criado em um projeto; ou seja, cada 
projeto pode ter um aplicativo do App Engine. Todos os recursos associados a um aplicativo do 
Google App Engine são criados na região especificada quando o aplicativo é criado. 
Os aplicativos têm pelo menos um serviço, que é o código executado no ambiente do App Engine. Como várias versões da base de código de um aplicativo podem existir, o App Engine
suporta a versão de aplicativos. Um serviço pode ter várias versões, e elas geralmente são 
um pouco diferentes, com versões mais recentes incorporando novos recursos, correções de bugs e outras 
alterações relativas a versões anteriores. Quando uma versão é executada, ela cria uma instância do 
aplicativo. 
Os serviços são tipicamente estruturados para executar uma única função com aplicativos complexos 
compostos de vários serviços, conhecidos como microsserviços. Um microsserviço pode manipular 
solicitações de API para acesso a dados, enquanto outro microsserviço realiza autenticação e um terceiro 
registra dados para fins de faturamento. 
Implantando um aplicativo do App Engine 211 Os 
serviços são definidos pelo código-fonte e pelo arquivo de configuração. A combinação
desses arquivos constitui uma versão do aplicativo. Se você alterar um pouco o código-fonte ou o arquivo de configuração, ele cria outra versão. Dessa maneira, você pode manter várias versões de 
seu aplicativo de uma só vez, o que é especialmente útil para testar novos recursos em um pequeno 
número de usuários antes de distribuir a alteração para todos os usuários. Se ocorrerem erros ou outros problemas 
com uma versão, você poderá reverter facilmente para uma versão anterior. Outra vantagem de manter 
várias versões é permitir que você migre e divida o tráfego, o que descreveremos em 
mais detalhes posteriormente no capítulo. 
Implantando um aplicativo do 
Google App Engine O exame de certificação do Google Eng. Cloud Engineer não exige que os engenheiros escrevam
um aplicativo, mas espera-se que saibamos como implantar um. Nesta seção, você fará o 
download de um exemplo Hello World do Google e o usará como um aplicativo de amostra que 
será implantado. O aplicativo é escrito em Python, portanto, você usará o tempo de execução do Python no App Engine. 
Implantando um aplicativo usando o Cloud Shell e o SDK 
Primeiro, você trabalhará em uma janela de terminal usando o Cloud Shell, que pode ser iniciado a partir 
do console, clicando no ícone do Cloud Shell. Certifique-se de que o gcloud esteja configurado para funcionar com o Google 
App Engine usando o seguinte comando: 
gcloud components instalar app-engine-python 
Figurar 9.1 A hierarquia de componentes dos aplicativos do App Engine 
Instância de 
versão do 
serviço de 
aplicativo
Versão Versão Versão Versão Versão 
Serviço 
Instância Instância Instância Instância Instância 
212 Capítulo 9 ■ Computação com o App Engine 
Isso instalará ou atualizará a biblioteca Python do App Engine conforme necessário. Se a biblioteca estiver 
atualizada, você receberá uma mensagem dizendo isso. 
Quando você abre o Cloud Shell, você pode ter um diretório chamado python-docs-samples. 
Isso contém vários aplicativos de exemplo, incluindo o aplicativo Hello World que 
usaremos. Se você não vir este diretório, faça o download do aplicativo Hello World do Google 
usando: 
git clone https://github.com/GoogleCloudPlatform/python-docs-samples 
Em seguida, altere seu diretório de trabalho para o diretório com o Hello World app, usando
o seguinte: 
cd python-docs-samples / appengine / padrão / hello_world 
Se você listar os arquivos no diretório, verá três arquivos. 
■ app.yaml 
■ main.py 
■ main_test.py 
Aqui você está preocupado principalmente com o arquivo app.yaml. Liste o conteúdo desse arquivo 
usando o seguinte comando: 
cat app.yaml 
Isso mostrará os detalhes da configuração, como mostra a Figura 9.2. 
F igur e 9.2 O conteúdo de um arquivo app.yaml para um aplicativo Python 
O arquivo de configuração do aplicativo especifica a versão do Python a ser usada, a versão da API que você está 
implementando e um parâmetro do Python chamado threadsafe, que é definido como true. Os últimos três
linhas especificam o script a ser executado, que neste caso é main.py. 
Para implantar seu aplicativo, você pode usar o seguinte comando: 
gcloud app deploy app.yml 
No entanto, app.yml é o padrão, portanto, se você estiver usando isso para o nome do arquivo, não é 
necessário especificar app.yml no comando deploy . 
Este comando deve ser executado a partir do diretório com o arquivo app.yaml. O 
comando gcloud app deploy tem alguns parâmetros opcionais: 
■ --version para especificar uma ID de versão personalizada 
■ --project para especificar o ID do projeto a ser usado para este app 
■ --no-promote para implantar o aplicativo sem rotear o tráfego para ele 
Implantando uma aplicação do App Engine 213
 Quando você emitir o comando gcloud app deploy, verá a saída, como na Figura 9.3. 
 FIGURA 9.3 A saída do comando gcloud app deploy 
 Você pode ver a saída do programa Hello World navegando em um navegador para o 
URL do seu projeto, como https://gcpace-project.appspot.com. O URL do projeto é o nome do projeto seguido por .appspot.com. Por exemplo, a Figura 9.4 mostra a saída. 
 FIGURA 9.4 A saída do aplicativo Hello World ao executar no App Engine Standard 
 Você também pode atribuir um domínio personalizado se preferir não usar um 
URL do appspot.com. Você pode fazer isso usando a 
função de domínio Adicionar novo personalizado na página Configurações do App Engine.
 No console do App Engine, selecione Serviços no menu do painel esquerdo para ver uma lista de 
serviços, como na Figura 9.5. 
 FIGURA 9.5 Uma listagem de serviços no console do 
App Engine A 
Figura 9.6 mostra uma lista de versões. Você pode exibir isso selecionando Versões no 
menu do painel esquerdo. 
F igur e 9.6 Uma listagem de versões no console do App Engine 
Figura 9.7 mostra os detalhes de desempenho da instância. Você pode exibir esses detalhes 
selecionando Instâncias no menu do painel esquerdo. Esta informação é útil para entender 
a carga na sua aplicação. 
F igur e 9.7 Uma listagem de serviços no console do 
App Engine
Você pode parar de veicular versões usando o comando gcloud app versions stop e passando uma lista de versões para parar. Por exemplo, para parar de veicular as versões v1 e v2, use o 
seguinte: 
gcloud app versions stop v1 v2 
Você também pode desativar um aplicativo inteiro no console do App Engine, em Configurações, 
clicando no botão Desativar aplicativo. 
As 
instâncias de aplicativos do Scaling App Engine são criadas para executar um aplicativo em um servidor gerenciado do App Engine. O App 
Engine pode adicionar ou remover instâncias automaticamente, conforme necessário, com base na carga. Quando as instâncias 
são dimensionadas com base no carregamento, elas são denominadas instâncias dinâmicas. Essas instâncias dinâmicas ajudam a 
otimizar seus custos desligando quando a demanda é baixa.
Como alternativa, você pode configurar suas instâncias para serem residentes ou estar em execução o tempo todo. 
Eles são otimizados para desempenho, para que os usuários esperem menos enquanto uma instância é iniciada. 
Sua configuração determina se uma instância é residente ou dinâmica. Se você configurar escalonamento automático ou escalonamento básico, as instâncias serão dinâmicas. Se você configurar o 
dimensionamento manual , suas instâncias serão residentes. 
Para especificar o dimensionamento automático, inclua uma seção em app.yaml que inclua o termo 
automatic_scaling seguido por pares de valor-chave das opções de configuração. Isso inclui 
o seguinte: 
■ target_cpu_utilization 
■ target_throughput_utilization 
■ max_concurrent_requests 
■ max_instances 
■ min_instances
■ max_pending_latency 
■ min_pending_latency 
Utilização da CPU de destino Especifica a utilização máxima da CPU que ocorre antes que instâncias adicionais sejam iniciadas. 
Utilização de taxa de transferência de destino Especifica o número máximo de solicitações simultâneas 
antes que instâncias adicionais sejam iniciadas. Isso é especificado como um número entre 0,5 e 0,95. 
Máximo de solicitações simultâneas Especifica o máximo de solicitações simultâneas que uma instância pode 
aceitar antes de iniciar uma nova instância. O padrão é 10; o máximo é 80. 
Instâncias Máxima e Mínima Indica o intervalo do número de instâncias que podem ser 
executadas para este aplicativo. 
Latência Máxima e Mínima Indica o tempo máximo e mínimo que uma solicitação 
aguardará na fila para ser processada.
216 Capítulo 9 ■ Computação com o App Engine 
Você também pode usar o dimensionamento básico para ativar o dimensionamento automático. Os únicos parâmetros para o 
escalonamento básico são idle_timeout e max_instances. 
A Figura 9.9 mostra um exemplo de arquivo Hello World app.yaml configurado para dimensionamento básico com 
um máximo de 10 instâncias e um idle_timeout de 20 minutos. 
F igur 9.9 Exemplo app.yaml usando escalonamento básico 
Se você preferir usar o escalonamento manual porque precisa controlar o escalonamento, especifique 
o parâmetro manual_scaling e o número de instâncias a serem executadas. No exemplo da 
Figura 9.10, o aplicativo Hello World está configurado para ser executado com sete instâncias. 
Figurar 9.10 Exemplo app.yaml usando escala manual
F igur e 9.8 Um exemplo app.yaml para o aplicativo Hello World com parâmetros de escalonamento automático 
Dividindo o tráfego entre as versões do App Engine 217 
Microservices vs. Monolithic Applications Os aplicativos 
escalonáveis ​​geralmente são gravados como coleções de microsserviços. Isso nem 
sempre foi o caso. No passado, muitos aplicativos eram monolíticos ou projetados para 
incluir todas as funcionalidades em um único programa ou script compilado. Isso pode soar como uma maneira 
simples e fácil de gerenciar aplicativos, mas, na prática, cria mais problemas do 
que resolve. 
■ Qualquer alteração no aplicativo exige a reimplantação de todo o aplicativo, o que pode 
levar mais tempo do que a implantação de microsserviços. Desenvolvedores tendiam a agregar mudanças
antes de liberá-los. 
■ Se uma versão empacotada tivesse um bug em uma alteração de recurso, todas as alterações de recurso seriam 
revertidas quando o aplicativo monolítico fosse revertido. 
■ Era difícil coordenar as alterações quando as equipes de desenvolvedores precisavam trabalhar com um 
único arquivo ou um pequeno número de arquivos do código-fonte. 
Os microsserviços dividem o código do aplicativo em aplicativos de função única, permitindo que os desenvolvedores alterem um serviço e o implementem sem afetar outros serviços. 
As ferramentas de gerenciamento de código-fonte , como o Git, facilitam a contribuição de vários desenvolvedores para componentes 
de um sistema maior, coordenando as alterações nos arquivos de código-fonte. Este código de função única
e a fácil integração com outro código promove atualizações mais frequentes e a capacidade de 
testar novas versões antes de distribuí-las para todos os usuários ao mesmo tempo. 
Dividindo o tráfego entre as 
versões do App Engine 
Se você tiver mais de uma versão de um aplicativo em execução, poderá dividir o tráfego entre 
as versões. O App Engine fornece três maneiras de dividir o tráfego: por endereço IP, por 
cookie HTTP e por seleção aleatória. A divisão do endereço IP fornece alguma rigidez, portanto, um cliente 
é sempre roteado para a mesma divisão, pelo menos enquanto o endereço IP não for alterado. Os 
cookies HTTP são úteis quando você deseja atribuir usuários a versões. A seleção aleatória é útil 
quando você deseja distribuir uniformemente a carga de trabalho.
Ao usar a divisão de endereço IP, o App Engine cria um hash, ou seja, um número gerado com 
base em uma string de entrada entre 0 e 999, usando o endereço IP de cada versão. Isso pode 
criar problemas se os usuários alterarem o endereço IP, por exemplo, se começarem a trabalhar com o aplicativo no 
escritório e depois mudarem para uma rede em uma cafeteria. Se as informações de estado forem mantidas em uma 
versão, elas podem não estar disponíveis após a alteração de um endereço IP. 
A maneira preferida de dividir o tráfego é com um cookie. Quando você usa um cookie, o HTTP 
cabeçalho de solicitação para um cookie chamado GOOGAPPUID contém um valor hash entre 
218 Capítulo 9 ■ Computing w om App Engine 
0 e 999. Com a divisão biscoito, um usuário irá acessar a mesma versão do aplicativo, mesmo se o
alterações do endereço IP do usuário. Se não houver um cookie GOOGAPPUID, o tráfego será roteado 
aleatoriamente. 
O comando para dividir o tráfego é gcloud app services set-traffic. Veja um exemplo: 
gcloud app services set-traffic serv1 --splits v1 = .4, v2 = .6 
Isso dividirá o tráfego com 40% indo para a versão 1 do serviço chamado serv1 e 60 
% indo para a versão 2. Se nenhum serviço nome é especificado, todos os serviços são divididos. 
O comando set-traffic do gcloud app services aceita os seguintes parâmetros: 
■ --migrate indica que o App Engine deve migrar o tráfego da versão anterior 
para a nova versão. 
■ --split-by especifica como dividir o tráfego usando IP ou cookies. Valores possíveis são
ip, cookie e aleatório. 
Você também pode migrar o tráfego do console. Navegue até a página Versões e selecione 
o comando Migrar. 
Resumo O 
App Engine Standard é uma plataforma sem servidor para executar aplicativos em 
ambientes específicos de idioma . Como engenheiro de nuvem, espera-se que você saiba como implantar e escalar os aplicativos do App 
Engine. Os aplicativos do App Engine consistem em serviços, versões e instâncias. 
Você pode ter várias versões em execução ao mesmo tempo. Você pode dividir o tráfego entre as versões 
e fazer com que todo o tráfego migre automaticamente para uma nova versão. Aplicativos do Google App Engine são
configurado através de arquivos de configuração app.yaml. Você pode especificar o ambiente de idioma, os parâmetros de escala e outros parâmetros para personalizar sua implementação. 
Fundamentos do exame 
Conheça a estrutura dos aplicativos padrão do Google App Engine. Estes consistem em serviços, versões 
e instâncias. Os serviços geralmente fornecem uma única função. As versões são versões diferentes do 
código em execução no ambiente do App Engine. Instâncias são instâncias gerenciadas executando 
o serviço. 
Saiba como implantar um aplicativo do App Engine. Isso inclui configurar o ambiente do App Engine usando o arquivo app.yaml. Saiba que um projeto pode ter apenas um aplicativo do App Engine por 
vez. Saiba como usar o comando gcloud app deploy.
Saiba como visualizar o status de um aplicativo no App Engine Console. Isso inclui a 
visualização de uma lista de serviços, versões e instâncias. 
Fundamentos do exame 219 
Compreenda as diferentes opções de dimensionamento. Três opções de escala são escalonamento automático, 
dimensionamento básico e escala manual. Apenas o escalonamento automático e o escalonamento básico são dinâmicos. O 
dimensionamento manual cria instâncias residentes. O escalonamento automático permite mais opções de configuração do que 
o dimensionamento básico. 
Saiba como dividir o tráfego. Use o comando set-traffic do gcloud app services para dividir o 
tráfego. É necessário um parâmetro ––splits, que especifica o percentual de tráfego a ser roteado para cada 
versão. 
Entenda como migrar o tráfego para uma nova versão. Você pode migrar das versões
página do console do App Engine ou usando o parâmetro ––migrate com o comando gcloud app 
services set-traffic. 
220 Capítulo 9 ■ Computação com o App Engine 
 Neste capítulo, descrevemos a finalidade das funções na nuvem, 
bem como como implementar e implantar as funções. Vamos 
usar exemplos das funções escritas em Python. Se você 
não estiver familiarizado com o Python, isso não deve dissuadi-lo de 
acompanhar. Os detalhes importantes das funções do Python serão explicados. Você 
aprenderá a usar o Cloud Console e os comandos gcloud para criar e gerenciar as Cloud 
Functions. 
  
 Este capítulo abrange apenas as funções da nuvem. O App Engine é coberto no 
Capítulo 9. 
 Introdução às funções da nuvem
 O Cloud Functions é um serviço de computação sem servidor fornecido pelo Google Cloud Platform (GCP). 
O Cloud Functions é semelhante ao App Engine, pois ambos são sem servidor. A principal 
diferença, no entanto, é que o App Engine suporta vários serviços organizados em um único 
aplicativo, enquanto o Cloud Functions oferece suporte a serviços individuais que são gerenciados e 
operam independentemente de outros serviços. 
 O App Engine é uma boa opção sem servidor para aplicativos da Web que têm uma 
interface de usuário front-end em execução em um serviço, um conjunto de APIs em execução em um ou mais serviços e 
lógica de negócios em execução em outro serviço. Os serviços juntos compõem o aplicativo, portanto 
, faz sentido tratá-los como uma única unidade gerenciada.
 Nem todos os requisitos de computação precisam de vários serviços. Por exemplo, seu departamento 
pode fazer o upload de uma extração diária de dados de um banco de dados, que é então carregado em um 
data warehouse corporativo . Se os arquivos de extração de dados forem carregados no Cloud Storage, você poderá 
usar uma função para executar o pré-processamento, como verificar se o arquivo tem o formato correto e se 
atende a outras regras de negócios. Se o arquivo passar verificações, uma mensagem será gravada em um tópico Pub / Sub, 
um serviço de mensagens no GCP, que é lido pelo processo de carregamento do data warehouse. O Cloud 
Functions permite que os desenvolvedores separem a verificação inicial de qualidade de dados do restante do processo de 
extração, transformação e carregamento.
 Existem limites para o Cloud Functions. Por padrão, as funções terão o tempo limite após um 
minuto, embora você possa definir o tempo limite por até nove minutos. 
Introdução a funções de nuvem 227 
Eventos, acionadores e funções 
Há alguns termos que você precisa saber antes de ir mais longe nas Funções da nuvem: 
■ Eventos 
■ Acionadores 
■ Funções 
Eventos são uma ação específica que acontece no Google Cloud, como o upload de um arquivo 
ao Cloud Storage ou uma mensagem (chamada de tópico) é gravada em uma fila de mensagens do Pub / Sub. Existem 
diferentes tipos de ações associadas a cada um dos eventos. Atualmente, o GCP oferece suporte a 
eventos em cinco categorias: 
■ Cloud Storage 
■ Cloud Pub / Sub
■ HTTP 
■ Firebase 
■ O Stackdriver Logging 
Events no Cloud Storage inclui o upload, a exclusão e o arquivamento de um arquivo. O Cloud Pub / Sub 
tem um evento para publicar uma mensagem. O tipo de evento HTTP permite que os desenvolvedores invoquem 
uma função fazendo uma solicitação HTTP usando as 
chamadas POST, GET, PUT, DELETE e OPTIONS . Os eventos do Firebase são ações executadas no banco de dados do Firebase, como acionadores de banco de dados, acionadores 
de configuração remota e acionadores de autenticação. Você pode configurar uma função para 
responder a uma alteração no Stackdriver Logging encaminhando as entradas do registro para um tópico Pub / Sub 
e acionando uma resposta a partir daí. 
Para cada um dos eventos ativados por Cloud Functions que podem ocorrer, você pode definir um acionador.
Um gatilho é uma maneira de responder a um evento. 
Triggers têm uma função associada. A função é passada argumentos com dados sobre 
o evento. A função é executada em resposta ao evento. 
Ambientes de tempo de execução As 
funções são executadas em seu próprio ambiente. Cada vez que uma função é chamada, ela é executada em uma 
instância separada de todas as outras chamadas. Não há como compartilhar informações entre 
invocações de funções usando apenas Cloud Functions. Se você precisar coordenar a atualização dos dados, como manter uma contagem global ou precisar manter informações sobre o estado das 
funções, como o nome do último evento processado, use um banco de dados, 
como o Cloud Datastore, ou um arquivo no Cloud Storage.
Atualmente, o Google suporta três ambientes de tempo de execução: 
■ Python 3 
■ Node.js 6 
■ Node.js 8 
228 Capítulo 10 ■ Computação com funções de nuvem 
Vamos percorrer uma função de exemplo. Você deseja registrar informações sobre 
uploads de arquivos em um determinado intervalo no Cloud Storage. Você pode fazer isso escrevendo uma função Python que recebe informações sobre um evento e, em seguida, emite comandos de impressão para enviar uma 
descrição desses dados para um arquivo de log. Aqui está o código Python: 
def cloud_storage_function_test (event_data, event_context): 
print ('ID do evento: {}'. Format (event_context.event_id)) 
 print ('Tipo de evento: {}'. Format (event_context.event_type)) 
 print ( 'Arquivo: {}'. Format (event_data ['name']))
A primeira linha inicia a criação de uma função chamada cloud_storage_function_test. Ele 
recebe dois argumentos, event_data e event_context. Estas são estruturas de dados do Python 
com informações sobre o objeto do evento e sobre o próprio evento. As próximas três 
linhas imprimem os valores de event_id, event_type e name do arquivo. Como esse código será 
executado como uma função e não de forma interativa, a saída de uma instrução print irá para o 
arquivo de log da função. 
As funções do Python devem ser salvas em um arquivo chamado main.py. 
Tornar Documentos Pesquisáveis ​​Os 
processos judiciais, ou ações judiciais, entre empresas geralmente envolvem a revisão de um grande volume 
de documentos. Os documentos eletrônicos podem estar em formatos prontamente pesquisáveis, como
Documentos do Microsoft Word ou arquivos PDF. Outros podem ser imagens digitalizadas de 
documentos em papel . Nesse caso, o arquivo precisa ser pré-processado usando um programa de 
reconhecimento óptico de caracteres (OCR). 
Funções podem ser usadas para automatizar o processo de OCR. Quando um arquivo é carregado, um 
acionador do Cloud Storage é acionado e invoca uma função. A função determina se o arquivo está 
em um formato pesquisável ou precisa ser pré-processado pelo programa OCR. Se o arquivo 
exigir processamento de OCR, a função gravará o local do arquivo em um 
tópico de Pub / Sub. 
Uma segunda função está vinculada a um novo evento de mensagem. Quando uma localização de arquivo é gravada 
em uma mensagem, a função chama o programa OCR para digitalizar o documento e produzir
uma versão pesquisável do arquivo. Essa versão pesquisável é gravada em um 
intervalo do Cloud Storage , onde pode ser indexada pela ferramenta de pesquisa junto com outros arquivos pesquisáveis. 
Funções da nuvem Recebendo eventos do Cloud Storage 229 
Funções da nuvem Recebendo eventos do 
Cloud Storage 
Cloud Storage é o armazenamento de objetos do GCP. Esse serviço permite armazenar arquivos em contêineres 
conhecidos como buckets. Entraremos em mais detalhes sobre o Cloud Storage no Capítulo 11, mas 
para este capítulo você só precisa entender que o Cloud Storage usa buckets para armazenar 
arquivos. Quando arquivos são criados, excluídos ou arquivados, ou seus metadados são alterados, um evento 
pode invocar uma função. Vamos passar por um exemplo de implantação de uma função para o Cloud
Eventos de armazenamento usando o Cloud Console e os comandos gcloud no Cloud SDK e no Cloud 
Shell. 
Implantando uma função de nuvem para eventos do Cloud Storage 
usando o Cloud Console 
Para criar uma função usando o Cloud Console, selecione as opções de Cloud Function no menu vertical no console, como na Figura 10.1. 
Figura 10.1 Abrindo o console do Cloud Functions 
No console do Cloud Functions, você pode ser solicitado a habilitar a Cloud Functions 
API, caso ainda não esteja habilitado. Após a ativação da Cloud Functions API, você terá a 
opção de criar uma nova função, conforme mostrado na Figura 10.2. 
Figura 10.2 O prompt para criar uma nova função no Cloud Console 
Capítulo 10 ■ Computando com as funções de nuvem
Quando você cria uma nova função no console, um formulário como na Figura 10.3 aparece. 
Na Figura 10.3, as opções que foram preenchidas incluem: 
■ Nome da função 
■ Memória alocada para a função 
■ Trigger 
■ Tipo de evento 
■ Origem do código de função 
■ Tempo de execução 
■ Código-fonte 
■ Função Python, Go ou Node.js para execute 
Figura 10.3 Criando uma função no console 
No exemplo a seguir, estamos carregando um arquivo contendo o código da função. O conteúdo desse arquivo é o seguinte: 
def cloud_storage_function_test (event_data, event_context): 
 print ('ID do Evento: {}'. Format (event_context.event_id)) 
 print ('Tipo de Evento: {}'. Format (event_context.event_type) )
 print ('File: {}'. format (event_data ['name'])) 
Funções da nuvem Recebendo eventos do Cloud Storage 231 
O nome da função é o nome que o GCP usará para se referir a essa função. Memória 
Alocada é a quantidade de memória que estará disponível para a função. As opções de memória 
variam de 128MB a 2GB. O acionador é um dos acionadores definidos, como HTTP, Cloud 
Pub / Sub e Cloud Storage. Há várias opções para especificar onde encontrar o 
código-fonte, inclusive fazer o upload dele, obtê-lo do Cloud Storage ou de um repositório do Cloud Source ou inserir o código em um editor. Tempo de execução indica qual tempo de execução usar para executar 
o código. O editor é onde você pode inserir o código de função. Finalmente, a função para executar
é o nome da função no código que deve ser executado quando o evento ocorrer. 
Depois que uma função é criada, você verá uma lista de funções no console do Cloud Functions, como na Figura 10.4. 
Figura 10.4 Lista de funções no console 
Observe que no topo da lista de funções existe a opção de excluir uma função. 
Implantando uma função do Cloud para eventos do Cloud Storage 
usando comandos do gcloud 
O primeiro passo para usar os comandos do gcloud para o Cloud Functions é garantir que você tenha a versão mais recente dos comandos instalados. Você pode atualizar os comandos padrão do gcloud usando o seguinte: 
gcloud components update 
Os comandos do Python estão em beta no momento da escrita, para que você possa garantir que eles estejam
instalado com o seguinte comando: 
gcloud components install beta 
Vamos supor que você tenha criado um intervalo do Cloud Storage chamado gcp-ace-exam-testbucket. Você pode implantar uma função usando o comando gcloud functions deploy. Este 
comando leva o nome de uma função como seu argumento. Há também três parâmetros 
que você precisa para passar em: 
■ tempo de execução 
■ gatilho de recursos 
■ gatilho evento 
232 Capítulo 10 ■ Computing com funções de nuvem 
de tempo de execução indica se você estiver usando o Python 3.7 Node.js 6, ou Node.js 8. 
gatilho -resources indica o nome do depósito associado ao acionador. trigger-event 
é o tipo de evento que acionará a execução da função. As opções possíveis são
da seguinte forma: 
■ google.storage.object.finalize 
■ google.storage.object.delete 
■ google.storage.object.archive 
■ google.storage.object.metadataUpdate 
finalize é o termo usado para descrever quando um arquivo é totalmente carregado. 
Sempre que um novo arquivo é enviado para o bloco chamado gcp-ace-exam-test-bucket, 
queremos executar o cloud_storage_function_test. Realizamos isso emitindo o 
seguinte comando: 
gcloud funções implantar cloud_storage_function_test \ 
 --runtime python37 \ 
 --trigger-resource gcp-ace-exame-teste-depósito \ 
 --trigger-event google.storage.object.finalize 
Quando você carrega um arquivo arquivo no bucket, a função executará e criará uma mensagem de log
semelhante ao que é mostrado na Figura 10.5. 
Figura 10.5 Mensagem de log de exemplo gerada pela 
função cloud_storage_function_test 
Quando você terminar a função e quiser excluí-la, poderá usar o comando delete da função gcloud, assim: 
funções gcloud delete cloud_storage_function_test 
Funções de nuvem Recebendo eventos do Pub / Sub 233 
Funções de nuvem Recebendo Eventos do 
Pub / Sub 
Uma função pode ser executada toda vez que uma mensagem é gravada em um tópico Pub / Sub. Você pode usar o 
Cloud Console ou os comandos gcloud para implantar funções acionadas por um 
evento do Cloud Pub / Sub . 
Implantando uma função de nuvem para eventos do Cloud Pub / Sub 
usando o Cloud Console
Suponha que você esteja usando uma função semelhante à usada no 
exemplo anterior do Cloud Storage . Desta vez vamos chamar a função pub_sub_function_test. 
Para criar uma função usando o Cloud Console, selecione as opções Cloud Function no 
menu vertical no console. No console do Cloud Functions, você pode ser solicitado a 
ativar a Cloud Functions API, caso ela ainda não esteja ativada. Após a ativação da Cloud Functions API 
, você terá a opção de criar uma nova função. Ao criar uma função, 
você precisará especificar vários parâmetros, incluindo o nome da função da nuvem, a memória 
alocada, o tipo de evento e o código-fonte. Aqui está o código-fonte para pub_sub_function_test: 
def pub_sub_function_test (event_data, event_context):
 import base64 
print ('ID do evento: {}'. format (event_context.event_id)) 
 print ('Tipo de evento: {}'. format (event_context.event_type)) 
 se 'nome' em event_data: 
 name = base64.b64decode (event_data ['name']]. decode ('utf-8') 
 print ('Nome da mensagem: {}'. format (event_data ['name'])) 
Esta função imprime o ID do evento e o tipo de evento associado à mensagem. Se os 
dados do evento tiverem um par de valores-chave com a chave do nome, a função também imprimirá o 
nome na mensagem. Note que esta função tem uma declaração de importação e usa uma função 
chamada base64.b64decode. Isso ocorre porque as mensagens no Pub / Sub são codificadas para permitir 
dados binários em um local onde os dados de texto são esperados,
usado para convertê-lo em uma codificação de texto mais comum chamada UTF-8. 
O código é implantado da mesma maneira que o exemplo anterior do Cloud Storage com duas 
exceções. Em vez de selecionar um acionador do Cloud Storage, escolha Cloud Pub / Sub na lista 
de acionadores, conforme mostrado na Figura 10.6. Você também pode especificar o nome do 
tópico do Cloud Pub / Sub depois de especificar que esse é um acionador do Cloud Pub / Sub. Se o tópico não existir, ele será 
criado. 
234 Capítulo 10 ■ Computing com funções de Nuvem 
Figura 10.6 Seleção de um disparador de opções no Cloud Console 
Implantando uma função em nuvem para nuvem Pub / Sub eventos 
usando comandos do gcloud 
Como com funções para Cloud Storage, se você estiver implantando Funções nuvem, é uma boa idéia
para usar os comandos gcloud mais recentes emitindo o seguinte: 
gcloud components update 
Se você estiver usando o Python, também deverá instalar componentes do beta gcloud: 
gcloud components install beta 
Para implantar essa função, use o comando gcloud functions deploy. Ao 
implantar uma função Cloud Pub / Sub, você especifica o nome do tópico que conterá 
mensagens que acionarão a função. Como a implantação no Cloud Storage, você precisa especificar o ambiente de tempo de execução que deseja usar. Veja um exemplo: 
gcloud funções implantar pub_sub_function_test --runtime python37 --trigger-topic 
gcp-ace-exame-teste-tópico 
Você pode excluir essa função usando o comando gcloud functions delete. Aqui está um 
exemplo:
gcloud funções delete pub_sub_function_test 
Resumo 
Neste capítulo, trabalhamos com o Cloud Functions e vimos como implementar e implantar 
funções. Usamos exemplos de funções escritas em Python, mas elas também poderiam ter sido escritas em Node.js. As funções podem ser criadas usando 
a linha de comando do Google Cloud Console ou do 
Exam Essentials . Para usar o Cloud Functions, é importante entender o relacionamento 
entre eventos, gatilhos e funções. Eventos são ações que acontecem na nuvem. 
Serviços diferentes têm diferentes tipos de eventos. Triggers são como você indica que deseja 
executar uma função quando ocorre um evento. Funções referem-se ao código que é executado quando
Ocorre um evento que possui um gatilho definido para ele. 
Fundamentos do exame 
Conheça a relação entre eventos, gatilhos e funções. Os eventos são ações que 
acontecem, como quando um arquivo é carregado no Cloud Storage ou uma mensagem é gravada em um 
tópico do Cloud Pub / Sub. Triggers são declarações de que uma ação deve ser tomada quando um evento 
ocorre. As funções associadas aos gatilhos definem quais ações são executadas quando um evento 
ocorre. 
Saiba quando usar os aplicativos do Cloud Functions em comparação com o App Engine. O Cloud Functions é 
um serviço que suporta funções de finalidade única que respondem a eventos na nuvem. Aplicativo
O Engine também é uma opção de computação sem servidor, mas é usado para implantar aplicativos multifuncionais, incluindo aqueles com os quais os usuários interagem diretamente. 
Conheça os tempos de execução suportados no Cloud Functions. O Cloud Functions suporta os seguintes tempos de execução: Node.js 6, Node.js 8 e Python 3. 
Conheça os parâmetros para definir uma função de nuvem em um evento do Cloud Storage. Os parâmetros 
para o Cloud Storage incluem o seguinte: 
Nome da função de nuvem 
Memória alocada para a função 
Trigger 
Tipo de evento 
Origem do código de função 
Runtime 
Código-fonte 
Nome da função Python ou Node.js a ser executada 
Conheça os parâmetros para definir uma Cloud Function em um Cloud Pub Evento / Sub.
Parâmetros para Pub / Sub incluem o seguinte: 
Nuvem nome da função 
de memória alocada para a função 
de disparo 
Topic 
236 Capítulo 10 ■ Computing com funções nuvem 
Fonte do código de função 
Runtime 
Source code 
Nome do Python ou Node.js função para executar 
Conheça os comandos do gcloud para trabalhar com o Cloud Functions. Isso inclui o 
seguinte: 
funções do gcloud implantar funções do 
gcloud delete 


Como engenheiro de nuvem, você terá que entender as várias 
opções de armazenamento fornecidas no Google Cloud Platform (GCP). 
Você deverá escolher a opção apropriada para um
dado caso de uso, sabendo os trade-offs relativos, como 
ter acesso ao SQL para uma linguagem de consulta versus a capacidade de armazenar e consultar petabytes 
de fluxo de dados em seu banco de dados. 
Ao contrário da maioria dos outros capítulos do livro, este capítulo se concentra mais em conceitos de armazenamento do 
que na execução de tarefas específicas no GCP. O material aqui ajudará você a responder perguntas 
sobre como escolher a melhor solução de armazenamento. O Capítulo 12 fornecerá detalhes sobre a implementação e 
implementação de soluções de dados. 
Para escolher entre as opções de armazenamento, é útil entender como as soluções de armazenamento variam: 
■ Tempo para acessar dados 
■ Modelo de dados 
■ Outros recursos, como consistência, disponibilidade e suporte para transações
Este capítulo inclui diretrizes para escolher soluções de armazenamento para diferentes tipos de 
requisitos. 
Tipos de sistemas de armazenamento 
Uma consideração principal quando você escolhe uma solução de armazenamento é o tempo no qual os dados 
devem ser acessados. Em um extremo, os dados em um cache L1 em ​​um chip da CPU podem ser acessados ​​em 
0,5 nanossegundos (ns). No outro extremo do espectro, alguns serviços podem exigir horas para 
retornar arquivos de dados. A maioria dos requisitos de armazenamento fica entre esses extremos. 
Nanossegundos, Milissegundos e Microssegundos 
Alguns sistemas de armazenamento operam em velocidades que nos são desconhecidas, como acontece com um 
microscópio eletrônico. Um segundo é um tempo extremamente longo quando se fala sobre o tempo
leva para acessar dados na memória ou no disco. Medimos o tempo de acesso, ou "latência", 
com três unidades de medida. 
■ Nanossegundo (ns), que é 10-9 segundos 
■ Microssegundo (μs), que é 10-6 segundos 
■ Milissegundo (ms), que é 10-3 segundos 
Tipos de sistemas de armazenamento 243 
Observação, o número 10-3 está em notação científica e significa 0,001 segundo. Da mesma forma, 10-6 é 
o mesmo que 0,000001 e 10-9 é o mesmo que 0,000000001 segundo. 
Outra consideração é persistência. Quão duráveis ​​são os dados armazenados em um sistema específico? 
Os caches oferecem a menor latência para acessar dados, mas esse tipo de dados voláteis existe apenas 
enquanto a energia é fornecida à memória. Encerre o servidor e afaste seus dados.
Unidades de disco têm taxas de durabilidade mais altas, mas podem falhar. Redundância ajuda aqui. Ao fazer 
cópias de dados e armazená-los em servidores diferentes, em racks diferentes, em zonas diferentes 
e em regiões diferentes, você reduz o risco de perder dados devido a falhas de hardware. 
GCP tem vários serviços de armazenamento, incluindo o seguinte: 
■ Um serviço de cache Redis conseguiu para cache 
■ armazenamento em disco persistente para uso com VMs 
armazenamento de objetos ■ para acesso compartilhado a arquivos através de recursos 
■ armazenamento de arquivo de longo prazo, os requisitos de acesso infrequentes 
cache 
Um cache é um armazenamento de dados na memória projetado para fornecer aplicativos com sub milissegundos
acesso aos dados. Sua principal vantagem em relação a outros sistemas de armazenamento é sua baixa latência. Os caches 
são limitados em tamanho pela quantidade de memória disponível e, se a máquina que hospeda o cache for 
desligada, o conteúdo do cache será perdido. Estas são limitações significativas, mas em 
alguns casos de uso, os benefícios do acesso rápido aos dados superam as desvantagens. 
O MemoryStore 
GCP oferece Memorystore, um serviço Redis gerenciado. Redis é um 
cache de código aberto amplamente utilizado . Como o Memorystore é compatível com o protocolo Redis, as ferramentas e aplicativos criados 
para trabalhar com o Redis devem funcionar com o Memorystore. 
Os caches geralmente são usados ​​com um aplicativo que não tolera latências longas
recuperar dados. Por exemplo, um aplicativo que precisa ler a partir de uma unidade de disco rígido 
pode ter que esperar 80 vezes mais do que se os dados fossem lidos de um cache na memória. 
Os desenvolvedores de aplicativos podem usar caches para armazenar dados recuperados de um banco de dados e, em 
seguida, recuperados do cache em vez do disco na próxima vez que os dados forem necessários. 
Quando você usa o Memorystore, cria instâncias que executam o Redis. A instância está configurada com 1 GB a 300 GB de memória. Ele também pode ser configurado para alta disponibilidade, em 
cujo caso o Memorystore cria réplicas de failover. 
Configurando os 
caches Memorystore Memorystore podem ser usados ​​com aplicativos em execução no Compute Engine, App
Engine e Kubernetes Engine. A Figura 11.1 mostra os parâmetros usados ​​para configurar o 
Memorystore. Você pode navegar para este formulário escolhendo Memorystore no 
menu principal do console e selecionando a opção para criar uma instância do Redis. 
244 Capítulo 11 ■ Planejamento armazenamento na nuvem 
F IGURA 11.1 parâmetros de configuração para um Memorystore de cache 
Tipos de Sistemas de Armazenamento 245 
para configurar um cache de Redis em Memorystore, você precisará especificar um ID exemplo, um 
nome de exibição, e uma versão Redis. Atualmente, apenas o Redis 3.2 é suportado. Você pode optar 
por ter uma réplica em uma zona diferente para alta disponibilidade, selecionando a 
camada da instância Padrão . A camada de instância básica não inclui uma réplica, mas custa menos.
Você precisará especificar uma região e zona junto com a quantidade de memória a ser dedicada 
ao seu cache. O cache pode ter entre 1 GB e 300 GB de tamanho. A instância do Redis estará acessível a partir da rede padrão, a menos que você especifique uma rede diferente. (Veja os capítulos 14 e 
15 para mais informações sobre redes no GCP). As opções avançadas do Memorystore permitem 
atribuir rótulos e definir um intervalo de IPs a partir do qual o endereço IP será atribuído. 
Armazenamento Persistente 
No GCP, os discos permanentes fornecem armazenamento de bloco durável. Discos 
permanentes podem ser anexados a VMs no Google Compute Engine (GCE) e no Google Kubernetes Engine (GKE). Como 
os discos permanentes são dispositivos de armazenamento em bloco, você pode criar sistemas de arquivos nesses dispositivos.
Os discos permanentes não são conectados diretamente aos servidores físicos que hospedam suas VMs, mas são 
acessíveis pela rede. As VMs podem ter unidades de estado sólido conectadas localmente (SSDs), mas os dados 
nessas unidades são perdidos quando a VM é finalizada. Os dados em discos permanentes continuam existindo depois que as VMs são encerradas e finalizadas. Discos persistentes existem independentemente de máquinas virtuais; SSDs anexados locais não. 
Recursos dos discos 
permanentes Os discos permanentes estão disponíveis em configurações de SSD e unidade de disco rígido (HDD). Os SSDs 
são usados ​​quando a alta taxa de transferência é importante. Os SSDs fornecem desempenho consistente 
tanto para acesso aleatório quanto para padrões de acesso sequencial. HDDs têm latências mais longas, mas custam
menos, portanto, os HDDs são uma boa opção ao armazenar grandes quantidades de dados e executar 
operações em lote que são menos sensíveis à latência de disco do que os aplicativos interativos. Os 
discos permanentes de backup com disco rígido podem executar 
IOPS de 0,75 entradas por segundo (IOPS) por gigabyte e 1,5 IOPS de gravação por gigabyte, enquanto os SSDs conectados à rede podem 
executar 30 IOPS de leitura e gravação por gigabyte. Os SSDs conectados localmente podem atingir 
taxas de IOPS de leitura entre 266 e 453 por gigabyte e gravar taxas de IOPS entre 186 e 
240 por gigabyte. 
Discos persistentes podem ser montados em várias VMs para fornecer armazenamento multireader. 
Instantâneos de discos podem ser criados em minutos, portanto, cópias adicionais de dados em um disco podem ser
distribuído para uso por outras VMs. Se um disco criado a partir de uma captura instantânea for montado em uma única 
VM, ele poderá suportar operações de leitura e gravação. 
O tamanho dos discos permanentes pode ser aumentado enquanto montado em uma VM. Se você redimensionar um 
disco, talvez seja necessário executar comandos do sistema operacional para tornar esse espaço adicional 
acessível ao sistema de arquivos. Os discos SSD e HDD podem ter até 64 TB. 
Os discos permanentes criptografam automaticamente os dados no disco. 
Ao planejar suas opções de armazenamento, você também deve considerar se deseja que seus 
discos sejam zonais ou regionais. Os discos zonais armazenam dados em várias unidades físicas em uma única 
zona. Se a zona ficar inacessível, você perderá o acesso aos seus discos. Alternativamente, você
246 Capítulo 11 ■ O Planejamento de armazenamento na nuvem 
pode usar discos persistentes regionais, que replicam blocos de dados em duas zonas de uma 
região, mas são mais caros do que o armazenamento zonal. 
Configurando discos 
permanentes Você pode criar e configurar discos permanentes no console, navegando até o Compute 
Engine e selecionando Discos. Na página Disk, clique em Create a Disk para exibir um formulário como 
esse na Figura 11.2. 
Figura 11.2 Formulário para criar um disco permanente 
Tipos de sistemas de armazenamento 247 
Você precisará fornecer um nome para o disco, mas a descrição é opcional. Existem 
dois tipos de disco: padrão e disco permanente SSD. Para maior disponibilidade, você pode ter
uma réplica criada dentro da região. Você precisará especificar uma região e zona. Os rótulos são 
opcionais, mas recomendados para ajudar a acompanhar o propósito de cada disco. 
Discos persistentes podem ser criados em branco ou a partir de uma imagem ou instantâneo. Use a 
opção image se você quiser criar um disco de inicialização persistente. Use um instantâneo se você quiser criar uma 
réplica de outro disco. 
Quando você armazena dados em repouso no GCP, ele é criptografado por padrão. Ao criar um disco, 
você pode optar por ter o Google gerenciando chaves de criptografia. Nesse caso, nenhuma configuração adicional é necessária. Você pode usar o Cloud Key Management Service do GCP para gerenciar 
chaves e armazená-las no repositório de chaves do GCP. Escolha o MKey gerenciado pelo cliente
opção para isso. Você precisará especificar o nome de uma chave que você criou no Cloud Key 
Management Service. Se você criar e gerenciar chaves usando outro sistema de gerenciamento de chaves, selecione SKey fornecido pelo cliente. Você terá que inserir a chave no formulário se 
escolher a opção de chave fornecida pelo cliente. 
Caches de 
armazenamento de objetos são usados ​​para armazenar quantidades relativamente pequenas de dados que devem ser acessíveis com 
latência sub-milissegunda. Dispositivos de armazenamento persistentes podem armazenar até 64 TB em um único disco 
e fornecer até centenas de IOPS para operações de leitura e gravação. Quando você precisa armazenar 
grandes volumes de dados, ou seja, até exabytes, e compartilhá-los amplamente, o armazenamento de objetos é uma boa 
opção. O armazenamento de objetos do GCP é Cloud Storage.
Recursos do Cloud Storage 
Cloud Storage é um sistema de armazenamento de objetos, o que significa que os arquivos armazenados no sistema 
são tratados como unidades atômicas, ou seja, você não pode operar em parte do arquivo, como ler 
apenas uma seção do arquivo. Você pode executar operações em um objeto, como criar ou excluí- 
lo, mas o Cloud Storage não fornece funcionalidade para manipular subcomponentes de um arquivo. 
Por exemplo, não há nenhum comando do Cloud Storage para sobrescrever uma seção do arquivo. Além disso, o 
Cloud Storage não suporta simultaneidade e bloqueio. Se vários clientes estiverem gravando em um 
arquivo, os últimos dados gravados no arquivo serão armazenados e persistidos.
O Cloud Storage é adequado para armazenar grandes volumes de dados sem exigir uma estrutura de dados consistente. Você pode armazenar diferentes tipos de dados em um intervalo, que é a 
unidade lógica da organização no Cloud Storage. Baldes são recursos dentro de um projeto. É importante lembrar que os buckets compartilham um namespace global, portanto, cada nome de bucket deve ser 
globalmente exclusivo. Não devemos nos surpreender se não pudermos nomear um bucket como mytestbucket, mas 
não é muito difícil encontrar um nome de arquivo exclusivo, especialmente se você seguir uma 
convenção de nomenclatura de buckets e objetos . 
É importante lembrar que o armazenamento de objetos não fornece um sistema de arquivos. Os buckets são 
análogos aos diretórios, pois ajudam a organizar objetos em grupos, mas os buckets não são
diretórios verdadeiros que suportam recursos como subdiretórios. Google suporta um aberto 
projeto de código chamado Cloud Storage Fuse, que fornece uma maneira de montar um balde como um 
248 Capítulo 11 ■ Planejamento armazenamento na nuvem 
sistema fi le em sistemas operacionais Linux e Mac. Usando o Cloud Storage Fuse, você pode fazer o download e upload de arquivos para blocos usando os comandos do sistema de arquivos, mas não fornece a funcionalidade completa do 
sistema de arquivos. O Cloud Storage Fuse tem as mesmas limitações que o Cloud Storage. Sua 
finalidade é tornar mais conveniente mover dados para dentro e para fora de buckets ao trabalhar em 
um sistema de arquivos Linux ou Mac. 
 O Cloud Storage fornece quatro classes diferentes de armazenamento de objetos: multirregional, regional, 
nearline e coldline.
 Armazenamento Multirregional e Regional 
 Quando você cria um depósito, especifica um local para criar o depósito. O bucket e seu 
conteúdo são armazenados nesse local. Você pode armazenar seus dados em uma única região, conhecida como 
um intervalo regional, ou várias regiões, não surpreendentemente conhecidas como intervalos multirregionais. 
Os intervalos multirregionais fornecem mais de 99,99% de disponibilidade mensal típica com 
um acordo de nível de serviço (SLA) de disponibilidade de 99,95%. Os dados são replicados em várias 
regiões. Os intervalos regionais têm uma disponibilidade mensal típica de 99,99% e um SLA de disponibilidade de 99,9%. Os intervalos regionais são redundantes entre as zonas. 
 Os intervalos multirregionais são usados ​​quando o conteúdo precisa ser armazenado em várias regiões para
garantir tempos aceitáveis ​​para acessar o conteúdo. Também fornece redundância em caso de 
falhas no nível da zona . Esses benefícios vêm com um custo maior, no entanto. Até o momento, o armazenamento multirregional nos Estados Unidos custa US $ 0,26 / GB / mês, enquanto o armazenamento regional custa 
US $ 0,20 / GB / mês. (Não é provável que você seja questionado sobre os preços específicos no 
exame Associate Cloud Engineer, mas deve conhecer os custos relativos para identificar a 
solução de custo mais baixo que atende a um conjunto de requisitos.) 
 O armazenamento regional e multirregional é usado para dados usados ​​com freqüência. Se você tiver 
um aplicativo em que os usuários baixem e acessem arquivos com freqüência, como mais de uma vez por
mês, então é mais rentável para escolher regional ou multirregional. Você escolhe 
entre regionais e multirregionais com base na localização de seus usuários. Se os usuários forem dispersos globalmente e precisarem de acesso a dados sincronizados, o multi-regional poderá fornecer 
melhor desempenho e disponibilidade. 
 E se seus dados não forem usados ​​ativamente? Por exemplo, se você tiver arquivos que precisa armazenar 
por sete anos para fins de conformidade, mas não espere acessar, talvez seja necessário arquivar o armazenamento. Da mesma forma, se você estiver armazenando arquivos necessários apenas para recuperação de desastres, talvez 
deseje uma classe de armazenamento projetada para acesso pouco frequente, como menos de uma vez por ano. 
Para esses tipos de casos de uso, o Google projetou classes de armazenamento nearline e coldline.
 Uma nota sobre a terminologia: o Google às vezes usa o termo georedundante. Os dados do georedundante são armazenados em pelo menos dois locais 
separados por pelo menos 100 milhas. Se seus dados estiverem em locais multirregionais, eles 
serão georedundantes. 
 Armazenamento Nearline e Coldline 
 Para os dados acessados ​​com pouca frequência, as classes de armazenamento nearline e coldline são boas opções. 
Armazenamento Nearline é projetado para casos de uso em que você espera para acessar fi les menos de uma vez 
Tipos de Sistemas de Armazenamento 249 
por mês. O armazenamento do Coldline é projetado e precificado para arquivos que devem ser acessados ​​uma vez 
por ano ou menos.
O armazenamento nearline tem uma disponibilidade mensal típica de 99,95% em locais multirregionais e uma disponibilidade típica de 99,9% em locais regionais. Os SLAs do nearline são 
99,9% em locais multirregionais e 99,0% em locais regionais. Esses 
SLAs inferiores vêm com um custo significativamente menor: US $ 0,10 / GB / mês. Antes de começar a mover todos os seus 
dados regionais e multirregionais para nearline para economizar nos custos, você deve saber que o Google 
adiciona uma taxa de recuperação de dados ao armazenamento nearline e coldline. O preço de recuperação do 
armazenamento nearline é de US $ 0,01 / GB. Há também uma duração mínima de armazenamento de 30 dias para o armazenamento nearline. 
O armazenamento da Coldline tem uma disponibilidade mensal típica de 99,95% em locais multirregionais
e uma disponibilidade típica de 99,9% em locais regionais. Os SLAs são 99,9% para 
locais multirregionais e 99,0% para locais regionais. O Coldline também tem o menor 
custo por gigabyte a US $ 0,07 / GB / mês. Lembre-se, isso é apenas a taxa de armazenamento. Como o 
armazenamento nearline, o armazenamento da linha de frio possui taxas de acesso. O Google espera que os dados no armazenamento em linha fria sejam acessados ​​uma vez por ano ou menos e tenham pelo menos 90 dias de armazenamento mínimo. O 
preço de recuperação do armazenamento da linha de frio é de US $ 0,05 / GB. 
É mais importante entender as relações de custo relativas do que os preços atuais. 
Os preços podem mudar, mas os custos de cada classe em relação a outras classes de armazenamento são mais
provavelmente permanecerão iguais. Consulte a Tabela 11.1 para obter um resumo de recursos, custos e casos de uso para 
diferentes tipos de armazenamento. 
Tabela 11.1 Serviços de armazenamento - Resumo dos recursos 
:: Recursos multilaterais locais do Coldline regionais Armazenamento de 
objeto 
replicado em 
várias zonas 
Armazenamento de objeto 
replicado em 
várias regiões 
Armazenamento de objeto para 
acesso menos de 
uma vez por mês 
Armazenamento de objeto para 
acesso menos de 
uma vez por ano 
Custo de armazenamento US $ 0,20 / GB / mês $ 0.26 / GB / mês $ 0.10 / GB / mês $ 0.07 / GB / mês 
Custo de acesso $ 0.01 / GB $ 0.05 / GB 
Caso de uso Armazenamento de objetos 
compartilhado entre 
aplicativos
Acesso global a 
objetos compartilhados 
Dados antigos em 
lagos de dados , backups 
Retenção de 
documentos , 
conformidade 
Controle de versão e gerenciamento do ciclo de vida do objeto Os 
depósitos no Cloud Storage podem ser configurados para reter versões de objetos quando elas são 
alteradas. Quando o controle de versão está ativado em um intervalo, uma cópia de um objeto é arquivada sempre que 
o objeto é sobrescrito ou quando é excluído. A versão mais recente do objeto é conhecida 
como a versão ao vivo. O controle de versão é útil quando você precisa manter um histórico de alterações em um 
objeto ou deseja reduzir o risco de excluir acidentalmente um objeto. 
250 Capítulo 11 ■ Planejando o armazenamento na nuvem
O Cloud Storage também fornece políticas de gerenciamento do ciclo de vida para alterar automaticamente 
a classe de armazenamento de um objeto ou excluir o objeto após um período especificado. Uma política de ciclo de vida, às vezes chamada de configuração, é um conjunto de regras. As regras incluem uma condição e uma ação. Se 
a condição for verdadeira, a ação será executada. As políticas de gerenciamento do ciclo de vida são aplicadas 
aos buckets e afetam todos os objetos no bucket. 
As condições geralmente são baseadas na idade. Quando um objeto atinge uma determinada idade, ele pode ser 
excluído ou movido para uma classe de armazenamento de custo mais baixo. Além da idade, as condições podem verificar o 
número de versões, se a versão está ativa, se o objeto foi criado antes de uma data específica e se o objeto está em uma determinada classe de armazenamento.
Você pode excluir um objeto ou alterar sua classe de armazenamento. Ambos os 
objetos não versionados e versionados podem ser excluídos. Se a versão ao vivo de um arquivo for excluída, em vez de realmente excluí- 
lo, o objeto será arquivado. Se uma versão arquivada de um objeto for excluída, o objeto será excluído permanentemente. 
Você também pode alterar a classe de armazenamento de um objeto usando o gerenciamento do ciclo de vida. Existem 
restrições sobre quais classes podem ser designadas. Os objetos de armazenamento multirregionais e regionais 
podem ser alterados para nearline ou coldline. O Nearline pode ser alterado apenas para a linha fria. 
Configurando o Cloud Storage 
Você pode criar intervalos no Cloud Storage usando o console. No menu principal, navegue
para Armazenamento e selecione Criar Balde. Isso exibirá um formulário semelhante à Figura 11.3. 
Figura 11.3 Formulário para criar um depósito de armazenamento a partir do console. Opções avançadas 
são exibidas. 
Ao criar um intervalo, você precisa fornecer algumas informações básicas, incluindo um 
nome de intervalo e uma classe de armazenamento. Opcionalmente, você pode adicionar rótulos e escolher 
chaves gerenciadas pelo Google ou chaves gerenciadas pelo cliente para criptografia. Você também pode definir uma política de retenção para impedir alterações nos arquivos ou excluir arquivos antes da hora especificada. 
Depois de criar um bucket, você define uma política de ciclo de vida. No menu Storage no 
console, escolha a opção Browse, conforme mostrado na Figura 11.4. 
Tipos de sistemas de armazenamento 251
Figura 11.4 A lista de buckets inclui um link para definir ou modificar políticas de ciclo de vida. 
Observe que a coluna Lifecycle indica se uma configuração de ciclo de vida está ativada. 
Escolha um bucket para criar ou modificar um ciclo de vida e clique em None ou Enabled na 
coluna Lifecycle . Isso exibirá um formulário como na Figura 11.5. 
Figura 11.5 Ao criar uma política de ciclo de vida, clique na opção Adicionar Regra para definir 
uma regra. 

252 Capítulo 11 ■ Planejando o armazenamento na nuvem 
Quando você adiciona uma regra, precisa especificar a condição do objeto e a ação. As 
opções de condição são Idade, Dados de criação, Classe de armazenamento, Versões mais recentes e Estado ativo. O Live 
State aplica-se a objetos de versão e você pode definir sua condição para ser aplicada ao vivo ou
versões arquivadas de um objeto. A ação pode ser definir a classe de armazenamento como nearline 
ou coldline. 
Vamos ver uma política de exemplo. Na seção Navegador do Cloud Storage no 
console, você pode ver uma lista de buckets e suas políticas de ciclo de vida atual, conforme mostrado na 
Figura 11.6. 
Figura 11.6 Listagem de buckets no Cloud Storage Browser 
Clique no status da política de um bucket para criar uma regra de ciclo de vida (veja a Figura 11.7). 
F igure 11.7 Formulário para adicionar uma regra de ciclo de vida a um bucket 
O formulário Add Object Lifecycle Rule aparece como na Figura 11.8. Nesse formulário, você pode 
especificar as condições do objeto, como Age e Storage Class, e a ação, como Set To 
Nearline. 
Tipos de sistemas de armazenamento 253
Figura 11.8 Adicione uma regra de ciclo de vida de objeto a um balde. 
Tipos de armazenamento 
ao planejar uma solução de armazenamento Ao planejar uma solução de armazenamento, um fator a considerar é o tempo necessário para acessar os dados. 
Caches, como Memorystore, oferecem o tempo de acesso mais rápido, mas estão limitados à quantidade 
de memória disponível. Os caches são voláteis; quando o servidor é desligado, o conteúdo do 
cache é perdido. Você deve salvar o conteúdo do cache no armazenamento persistente em 
intervalos regulares para ativar a recuperação para o momento em que o conteúdo do cache 
foi salvo pela última vez. 
O armazenamento persistente é usado para dispositivos de armazenamento de bloco, como discos conectados a VMs. 
O GCP oferece drives SSD e HDD. Os SSDs oferecem desempenho mais rápido, mas custam mais. HDDs
são usados ​​quando grandes volumes de dados precisam ser armazenados em um sistema de arquivos, mas os usuários dos dados 
não precisam do acesso mais rápido possível. 
O 
armazenamento de objetos é usado para armazenar grandes volumes de dados por longos períodos de tempo. 
O Cloud Storage tem classes de armazenamento regionais e multirregionais e suporta 
gerenciamento de ciclo de vida e controle de versão. 
Além de escolher um sistema de armazenamento subjacente, você também terá que considerar como os 
dados são armazenados e acessados. Para isso, é importante entender os modelos de dados disponíveis e quando usá-los. 
Modelos de dados de armazenamento 
Existem três categorias amplas de modelos de dados disponíveis no GCP: objeto, relacional e
NoSQL. Além disso, trataremos os produtos otimizados para dispositivos móveis como o Cloud Firestore e o 
Firebase como uma quarta categoria, embora esses armazenamentos de dados utilizem um modelo NoSQL. Seus 
recursos de suporte móvel são suficientemente importantes para garantir sua própria descrição. 
Objeto: Cloud Storage 
O modelo de dados de armazenamento de objetos trata os arquivos como objetos atômicos. Você não pode usar 
comandos de armazenamento de objetos para ler blocos de dados ou sobrescrever partes do objeto. Se você precisar atualizar um 
objeto, deverá copiá-lo para um servidor, fazer a alteração e depois copiar a versão atualizada de 
volta para o sistema de armazenamento de objetos. 
O armazenamento de objetos é usado quando você precisa armazenar grandes volumes de dados e não precisa
acesso granular aos dados dentro de um objeto enquanto ele está no armazenamento de objetos. Esse modelo de dados 
é adequado para dados arquivados, dados de treinamento de aprendizado de máquina e dados antigos da Internet das Coisas 
(IoT) que precisam ser salvos, mas não são mais analisados ​​ativamente. 
Relacional: os bancos de dados Cloud SQL, Cloud Spanner e BigQuery 
Relational têm sido o principal armazenamento de dados para empresas há décadas. 
Bancos de dados relacionais suportam consultas freqüentes e atualizações de dados. Eles são usados ​​quando é 
importante que os usuários tenham uma visão consistente dos dados. Por exemplo, se dois usuários estiverem lendo 
dados de uma tabela relacional ao mesmo tempo, eles verão os mesmos dados. Isso nem sempre é
o caso de bancos de dados que podem ter inconsistências entre réplicas de dados, como 
alguns bancos de dados NoSQL. 
Bancos de dados relacionais, como Cloud SQL e Cloud Spanner, suportam transações de banco de dados. Uma transação é um conjunto de operações com garantia de sucesso ou falha em sua 
totalidade - não há chance de que algumas operações sejam executadas e outras não. Por 
exemplo, quando um cliente compra um produto, a contagem do número de produtos disponíveis é diminuída na tabela de estoque e um registro é adicionado a uma 
tabela de produtos adquiridos pelo cliente . Com as transações, se o banco de dados falhar após a actualização do inventário mas antes de 
Armazenamento de Dados Modelos 255 
atualizar a tabela produtos da compra para o cliente, o banco de dados irá reverter a parcialmente
transação executada quando o banco de dados é reiniciado. 
O Cloud SQL e o Cloud Spanner são usados ​​quando os dados são estruturados e modelados para 
bancos de dados relacionais. O Cloud SQL é um serviço de banco de dados gerenciado que fornece 
bancos de dados MySQL e PostgreSQL. O Cloud SQL é usado para bancos de dados que não precisam escalonar 
horizontalmente, ou seja, adicionando servidores adicionais a um cluster. Os bancos de dados do Cloud SQL são 
dimensionados verticalmente, ou seja, são executados em servidores com mais memória e mais CPU. O Cloud 
Spanner é usado quando você tem volumes extremamente grandes de dados ou dados relacionais que 
precisam ser distribuídos globalmente, garantindo consistência e integridade de transações 
em todos os servidores.
As grandes empresas geralmente usam o Cloud Spanner para aplicativos como cadeias de suprimento globais e 
aplicativos de serviços financeiros, enquanto o Cloud SQL é frequentemente usado para aplicativos da Web, business intelligence e aplicativos de comércio eletrônico. 
O BigQuery é um serviço projetado para um armazém de dados e aplicativos analíticos. O BigQuery 
foi projetado para armazenar petabytes de dados. O BigQuery funciona com um grande número de linhas e colunas de dados e não é adequado para aplicativos orientados a transações, como comércio eletrônico 
ou suporte para aplicativos da Web interativos. 
Configurando o Cloud SQL 
Você pode criar uma instância do Cloud SQL navegando até o Cloud SQL no menu principal do 
console e selecionando Criar Instância. Você será solicitado a escolher um MySQL ou
PostgreSQL, como mostra a Figura 11.9. 
Figura 11.9 O Cloud SQL fornece instâncias do MySQL e do PostgreSQL. 
Se você escolher o PostgreSQL, será levado para o formulário Configuração. Se você escolher o 
MySQL, você será solicitado a escolher uma 
instância MySQL da Primeira Geração ou Segunda Geração (veja a Figura 11.10). A menos que você precise usar uma versão mais antiga do MySQL, uma 
instância de segunda geração é recomendada. A segunda geração do MySQL fornecerá 
maior capacidade, configurações opcionais de alta disponibilidade, suporte para o MySQL 5.7 e, 
em muitos casos, menor custo. 
256 Capítulo 11 ■ Planejando o armazenamento na nuvem 
F igure 11.10 As instâncias do MySQL estão disponíveis nas instâncias Primeira e Segunda Geração.
Para configurar uma instância do MySQL, você precisará especificar um nome, uma senha root, uma região 
e uma zona. As opções de configuração incluem o seguinte: 
■ Versão do MySQL. 
■ Conectividade, onde você pode especificar se deve usar um endereço IP público ou privado. 
■ tipo de máquina. O padrão é um db-n1-standard-1 com 1 vCPU e 3.75GB de memória. 
■ Backups automáticos. 
■ réplicas de failover. 
■ Sinalizadores de banco de dados. Eles são específicos do MySQL e incluem a capacidade de definir um 
sinalizador somente leitura do banco de dados e definir o tamanho do cache de consulta. 
■ Definir uma janela de tempo de manutenção. 
■ Etiquetas. 
A Figura 11.11 mostra o formulário de configuração para a segunda geração do MySQL, e a Figura 11.12 
mostra o formulário de configuração do PostgreSQL.
Modelos de dados de armazenamento 257 
Figura 11: Formulário de configuração para uma instância de MySQL de segunda geração 
258 Capítulo 11 ■ Planejando o armazenamento na nuvem 
Figura 11.12 Formulário de configuração para uma instância do PostgreSQL 
Modelos de dados de armazenamento 269 
Configurando o Cloud Spanner 
Se você precisar criar um banco de dados global e consistente com suporte para transações, você 
deve considerar o Cloud Spanner. Dada a natureza avançada do Spanner, sua configuração é 
surpreendentemente simples. No console, navegue até o Cloud Spanner e selecione Create Instance para 
exibir um formulário como a Figura 11.13. 
Figura 11.13 O formulário de configuração do Cloud Spanner no Cloud Console 
260 Capítulo 11 ■ Planejando o armazenamento na nuvem
Você precisa fornecer um nome de instância, um ID de instância e um número de nós. 
Você também terá que escolher uma configuração regional ou multirregional para determinar onde os nós e os dados estão localizados. Isso determinará o 
local de armazenamento de custo e replicação . Se você selecionar regional, escolherá da lista de regiões disponíveis, como 
us-west1, asia-east1 e europe-north1. 
Deve-se notar que o Cloud Spanner é significativamente mais caro do que o Cloud SQL 
ou outras opções de banco de dados. Um único nó regional localizado em us-central1 custa US $ 0,90 por 
hora, enquanto um único nó multirregional em nam3 custa US $ 3 por hora. Um único 
nó multirregional em nam-eur-asia1 custa US $ 9 por hora. 
Configurando o BigQuery
O BigQuery é um serviço de análise gerenciada, que fornece armazenamento, além de 
ferramentas de análise de consulta, estatística e aprendizado de máquina. O BigQuery não exige que você configure instâncias. 
Em vez disso, ao navegar pela primeira vez no BigQuery a partir do menu do console, você verá um formulário 
como na Figura 11.14. 
F igure 11.14 Interface do usuário do BigQuery para criar e consultar dados 
A primeira tarefa para usar o BigQuery é criar um conjunto de dados para conter dados. Você faz isso 
clicando em Create Dataset para exibir o formulário mostrado na Figura 11.15. 
Modelos de dados de armazenamento 261 
Figura 11.15 Formulário para criar um conjunto de dados no BigQuery 
Ao criar um conjunto de dados, você terá que especificar um nome e selecionar uma região na qual
para armazená-lo. Nem todas as regiões suportam o BigQuery. Atualmente, você tem a opção de nove locais 
nos Estados Unidos, na Europa e na Ásia. 
No Capítulo 12, discutiremos como carregar e consultar dados no BigQuery e em outros 
bancos de dados do GCP. 
NoSQL: os bancos de dados NoSQL do Datastore, Cloud Firestore e Bigtable 
não usam o modelo relacional e não exigem uma estrutura ou 
esquema fixo . Os esquemas de banco de dados definem quais tipos de atributos podem ser armazenados. Quando nenhum 
esquema fixo é necessário, os desenvolvedores têm a opção de armazenar atributos diferentes em 
registros diferentes . O GCP tem três opções NoSQL: 
■ Cloud Datastore 
■ Cloud Firestore 
■ Cloud Bigtable 
Datastore Features
O armazenamento de dados é um banco de dados de documentos. Isso não significa que seja usado para armazenar documentos 
como planilhas ou arquivos de texto, mas os dados no banco de dados são organizados em uma estrutura 
chamada documento. Os documentos são compostos de conjuntos de pares de valores-chave. Um exemplo simples 
é o seguinte: 
{ 
book: "ACE Exam Guide", 
 capítulo: 11, 
 duração: 20, 
 tópico: "storage" 
 } 
262 Capítulo 11 ■ Planejando o armazenamento na nuvem 
Este exemplo descreve as características de um capítulo de um livro. . Existem quatro chaves ou 
propriedades neste exemplo: livro, capítulo, tamanho e armazenamento. Esse conjunto de pares de valores-chave 
é chamado de entidade na terminologia do Datastore. Entidades geralmente têm propriedades em comum, mas
Como o Datastore é um banco de dados sem esquema, não há requisito de que todas as entidades tenham o 
mesmo conjunto de propriedades. Veja um exemplo: 
{ 
book: "ACE Exam Guide", 
 Capítulo: 11, 
 tópico: "computing", 
 number_of_figures: 8 
 } 
Datastore é um banco de dados gerenciado, portanto, os usuários do serviço não precisam gerenciar servidores 
ou instalar software de banco de dados. O armazenamento de dados particiona dados automaticamente e aumenta ou diminui 
conforme a demanda exigir. 
O armazenamento de dados é usado para necessidades de armazenamento não analíticas e não relacionais. É uma boa escolha para catálogos de produtos, que têm muitos tipos de produtos com características ou propriedades variadas. Também 
é uma boa opção para armazenar perfis de usuário associados a um aplicativo.
O armazenamento de dados tem alguns recursos em comum com bancos de dados relacionais, como suporte 
a transações e índices para melhorar o desempenho da consulta. A principal diferença é que o 
Datastore não exige um esquema ou uma estrutura fixa e não oferece suporte a 
operações relacionais , como unir tabelas ou computar agregados, como somas e contagens. 
A configuração do armazenamento de 
dados do armazenamento de dados, como o BigQuery, é um serviço de banco de dados gerenciado que não exige a especificação de configurações de nós. Em vez disso, você pode trabalhar no console para adicionar entidades ao banco de dados. A Figura 11.16 mostra o formulário inicial exibido quando você acessa o Datastore 
no Cloud Console pela primeira vez. 
Figura 11.16 A interface do usuário do Datastore permite criar e consultar dados.
Data Storage Models 263 
selecione Criar Entidade para exibir um formulário para adicionar dados em uma estrutura de dados do documento, como 
mostrado na Figura 11.17. 
Figura 11.17 Adicionando entidades ao armazenamento de dados 
Ao criar uma entidade, você especifica um espaço para nome, que é uma maneira de agrupar entidades de maneira muito 
semelhante às tabelas do grupo de esquemas em um banco de dados relacional. Você precisará especificar um tipo, que 
é análogo a uma tabela em um banco de dados relacional. Cada entidade requer uma chave, que pode ser uma 
chave numérica auto - gerada ou uma chave personalizada. 
Na próxima 
etapa , você adicionará uma ou mais propriedades que possuem nomes, tipos e valores. Os tipos 
incluem string, data e hora, Boolean e outros tipos estruturados, como matrizes.
Detalhes adicionais sobre como carregar e consultar dados no Datastore estão no Capítulo 12. 
Recursos do 
Cloud Firestore O Cloud Firestore é um banco de dados NoSQL gerenciado que usa o modelo de dados do documento. 
Isso é semelhante ao Datastore e, de fato, os bancos de dados do Datastore podem usar o mais novo 
sistema de armazenamento do Cloud Firestore. Uma vantagem do Cloud Firestore é que ele é projetado para armazenar, sincronizar e consultar dados em aplicativos distribuídos, como aplicativos móveis. 
Os aplicativos podem ser atualizados automaticamente em tempo quase real quando os dados são alterados no 
back - end. 
O Cloud Firestore suporta transações e fornece replicação multirregional. 
Configurando o Cloud Firestore
O Cloud Firestore é um serviço de banco de dados gerenciado que não exige que você configure 
instâncias. Você precisa, no entanto, escolher um sistema de armazenamento de dados. As opções incluem o 
uso do Datastore, o uso do Firestore no modo Datastore (que usa o sistema de armazenamento do Datastore) ou o uso do Firestore no modo nativo. Novos usuários do Firestore devem usar o Firestore no 
modo nativo (veja a Figura 11.18). 
Figura 11.18 O Firestore pode ser configurado para usar o sistema de armazenamento backend do Datastore 
ou seu novo sistema de armazenamento nativo. 
Depois de selecionar o sistema de armazenamento, você será solicitado a selecionar um local para o banco de dados, conforme mostrado na Figura 11.19. 
Modelos de dados de armazenamento 269 
Figura 11.19 Selecionando um local para um banco de dados do Firebase
O Firestore criará um banco de dados, que pode levar alguns minutos. Quando o banco de dados estiver 
pronto, você verá uma exibição, como na Figura 11.20. 
No Capítulo 12, vamos examinar o carregamento e a consulta de dados do Firestore. 
Recursos do 
Bigtable O Bigtable é outro banco de dados NoSQL, mas, ao contrário do Datastore, é um banco de dados de coluna ampla, 
não um banco de dados de documentos. Bancos de dados de coluna larga, como o nome indica, armazenam tabelas que 
podem ter um grande número de colunas. Nem todas as linhas precisam usar todas as colunas, de modo que 
é como o armazenamento de dados - não é necessário um esquema fixo para estruturar os dados.
O Bigtable é projetado para bancos de dados em escala de petabytes. Os bancos de dados operacionais, como o armazenamento de dados da IoT e o processamento analítico, como aplicativos de ciência de dados, podem usar efetivamente o 
Bigtable. Esse banco de dados foi projetado para fornecer uma latência consistente de baixo milissegundo. Bigtable 
é executado em clusters e escala horizontalmente. 
O Bigtable é projetado para aplicativos com altos volumes de dados e uma ingestão de 
dados em alta velocidade . Séries temporais, IoT e aplicativos financeiros se enquadram nessa categoria. 
266 Capítulo 11 ■ Planejando o armazenamento na nuvem 
Figura 11.20 Banco de dados Firestore pronto para uso 
Configurando o Bigtable No 
Cloud Console, navegue até Bigtable e clique em Criar Instância. Isso exibirá um 
formulário como mostrado na Figura 11.21.
Nesse formulário, você precisará fornecer um nome de instância e um ID de instância. Em seguida, 
escolha entre o modo de produção ou desenvolvimento. Os clusters de produção têm um mínimo de 
três nós e fornecem alta disponibilidade. O modo de desenvolvimento usa instâncias de baixo custo 
sem replicação ou alta disponibilidade. Você também precisará escolher SSD ou HDD 
para discos permanentes usados ​​pelo banco de dados. 
O Bigtable pode suportar vários clusters. Para cada cluster, você precisará especificar um 
ID de cluster , um local de região e zona e o número de nós no cluster. O cluster pode ser 
replicado para melhorar a disponibilidade. 
No Capítulo 12, descreveremos como carregar e consultar dados no Bigtable. 
Modelos de dados de armazenamento 267
Formulário de configuração do F igure 11.21 para Bigtable 
268 Capítulo 11 ■ Planejando o armazenamento na nuvem 
A necessidade de vários bancos de dados As 
organizações de saúde e as instalações médicas armazenam e gerenciam uma ampla gama de dados 
sobre pacientes, seus tratamentos e os resultados. Os registros médicos de um paciente incluem 
informações demográficas, como nome, endereço, idade e assim por diante. Os registros médicos também 
armazenam informações detalhadas sobre condições médicas e diagnósticos, bem como tratamento, 
como medicamentos prescritos e procedimentos realizados. Este tipo de dados é altamente estruturado. Suporte de transação e consistência forte são necessários. Bancos de dados relacionais, como o 
Cloud SQL, são uma boa solução para esse tipo de aplicativo.
Os dados médicos armazenados em bancos de dados relacionais transacionais são valiosos para analisar padrões em tratamentos e recuperação. Por exemplo, cientistas de dados poderiam usar registros médicos para identificar padrões associados à readmissão no hospital. No entanto, 
os bancos de dados relacionais transacionais não são adequados para análises. A melhor opção é usar o 
BigQuery e criar um data warehouse com dados estruturados de maneira a facilitar a 
análise de dados. Os dados do sistema transacional são extraídos, transformados e carregados 
em um conjunto de dados do Bigtable. 
Escolhendo uma solução de armazenamento: 
Diretrizes a serem consideradas O 
GCP oferece várias soluções de armazenamento. Como engenheiro de nuvem, você pode ter que ajudar a planejar e
implementar soluções de armazenamento para uma ampla variedade de aplicativos. As diferentes soluções de armazenamento prestam-se a diferentes casos de uso e, em muitos aplicativos corporativos, você 
descobrirá que precisa de dois ou mais produtos de armazenamento diferentes para dar suporte a toda a gama de 
requisitos de aplicativos. Aqui estão vários fatores a serem lembrados ao escolher 
soluções de armazenamento : 
Ler e gravar padrões Alguns aplicativos, como aplicativos de contabilidade e de vendas no varejo, leem e gravam dados com frequência. Há também atualizações freqüentes nesses aplicativos. 
Eles são melhor atendidos por uma solução de armazenamento, como o Cloud SQL, se os dados estiverem estruturados; 
no entanto, se você precisar de um banco de dados global que suporte operações de leitura / gravação relacional,
Cloud Spanner é uma escolha melhor. Se você estiver gravando dados a taxas consistentemente altas e em 
grandes volumes, considere o Bigtable. Se você estiver escrevendo arquivos e baixando-os na 
íntegra, o Cloud Storage é uma boa opção. 
A Consistência de Consistência garante que um usuário 
que esteja lendo dados do banco de dados obterá os mesmos dados, não importando qual servidor em um cluster responda à solicitação. Se você precisa de 
consistência forte , que está sempre lendo os dados mais recentes, o Cloud SQL e o Cloud Spanner 
Summary 269 
são boas opções. O armazenamento de dados pode ser configurado para consistência forte, mas as operações de E / S demorarão 
mais do que se uma configuração de consistência menos estrita for usada. O armazenamento de dados é um bom
opção se seus dados não estiverem estruturados; Caso contrário, considere um dos bancos de dados relacionais. 
Os bancos de dados NoSQL oferecem pelo menos consistência eventual, o que significa que algumas réplicas podem não 
estar sincronizadas por um curto período de tempo. Durante esses períodos, é possível ler dados obsoletos. 
Se seu aplicativo puder tolerar isso, você poderá descobrir que requisitos de consistência menos rígidos podem levar a operações de leitura e gravação mais rápidas. 
Suporte a Transações Se você precisar executar transações atômicas em seu aplicativo, use 
um banco de dados que as suporte. Você pode implementar suporte à transação em seu 
aplicativo, mas esse código pode ser difícil de desenvolver e manter. Os bancos de dados relacionais, Cloud SQL e Spanner e o Datastore fornecem suporte a transações.
Custo O custo de usar um determinado sistema de armazenamento dependerá da quantidade de dados 
armazenados, da quantidade de dados recuperados ou digitalizados e das cobranças por unidade do sistema de armazenamento. 
Se você estiver usando um serviço de armazenamento no qual você provisiona as VMs, também será necessário contabilizar 
esse custo. 
Latência A latência é o tempo entre o início de uma operação, como uma solicitação para ler uma 
linha de dados de um banco de dados, até o momento em que ela é concluída. O Bigtable fornece operações consistentemente baixas em milissegundos. O Spanner pode ter latências mais longas, mas com essas latências mais longas, 
você obtém um banco de dados escalonável globalmente consistente. 
Em geral, a escolha de um armazenamento de dados é sobre como fazer compensações. Em um mundo ideal, poderíamos
tem um banco de dados de baixo custo, globalmente escalável, de baixa latência e fortemente consistente. Nós não vivemos 
em um mundo ideal. Temos que desistir de uma ou mais dessas características. 
No próximo capítulo, você aprenderá a usar cada uma das soluções de armazenamento descritas 
aqui, com ênfase no carregamento e na consulta de dados. 
Resumo 
Ao planejar o armazenamento em nuvem, considere os tipos de sistemas de armazenamento e os tipos de modelos de dados. Os sistemas de armazenamento fornecem o hardware e a estrutura organizacional básica usada para 
armazenar dados. Os modelos de dados organizam os dados em estruturas lógicas que determinam como os 
dados são armazenados e consultados em um banco de dados. 
Os principais sistemas de armazenamento disponíveis no GCP são Memorystore, um serviço de cache gerenciado,
e discos permanentes, que são discos acessíveis pela rede para VMs no Compute Engine e no 
Kubernetes Engine. O Cloud Storage é o sistema de armazenamento de objetos do GCP. 
Os modelos de dados primários são objeto, relacional e NoSQL. Os bancos de dados NoSQL no 
GCP são subdivididos em bancos de dados de documentos e de colunas largas. O Cloud Storage 
usa um modelo de dados de objeto. O Cloud SQL e o Cloud Spanner usam bancos 
de dados relacionais para aplicativos de processamento de transações. O BigQuery usa um modelo relacional para 
aplicativos analíticos e de armazenamento de dados . O Datastore e o Firebase são bancos de dados de documentos. 
O Bigtable é uma tabela de coluna ampla. 
270 Capítulo 11 ■ Planejando o armazenamento na nuvem 
Ao escolher sistemas de armazenamento de dados, considere padrões de leitura e gravação, consistência
requisitos, suporte a transações, custo e latência. 
Fundamentos do exame 
Conheça os principais tipos de sistemas de armazenamento, incluindo caches, discos permanentes e armazenamento de objetos. 
Os caches são usados ​​para melhorar o desempenho do aplicativo, reduzindo a necessidade de ler os 
bancos de dados no disco. Os caches são limitados pela quantidade de memória disponível. Discos permanentes 
são dispositivos de rede conectados a VMs. Discos persistentes podem ser anexados a várias 
VMs no modo somente leitura. O armazenamento de objetos é usado para armazenar arquivos para acesso compartilhado e armazenamento de longo prazo. 
Conheça os principais tipos de modelos de dados. Bancos de dados relacionais são usados ​​para 
sistemas de processamento de transações que exigem suporte a transações e consistência forte. Cloud SQL
e Cloud Spanner são bancos de dados relacionais usados ​​para aplicativos de processamento de transações. 
O BigQuery usa um modelo relacional, mas é projetado para armazéns de dados e análises. O 
modelo de objeto é uma alternativa para um modelo de sistema de arquivos. Objetos, armazenados como arquivos, são tratados como 
unidades atômicas. Os modelos de dados NoSQL incluem modelos de dados de documentos e modelos de coluna larga. 
O Datastore e o Firebase são bancos de dados de modelo de documento. O Bigtable é um banco de dados de coluna ampla. 
Conheça as quatro classes de armazenamento no Cloud Storage. Regional, multirregional, nearline e 
coldline são as quatro classes de armazenamento. A classe multirregional replica dados entre regiões. 
O armazenamento regional replica dados entre zonas. O Nearline é projetado para acesso pouco frequente,
menos de uma vez por mês. O armazenamento do Coldline é projetado para armazenamento de arquivos, com arquivos 
acessados ​​menos de uma vez por ano. O armazenamento nearline e coldline incorre 
em cobranças de recuperação, além de cobranças com base no tamanho dos dados. 
Saiba que os aplicativos em nuvem podem exigir mais de um tipo de armazenamento de dados. Por exemplo, um aplicativo pode precisar de um cache para reduzir a latência ao consultar dados no Cloud SQL, 
armazenamento de objetos para o armazenamento de longo prazo de arquivos de dados e BigQuery para 
relatórios e análises de data warehousing . 
Saiba que você pode aplicar configurações de ciclo de vida em intervalos do Cloud Storage. Os ciclos de vida 
são usados ​​para excluir arquivos e alterar a classe de armazenamento. Saiba que classe regional e multirregional
pode ser alterado para nearline ou coldline. O armazenamento nearline pode mudar para coldline. O 
armazenamento de classe regional não pode ser alterado para multirregional e multirregional não pode ser alterado para 
regional. 
Conheça as características de diferentes armazenamentos de dados que ajudam a determinar qual é a 
melhor opção para suas necessidades. Ler e escrever padrões, requisitos de consistência, 
suporte a transações, custo e latência são frequentemente fatores. 

Neste capítulo, discutiremos como criar 
sistemas de armazenamento de dados em vários produtos do Google Cloud Platform (GCP), 
incluindo Cloud SQL, Cloud Datastore, BigQuery, Bigtable, 
Cloud Spanner, Cloud Pub / Sub, Cloud Dataproc e Cloud
Armazenamento. Você aprenderá a criar bancos de dados, buckets e outras estruturas de dados básicas 
, além de executar tarefas importantes de gerenciamento, como fazer backup de dados e verificar 
o status de tarefas. 
Implantando e gerenciando o Cloud SQL 
Cloud O SQL é um serviço de banco de dados relacional gerenciado. Nesta seção, você aprenderá a 
fazer o seguinte: 
■ Criar uma instância de banco de dados 
■ Conectar à instância 
■ Criar um banco de dados 
■ Carregar dados no banco de dados 
■ Consultar o banco de dados 
■ Fazer backup do banco de dados 
Usaremos uma instância do MySQL neste seção, mas os procedimentos a seguir são semelhantes 
para o PostgreSQL. 
Criando e Conectando-se a uma Instância MySQL
Descrevemos como criar e configurar uma instância do MySQL no Capítulo 11, mas revisaremos 
as etapas aqui. 
No console, navegue até SQL e clique em Criar Instância. Escolha MySQL e, em 
seguida, selecione Tipo de Instância de Segunda Geração. Isso levará a um formulário como na 
Figura 12.1. 
Implementando e gerenciando o Cloud SQL 277 
F u ua 12.1 Criando uma instância do MySQL 
Após alguns minutos, a insta- nância é criada; A lista de instâncias do MySQL será semelhante 
à da Figura 12.2. 
Figura 12.2 Uma listagem de instâncias do MySQL 
Depois que o banco de dados é criado, você pode se conectar iniciando o Cloud Shell e usando o 
comando gcloud sql connect. Este comando pega o nome da instância para conectar
e, opcionalmente, um nome de usuário e senha. É uma boa prática não especificar uma senha 
na linha de comando. Em vez disso, você será solicitado, e ele não será exibido 
enquanto você digita. Você pode ver uma mensagem sobre a lista de permissões do seu endereço IP; Essa é uma 
medida de segurança e permitirá que você se conecte à instância do Cloud Shell. 
Para conectar-se à instância chamada ace-exam-mysql, use o seguinte comando: 
gcloud sql connect ace-exam-mysql –usuário = root 
Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
Isso abre um prompt de linha de comando para a instância do MySQL , conforme mostrado na Figura 12.3. 
F ig ure 12.3 Prompt de linha de comando para trabalhar com o MySQL após conectar-se usando o 
gcloud sql connect
Criando um banco de dados, carregando dados e consultando dados 
No ambiente de linha de comando do MySQL, você usa comandos do MySQL, não 
comandos gcloud . O MySQL usa SQL padrão, portanto, o comando para criar um banco de dados é CREATE 
DATABASE. Você indica o banco de dados para trabalhar com (pode haver muitos em uma única instância) 
usando o comando USE. Por exemplo, para criar um banco de dados e configurá-lo como o 
banco de dados padrão para trabalhar, use: 
CREATE DATABASE ace_exam_book; 
USE ace_exam_book 
Você pode criar uma tabela usando CREATE TABLE. Os dados são inseridos usando o 
comando INSERT . Por exemplo, os seguintes comandos criam uma tabela chamada books e inserem 
duas linhas:
CRIAR livros TABLE (título VARCHAR (255), num_chapters INT, entity_id INT NOT NULL 
\ AUTO_INCREMENT, PRIMARY KEY (entity_id)); INSERT INTO livros (title, num_chapters) 
VALUES ('ACE Exam Study Guide', 18); 
INSERT INTO livros (title, num_chapters) VALUES ('Architecture Exam Study Guide', 
18); 
Para consultar a tabela, use o comando SELECT. Aqui está um exemplo: 
SELECT * from books; 
Isso listará todas as linhas da tabela, como mostra a Figura 12.4. 
Implantando e gerenciando o Cloud SQL 279 
F u nção 12.4 Listando o conteúdo de uma tabela no MySQL 
Fazendo backup do MySQL no Cloud SQL O 
SQL SQL permite backups automáticos e sob demanda.
Para criar um backup sob demanda, clique no nome da instância na página Instâncias no 
console. Isso exibirá a página Detalhes da Instância (veja a Figura 12.5). 
Figura 12.5 Uma página de Detalhes da Instância do MySQL 
280 
Clique na guia Backups para exibir a opção Criar Backup (veja a Figura 12.6). 
Figura 12.6 Formulário usado para clicar em Criar Backup 
Clicar em Criar Backup abre um formulário como o mostrado na Figura 12.7. 
Figura 12.7 Atribua uma descrição a um backup e crie-a. 
Preencha a descrição opcional e clique em Criar. Quando o backup for concluído, ele 
aparecerá na lista de backups, conforme mostrado na Figura 12.8. 
Implantando e gerenciando o Cloud SQL 281
Figura 12.8 Lista de backups disponíveis para esta instância 
Você também pode criar um backup usando o comando gcloud sql backups, que possui 
este formato: 
gcloud sql backups create ––async ––instance [INSTANCE_NAME] 
Aqui, [INSTANCE_NAME] é o nome , como ace-exam-mysql e o parâmetro --async 
é opcional. 
Para criar um backup sob demanda para a instância ace-exam-mysql, use o seguinte 
comando: 
gcloud sql backups create ––async ––instance ace-exam-mysql 
Você também pode fazer com que o Cloud SQL crie backups automaticamente. 
No console, navegue até a página Instância do Cloud SQL, clique no nome da 
instância e, em seguida, clique em Editar Instância. Abra a seção Backups automáticos ativados e preencha
os detalhes de quando criar os backups (veja a Figura 12.9). Você deve especificar um intervalo de tempo 
para quando os backups automáticos devem ocorrer. Você também pode ativar o log binário, que é 
necessário para recursos mais avançados, como a recuperação pontual. 
Para ativar backups automáticos a partir da linha de comando, use o comando gcloud: 
gcloud sql instances patch [INSTANCE_NAME] –backup-start-time [HH: MM] 
Para esta instância de exemplo, você pode executar backups automáticos às 1:00 com o 
seguinte Comando: 
gcloud sql instances patch ace-exam-mysql –backup-start-time 01:00 
282 Capítulo 12 ■ Implantando o armazenamento na Google Cloud Platform 
F ig ure 12.9 Habilitando backups automáticos no Cloud Console 
Implantando e gerenciando o Datastore 283
Implantando e gerenciando o Datastore O 
Capítulo 11 descreveu como inicializar um banco de dados de documentos do Datastore. Agora, você 
verá como criar entidades e adicionar propriedades a um banco de dados de documentos. Você também analisará as 
operações de backup e restauração. 
Adicionando dados a um banco de dados do armazenamento de dados 
Adicione dados a um banco de dados do Datastore usando a opção Entidades na seção Datastore do 
console. A estrutura de dados das Entidades é análoga a um esquema em bancos de dados relacionais. 
Você cria uma entidade clicando em Criar Entidade e preenchendo o formulário que aparece. Aqui 
você precisará preencher o Kind, que é análogo a uma tabela em um banco de dados relacional, e o 
Properties, conforme mostrado na Figura 12.10.
Figura 12.10 Adicionando dados a uma entidade do Datastore 
Depois de criar entidades, você pode consultar o banco de dados do documento usando o GQL, uma linguagem de consulta semelhante ao SQL. A Figura 12.11 mostra um exemplo de consulta usando o comando SELECT. 
283 Capítulo 12 ▪ Implantando armazenamento no Google Cloud Platform 
F ig ure 12.11 Fazendo o armazenamento de dados usando o GGL, uma linguagem de consulta semelhante a SQL 
Fazendo backup do armazenamento de dados 
Para fazer backup de um banco de dados do Datastore, você precisa criar um intervalo do Cloud Storage para armazenar um 
arquivo de backup e conceda permissões apropriadas aos usuários que executam o backup. 
Você pode criar um depósito para backups usando o comando gsutil. 
gsutil mb gs: // [BUCKET_NAME] / 
Aqui, [BUCKET_NAME] é o nome, como ace_exam_backups. No nosso exemplo, usamos
ace_exam_backups e crie esse bucket usando o seguinte: 
gsutil mb gs: // ace_exam_backups / 
Os usuários que criam backups precisam da permissão datastore.databases.export. Se você estiver 
importando dados, precisará do datastore.databases.import. A 
função Administrador de importação do Google Cloud Datastore tem as duas permissões. consulte o Capítulo 17 para obter detalhes sobre como atribuir funções aos 
usuários. 
Implantando e gerenciando o BigQuery 289 
O usuário com a função Administrador de importação de exportação do Cloud Datastore pode fazer um backup 
usando o seguinte comando: 
gcloud –namespaces = '[NAMESPACE]' gs: // [BUCKET_NAME} 
Neste exemplo, o comando para criar um O backup é o seguinte: 
gcloud datastore export –namespaces = '(padrão)' gs: // ace_exam_backups
Para importar um arquivo de backup, use o comando gcloud datastore import: 
gcloud datastore importar gs: // [BUCKET] / [PATH] / [FILE] .overall_export_metadata 
No nosso exemplo, você pode importar usando: 
gcloud datastore import gs: // ace_exam_backups / [FILE] .overall_export_metadata 
Aqui, [FILE] é o nome do arquivo atribuído pelo processo de exportação. 
Implantando e gerenciando o BigQuery O 
BigQuery é um serviço de banco de dados totalmente gerenciado, de modo que o Google cuida dos backups e de outras 
tarefas administrativas básicas. Como engenheiro de nuvem, você ainda tem algumas tarefas administrativas 
ao trabalhar com o BigQuery. Duas dessas tarefas são estimar o custo de uma consulta e 
verificar o status de um trabalho. 
Estimando o custo de consultas no BigQuery
No console, escolha BigQuery no menu de navegação principal para exibir a 
interface de consulta do BigQuery , conforme mostrado na Figura 12.12. 
Figura 12.12 A interface do usuário do BigQuery. Note que esta é uma versão beta da nova 
interface; versões mais antigas serão diferentes. 
286 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
Neste formulário, você pode inserir uma consulta no Editor de Consultas, como uma consulta sobre nomes e 
gêneros na tabela usa_1910_2013, como mostra a Figura 12.13. 
Exemplo 12.13 Exemplo de consulta com quantidade estimada de dados verificados 
Observe no canto inferior direito que o BigQuery fornece uma estimativa de quantos dados 
serão verificados. Você também pode usar a linha de comando para obter essa estimativa usando o bq
comando com a opção ––dry-run. 
bq ––location = [LOCATION] consulta ––use_legacy_sql = false ––dry_run [SQL_QUERY] 
Aqui, [Location] é o local em que você criou o conjunto de dados que você está consultando e 
[SQL_QUERY] é a consulta SQL que você está estimando . 
Você pode usar esse número com a calculadora de preços para estimar o custo. A 
calculadora de preços está disponível em https://cloud.google.com/products/calculator/. Depois de 
selecionar o BigQuery, navegue até a guia On-Demand, insira o nome da tabela que você está 
consultando, defina a quantidade de armazenamento como 0 e insira o tamanho da consulta na 
linha Consultas da seção Precificação de consultas. Certifique-se de usar a mesma unidade de tamanho exibida na
Console do BigQuery. Em nosso exemplo, a unidade de medida é megabytes. Quando você clicar em Adicionar 
à estimativa, a Calculadora de preços exibirá o custo (veja a Figura 12.14). 
A visualização de trabalhos no BigQuery 
Jobs no BigQuery são processos usados ​​para carregar, exportar, copiar e consultar dados. Os trabalhos são criados automaticamente quando você inicia qualquer uma dessas operações. 
Para visualizar o status das tarefas, navegue até o console do BigQuery e clique em Histórico de tarefas no 
menu à esquerda. Isso exibirá uma lista de tarefas e seu status. Observe, na Figura 12.15, 
que a tarefa principal na lista tem uma barra verde, indicando que a tarefa foi concluída com êxito. 
Este é um exemplo de uma exibição expandida de uma entrada de trabalho. Abaixo disso é um resumo de linha única
de um trabalho que falhou. A falha é indicada pelo ícone vermelho ao lado da descrição do trabalho. 
Implantando e gerenciando o BigQuery 287 
F ig ure 12.14 Usando a calculadora de preços para estimar o custo de uma consulta 
F igura 12.15 Uma listagem de status de tarefas no BigQuery 
288 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
Você também pode ver o status de um BigQuery trabalho usando o comando bq show. Por 
exemplo, para mostrar os resultados da tarefa de exportação bem-sucedida mostrada na Figura 12.15, você poderia 
usar este comando: 
bq --location = US show -j gcpace-project: US.bquijob_119adae7_167c373d5c3 
Implantando e gerenciando o Cloud Spanner
Agora, vamos voltar nossa atenção para o Cloud Spanner, o banco de dados relacional global. Nesta seção, você criará um banco de dados, definirá um esquema, inserirá alguns dados e, em seguida, consultará-os. 
Primeiro, você criará uma instância do Cloud Spanner. Navegue até o formulário Cloud Spanner no 
console e selecione Criar Instância. Isso exibirá um formulário conforme mostrado na Figura 12.16. 
Figura 12.16 Crie uma instância do Cloud Spanner. 
Implantação e gerenciamento de nuvem Spanner 289 
Em seguida, você precisa criar um banco de dados na instância. Selecione Create Database no topo da 
página Instance Details, como mostra a Figura 12.17. 
Figura 12.17 Crie um banco de dados dentro de uma instância do Cloud Spanner. 
Ao criar um banco de dados, você precisará usar a linguagem de definição de dados SQL (DDL)
para definir a estrutura das tabelas. SQL DDL é o conjunto de comandos SQL para criar tabelas, 
índices e outras estruturas de dados (consulte a Tabela 12.1). No exemplo da Figura 12.18, você usa 
uma definição de tabela de Cantores fornecida pelo Google no Guia de início rápido do Cloud Spanner (https: // 
cloud.google.com/spanner/docs/quickstart-console). 
Tabela 12.1 Comandos de definição de dados SQL 
Comando Descrição 
CREATE TABLE Cria uma tabela com colunas e tipos de dados especificados 
CREATE INDEX Cria um índice nas colunas especificadas 
ALTER TABLE Altera a estrutura da tabela 
DROP TABLE Remove a tabela do esquema do banco de dados 
DROP INDEX Remove o índice do esquema do banco de dados
Depois de executar o comando CREATE TABLE, você verá uma listagem da estrutura da tabela, 
como na Figura 12.19. 
290 Capítulo 12 ■ Implantando o armazenamento na biblioteca do Google Cloud Platform 
12.18 Crie uma tabela no banco de dados. 
F ig ure 12,19 Lista de colunas da tabela na tabela 
implantação e gerenciamento de nuvem Spanner 291 
Para adicionar dados à tabela, selecione a tabela de dados na página de detalhes da tabela, como mostrado na 
Figura 12.20. 
Figura 12.20 Selecione a guia Dados para inserir dados na tabela. 
Quando você adiciona uma linha, você verá um formulário como o da Figura 12.21, que mostra as 
colunas na tabela. Neste exemplo, as colunas são SingerID, BirthDate, FirstName, 
LastName e SingerInfo.
Figura 12.21 Dados inseridos na tabela 
Finalmente, você pode executar uma consulta selecionando a consulta na página Detalhes da tabela (conforme 
mostrado na Figura 12.22). 
292 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
F igura 12.22 Consulte uma tabela no formulário Consulta. 
O Cloud Spanner é um serviço de banco de dados gerenciado, portanto, você não precisará corrigir, fazer backup ou 
executar outras tarefas básicas de administração de dados. Suas tarefas e as dos modeladores de dados e 
engenheiros de software se concentrarão em tabelas e consultas de projeto. 
Implantando e gerenciando o 
Cloud Pub / Sub
Há duas tarefas necessárias para implantar uma fila de mensagens do Pub / Sub: criando um tópico e criando uma assinatura. Um tópico é uma estrutura na qual os aplicativos podem enviar mensagens. Pub / Sub 
recebe as mensagens e as mantém até serem lidas por um aplicativo. Aplicativos 
ler mensagens usando uma assinatura. 
O primeiro passo para trabalhar com Pub / Sub é navegar para a página Pub / Sub no Cloud 
Console. Na primeira vez que você usar o Pub / Sub, o formulário será semelhante à Figura 12.23. 
Implantar e gerenciar o Cloud Pub / Sub 293 
F ig of 12.23 Crie um tópico Pub / Sub. 
Ao clicar em Criar um Tópico, você será solicitado a fornecer um nome para o tópico, como na 
Figura 12.24. 
F ig ure 12.24 Nomeie um tópico.
Você verá uma lista de tópicos exibidos na página Tópicos depois de criar o primeiro tópico, como 
mostra a Figura 12.25. 
Figura 12.25 Lista de tópicos 
Para criar uma assinatura para um tópico, clique no ícone de três pontos no final da 
linha de resumo do tópico na listagem. O menu exibido inclui uma opção Criar assinatura 
no Google Cloud Platform 
(consulte a Figura 12.26). Clique em Criar Assinatura para criar uma assinatura para esse tópico. Isso 
exibirá um formulário como o mostrado na Figura 12.27. 
F ig ra u ç ã o 12.26 Criando uma assinatura para um tópico 
F ig ra u ra 12.27 O formulário para criar uma assinatura 
Implantando e gerenciando o Cloud Bigtable 295
Para criar uma assinatura, especifique um nome de assinatura e um tipo de entrega. As assinaturas 
podem ser extraídas, em que o aplicativo lê de um tópico ou é enviado por push, no qual a assinatura grava mensagens em um nó de extremidade. Se você quiser usar uma assinatura de envio, 
precisará especificar o URL de um terminal para receber a mensagem. 
Depois que uma mensagem é lida, o aplicativo que lê a mensagem confirma o recebimento da 
mensagem. O Pub / Sub aguardará o período de tempo especificado no 
parâmetro Prazo de Confirmação . O tempo de espera pode variar de 10 a 600 segundos. 
Você também pode especificar um período de retenção, que é o período de tempo para manter uma mensagem que não pode ser entregue. Após o período de retenção, as mensagens são excluídas 
do tópico.
Quando você concluir a criação de uma assinatura, verá uma lista de assinaturas como a 
mostrada na Figura 12.28. 
Figura 12.28 Uma lista de assinaturas 
Além de usar o console, você pode usar os comandos gcloud para criar tópicos e assinaturas. Os comandos para criar tópicos e inscrições são os seguintes: 
gcloud pubsub topics create [TÓPICO-NOME] 
gcloud pubsub assinaturas create [NOME DA ASSOCIAÇÃO] ––topico [TOPIC-NAME] 
Implantando e gerenciando o 
Cloud Bigtable 
Como engenheiro de nuvem, você pode precisar para criar um cluster Bigtable ou conjunto de servidores executando 
serviços Bigtable, bem como criar tabelas, adicionar dados e consultar esses dados.
Para criar uma instância do Bigtable, navegue até o console do Bigtable e clique em Criar Instância. 
Isso exibirá um formulário como o mostrado na Figura 12.29. (Veja o Capítulo 11 para adicionais 
informações sobre como criar uma instância Bigtable.) 
296 Capítulo 12 ■ A implementação do armazenamento no Google Cloud Platform 
F ig ure 12,29 Criando uma instância Bigtable 
Grande parte do trabalho que você vai fazer com Bigtable é feito na linha de comando. 
Para criar uma tabela, abra um navegador Cloud Shell e instale o comando cbt. Ao contrário dos 
bancos de dados relacionais, o Bigtable é um banco de dados NoSQL e não usa o comando SQL. 
Em vez disso, o comando cbt possui subcomandos para criar tabelas, inserir dados e consultar tabelas 
(consulte a Tabela 12.2). 
Implantando e gerenciando o Cloud Bigtable 297
Tabela 12.2 Comandos cbt 
Comando Descrição 
createtable Cria uma tabela 
createfamily Cria uma família de colunas 
read Lê e exibe linhas 
ls Lista tabelas e colunas 
Para configurar cbt no Cloud Shell, insira os seguintes comandos: 
gcloud components update 
gcloud componentes cbt 
Bigtable requer uma variável de ambiente chamada instance para ser definido, incluindo-o em um 
arquivo de configuração .cbt chamado .cbtrc, que é mantido no diretório inicial. 
Por exemplo, para definir a instância como ace-exam-bigtable, digite este comando no 
prompt da linha de comando: 
echo instance = ace-exam-bigtable >> ~ / .cbtrc
Agora os comandos do cbt irão operar nessa instância. Para criar uma tabela, emita um comando 
como este: 
cbt createtable ace-exam-bt-table 
O comando ls lista as tabelas. Aqui está um exemplo: 
cbt ls 
Isso exibirá uma lista de todas as tabelas. Tabelas contêm colunas, mas o Bigtable também tem um 
conceito de famílias de colunas. Para criar uma família de colunas chamada colfam1, use o seguinte 
comando: 
cbt createfamily ace-exam-bt-table colfam1 
Para definir um valor da célula com a coluna colfam1 em uma linha chamada row1, use o seguinte comando: 
cbt set ace-exam -bt-table row1 colfam1: col1 = ace-exam-value 
298 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform
Para exibir o conteúdo de uma tabela, use um comando de leitura como este: 
cbt read ace-exam-bt-table 
O comando read gerará uma saída como a mostrada na Figura 12.30. 
F ig ure 12.30 Exibir o conteúdo da tabela usando o comando cbt read 
Implantando e gerenciando o 
Cloud Dataproc 
Cloud O Dataproc é o serviço Apache Spark e Apache Hadoop gerenciado pelo Google. Tanto o 
Spark quanto o Hadoop são projetados para aplicativos de “big data”. O Spark suporta análise e 
aprendizado de máquina, enquanto o Hadoop é adequado para aplicativos em lote e de big data. Como 
engenheiro de nuvem , você deve estar familiarizado com a criação de um cluster do Dataproc e o envio de tarefas para 
execução no cluster.
Para criar um cluster, navegue até a parte do Dataproc do Cloud Console (consulte a Figura 12.31). 
Figura 12.31 Página do console do Dataproc 
Crie um cluster do Dataproc preenchendo o formulário Create Cluster. Você precisará especificar 
o nome do cluster e uma região e zona. Você também vai precisar para especificar o modo de cluster, 
implantação e gerenciamento de nuvem Dataproc 299 
que pode ser um único nó, normal ou alta disponibilidade. Único nó é útil para o desenvolvimento. O padrão tem apenas um nó mestre, portanto, se ele falhar, o cluster se tornará inacessível. 
O modo de alta disponibilidade usa três mestres. 
Você também precisará especificar informações de configuração da máquina para os nós principais
e os nós do trabalhador. Você especificará as informações de CPUs, memória e disco. O 
modo de cluster determina o número de nós principais, mas você pode escolher o número de 
nós do trabalhador . Se você optar por expandir a lista de opções avançadas, poderá indicar que deseja 
usar VMs preemptivas e especificar um número de VMs preemptivas a serem executadas (consulte a Figura 12.32). 
Figura 12.32 Crie um cluster do Dataproc. 
300 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
Depois de criar um cluster, ele aparecerá na lista de clusters, como na Figura 12.33. 
Figura 12.33 Listagem de clusters do Dataproc 
Quando o cluster está em execução, você pode enviar trabalhos usando o formulário Jobs mostrado na 
Figura 12.34.
F igura 12.34 Submeta um trabalho a partir da página Detalhes do Cluster. 
Você precisará especificar o cluster para executar o trabalho e o tipo de trabalho, que pode ser 
Spark, PySpark, SparkR, Hive, Spark SQL, Pig ou Hadoop. Os arquivos JAR são 
os programas Java que serão executados, e a classe principal ou JAR é o nome do 
301 implantação e gerenciamento de nuvem Dataproc 
função ou método que deve ser chamado para iniciar o trabalho. Se você escolher o PySpark, você 
enviará um programa em Python; Se você enviar o SparkR, você enviará um programa R. 
Ao executar o Hive ou o SparkSQL, você enviará arquivos de consulta. Você também pode passar 
argumentos opcionais. Quando o trabalho estiver em execução, você o verá na página de listagem de trabalhos, conforme 
mostrado na Figura 12.35.
Figura 12.35 Listagem de trabalhos 
Clicar duas vezes na ID de Jobs na listagem exibirá detalhes do log da tarefa (veja a Figura 12.36). 
Figura 12.36 Detalhes de log de um trabalho em execução 
Além de usar o console, você pode criar um cluster usando o 
comando gcloud dataproc clusters. Veja um exemplo: 
gcloud dataproc clusters create cluster-bc3d ––zone us-west2-a 
Isso criará um cluster padrão na zona us-west2-a. Você também pode especificar 
parâmetros adicionais para tipos de máquina, configurações de disco e outras características de cluster. 
302 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform 
 Use o comando gcloud dataproc jobs para enviar trabalhos a partir da linha de comando. 
Aqui está um exemplo:
 Tarefas gcloud dataproc submetem spark ––cluster cluster-bc3d ––jar ace_exam_jar.jar 
 Isso enviará uma tarefa executando o programa ace_exam_jar.jar no cluster cluster-bc3d. 
 Spark para aprendizado de máquina Os 
 varejistas coletam grandes volumes de dados sobre as compras dos compradores, e isso é especialmente 
útil para entender as preferências e os interesses dos clientes. Os 
sistemas de processamento de transações que coletam grande parte desses dados não são projetados para analisar grandes volumes de dados. Por exemplo, se os varejistas quisessem recomendar produtos aos clientes com 
base em seus interesses, eles poderiam criar modelos de aprendizado de máquina treinados em seus 
dados de vendas . O Spark tem uma biblioteca de aprendizado de máquina, chamada MLlib, que é projetada apenas para esse
tipo de problema. Os engenheiros podem exportar dados de sistemas de processamento de transações, carregá-los 
no Spark e, em seguida, aplicar uma variedade de algoritmos de aprendizado de máquina, como clustering 
e filtragem colaborativa, para recomendações. A saída desses modelos inclui 
produtos que provavelmente são de interesse de clientes específicos. São aplicativos como 
esses que impulsionam a adoção do Spark e de outras plataformas de análise. 
 Gerenciando o armazenamento em nuvem 
 No Capítulo 11, você viu como usar políticas de gerenciamento do ciclo de vida para alterar automaticamente 
a classe de armazenamento de um bucket. Por exemplo, você pode criar uma política para alterar um intervalo de classe de armazenamento regional para um intervalo de nearline após 90 dias. Pode haver momentos, no entanto, quando
você gostaria de alterar manualmente a classe de armazenamento de um bucket. Nesses casos, você pode usar o 
comando reescrever gsutil e especificar o -s fl ag. Veja um exemplo: 
 gsutil rewrite -s [STORAGE_CLASS] gs: // [PATH_TO_OBJECT] 
Aqui, [STORAGE_CLASS] é a nova classe de armazenamento. Pode ser multi-regional, regional, 
nearline ou coldline. 
 Não é possível alterar a classe de armazenamento de um bucket no console. 
Resumo 303 
Outra tarefa comum com o Cloud Storage é mover objetos entre intervalos. Você pode 
fazer isso usando o comando gsutil mv. A forma do comando é a seguinte: 
gsutil mv gs: // [SOURCE_BUCKET_NAME] / [SOURCE_OBJECT_NAME] \ 
gs: // [DESTINATION_BUCKET_NAME] / [DESTINATION_OBJECT_NAME]
Aqui, [SOURCE_BUCKET_NAME] e [SOURCE_OBJECT_NAME] são o nome do intervalo e o nome do 
arquivo original, e [DESTINATION_BUCKET_NAME] e [DESTINATION_OBJECT_NAME] são o 
intervalo e o nome de arquivo de destino , respectivamente. 
O comando move também pode ser usado para renomear um objeto, similar ao comando mv no 
Linux. Para um objeto no Cloud Storage, você pode usar este comando: 
gsutil mv gs: // [BUCKET_NAME] / [OLD_OBJECT_NAME] gs: // [BUCKET_NAME] / 
[NEW_OBJECT_NAME] 
Você também pode usar o console para mover e renomear objetos em um balde. Navegue até a 
seção Cloud Storage do console e navegue até um bucket, conforme mostrado na Figura 12.37.
Clique no ícone de três pontos no final da descrição do objeto. Isso exibe uma lista de operações, incluindo renomeação e movimentação. 
F ig ure 12.37 Renomeando e movendo um objeto do console 
Resumo 
Neste capítulo, você aprendeu a executar tarefas básicas de implantação e gerenciamento de 
vários serviços do GCP, incluindo Cloud SQL, Cloud Datastore, BigQuery, Bigtable, 
Cloud Spanner e Cloud Pub. / Sub, Cloud Dataproc e Cloud Storage. Você viu como 
usar o console e as ferramentas de linha de comando. Embora o gcloud seja usado com frequência, vários dos serviços 
têm suas próprias ferramentas de linha de comando. Houve alguma discussão sobre como criar um banco de dados 
304 Capítulo 12 ■ Implantando o armazenamento no Google Cloud Platform
estruturas, inserir dados e consultar esses dados nos vários serviços de banco de dados. Também discutimos as operações básicas de gerenciamento do Cloud Storage, como mover e renomear objetos. 
Neste capítulo, nos aprofundaremos nos detalhes de carregamento e 
movimentação de dados em vários sistemas de armazenamento e processamento no 
Google Cloud Platform. Começaremos explicando como carregar 
e mover dados no Cloud Storage usando o console e a 
linha de comando. 
A maior parte do capítulo descreverá como importar e exportar dados para 
serviços de armazenamento e análise de dados , incluindo Cloud SQL, Cloud Datastore, BigQuery, Cloud Spanner, 
Cloud Bigtable e Cloud Dataproc. O capítulo finaliza com uma análise dos 
dados em streaming no Cloud Pub / Sub.
Carregando e movendo dados para o Cloud Storage O 
Cloud Storage é usado para uma variedade de casos de uso de armazenamento, incluindo armazenamento e 
arquivamento de longo prazo , transferências de arquivos e compartilhamento de dados. Esta seção descreve como criar 
intervalos de armazenamento, carregar dados em intervalos de armazenamento e mover objetos entre intervalos de armazenamento. 
Carregando e movendo dados para o armazenamento em nuvem Usando o console O 
carregamento de dados no Cloud Storage é uma tarefa comum e fácil de usar usando o Cloud Console. 
Navegue até a página do Cloud Storage do Cloud Console. Você verá uma lista de 
intervalos existentes ou uma opção para criar um novo intervalo (veja a Figura 13.1). 
Figura 13.1 A primeira etapa para carregar dados no Cloud Storage é criar um bloco.
Carregando e Movendo Dados para o Cloud Storage 317 
 Ao criar um bucket, você será solicitado a especificar a classe de armazenamento do bucket 
e a região para armazená-lo, conforme mostrado na Figura 13.2. 
 
 Para o exame, lembre-se de que os buckets são recursos regionais. Os buckets são 
replicados em todas as zonas da região. 
 figura 13.2 Definindo um bucket regional em us-west1 
 Depois de criar um bucket, você vê a página Bucket Details (veja a Figura 13.3). A partir daqui, 
você pode carregar arquivos ou pastas individuais. 
312 Capítulo 13 ■ Carregando dados no armazenamento 
F igura 13.3 Na página Detalhes do intervalo, você pode carregar arquivos e pastas. 
Quando você faz o upload de um arquivo, você é solicitado a fazê-lo usando o sistema de arquivos do seu dispositivo cliente.
A Figura 13.4 mostra uma janela do macOS Finder para fazer o upload de arquivos. Você veria algo 
semelhante em um sistema operacional Windows ou Linux. 
Figura 13.4 A escolha da opção Upload de Arquivo solicita um arquivo usando as 
ferramentas do sistema de arquivos do dispositivo cliente . 
Ao fazer o upload de uma pasta, você também é solicitado pelas ferramentas do seu sistema operacional local 
(consulte a Figura 13.5). 
Carregar e mover dados para o Cloud Storage 313 
F igure 13.5 A escolha da opção Upload da pasta funciona de forma semelhante ao Upload de arquivos; você 
é solicitado a fornecer uma pasta usando as ferramentas do sistema de arquivos do dispositivo cliente. 
É fácil mover objetos entre os baldes. Basta clicar na opção de três pontos no final do
uma linha sobre um objeto para exibir uma lista de operações, que inclui Mover. Selecionar Mover 
abrirá um formulário de diálogo como o mostrado na Figura 13.6. 
Figura 13.6 Objetos podem ser movidos usando o comando Mover no menu Operações. 
Ao mover um objeto, você será solicitado a fornecer um depósito e uma pasta de destino, conforme mostrado 
na Figura 13.7. 
Figura 13.7 Ao mover um objeto no console, você será solicitado a inserir um 
depósito e uma pasta de destino. 
314 Capítulo 13 ■ Carregando dados no armazenamento 
  
 Você pode mover objetos usando a operação Mover no menu pop-up, mas 
não pode mover uma pasta dessa maneira. Mover não é uma opção no menu pop-up ao selecionar uma pasta. 
 Carregar e mover dados para o armazenamento na nuvem usando o
Linha de Comando O 
 carregamento e a movimentação de dados podem ser feitos na linha de comando usando o comando gsutil. 
 Para criar um intervalo, use o comando gsutil mb; "Mb" é a abreviação de "make bucket". 
 Gsutil mb gs: // [BUCKET_NAME] / 
 Lembre-se de que os nomes de intervalos devem ser exclusivos globalmente. Para criar um bloco chamado 
ace-exam-bucket1, use o seguinte comando: 
 gsutil mb gs: // ace-exam-bucket1 / 
 Para fazer upload de um arquivo do seu dispositivo local ou de uma máquina virtual do GCP (VM), você pode use o 
comando gsutil cp para copiar arquivos. O comando é o seguinte: 
 gsutil cp [LOCAL_OBJECT_LOCATION] gs: // [DESTINATION_BUCKET_NAME] / 
 Por exemplo, para copiar um arquivo chamado README.txt de / home / mydir para o intervalo
ace-exam-bucket1, você executaria o seguinte comando a partir da linha de comando do seu dispositivo cliente 
: 
 gsutil cp /home/mydir/README.txt gs: // ace-exam-bucket1 / 
 Da mesma forma, se você quiser baixar uma cópia dos seus dados de um intervalo do Cloud Storage para um 
diretório em uma VM, você poderia fazer login na VM usando o SSH e emitir um comando como 
este: 
 gsutil cp gs: //ace-exam-bucket1/README.txt / home / mydir / 
 Neste exemplo, o objeto de origem está no Cloud Storage e o arquivo de destino está na VM a 
partir da qual você está executando o comando. 
 A ferramenta gsutil tem um comando de movimentação; Sua estrutura é a seguinte: 
 gsutil mv gs: // [SOURCE_BUCKET_NAME] / [SOURCE_OBJECT_NAME] \ 
 gs: // [DESTINATION_BUCKET_NAME] / [DESTINATION_OBJECT_NAME]
 Para mover o arquivo README.txt de ace-exam-bucket1 para ace-exam-bucket2 e manter o 
mesmo arquivo, você usaria este comando: 
 gsutil mv gs: //ace-exam-bucket1/README.txt gs : // ace-exam-bucket2 / 
Importando e exportando dados 315 
Importando e exportando dados 
Como engenheiro de nuvem, talvez seja necessário executar operações de dados em massa, como importar 
e exportar dados de bancos de dados. Essas operações são feitas com ferramentas de linha de comando 
e, às vezes, com o console. Não examinaremos como inserir dados em 
bancos de dados programaticamente; é mais uma tarefa de desenvolvedor de aplicativo e administrador de banco de dados. 
Importando e exportando dados: Cloud SQL
Para exportar um banco de dados do Cloud SQL usando o console, navegue até a página do Cloud SQL do 
console para listar as instâncias do banco de dados, como na Figura 13.8. 
Figura 13.8 Listagem de instâncias do banco de dados na página Cloud SQL do console 
Abra a página Detalhes da Instância clicando duas vezes no nome da instância (veja a 
Figura 13.9). 
Figura 13.9 A página Detalhe da Instância possui as guias Importar e Exportar. 
316 Capítulo 13 ■ Carregando dados no armazenamento 
Selecione a guia Exportar para mostrar o diálogo do banco de dados de exportação. Você precisará especificar um 
intervalo para armazenar o arquivo de backup (veja a Figura 13.10). 
Figura 13.10 A exportação de um banco de dados requer um depósito para armazenar o arquivo de exportação e uma 
especificação de formato de arquivo .
Você também precisará escolher saída SQL ou CSV. A saída SQL é útil se você planeja 
importar os dados para outro banco de dados relacional. O CSV é uma boa escolha se você precisar mover 
esses dados para um banco de dados não relacional. 
Depois de criar um arquivo de exportação, você pode importá-lo. 
Siga as mesmas instruções para exportar, mas escolha a guia Importar em vez da 
guia Exportar. Isso mostrará um formulário como esse na Figura 13.11. Especifique o arquivo de origem, o 
formato de arquivo e o banco de dados para o qual importar os dados. 
Importação e exportação de dados 317 
Figura 13.11 A importação de um banco de dados requer um caminho para o bloco e objeto que armazena 
o arquivo de exportação, uma especificação de formato de arquivo e um banco de dados de destino dentro da instância.
Você também pode criar, importar e exportar um banco de dados usando a linha de comando. Use o 
comando gsutil para criar um bloco, como este: 
gsutil mb gs: // ace-exam-bucket1 / 
Você precisa garantir que a conta de serviço possa gravar no bloco, portanto, obtenha o nome da 
conta de serviço descrevendo o instance com o seguinte comando: 
gcloud sql instances describe [INSTANCE_NAME] 
Neste exemplo, este comando seria o seguinte: 
gcloud sql instances describe ace-exam-mysql1 
Isso produzirá uma lista detalhada sobre a instância, incluindo o 
email da conta de serviço . Veja a Figura 13.12 para um exemplo da saída. 
318 Capítulo 13 ■ Carregando dados no armazenamento
Figura 13.12 Detalhes sobre uma instância de banco de dados gerada pelo 
comando gcloud sql instances describe 
Importando e Exportando Dados 319 
Com isso você pode usar o comando gsutil acl ch para alterar os controles de acesso no 
bucket para permitir que a conta de serviço acesse o bucket. Esse comando é o seguinte: 
gsutil acl ch -u [SERVICE_ACCOUNT_ADDRESS]: W gs: // [BUCKET_NAME] 
O comando gsutil acl ch altera as permissões de acesso. O parâmetro -u especifica 
o usuário. A opção: W indica que o usuário deve ter acesso de gravação ao bloco. Em 
nosso exemplo, o comando seria o seguinte: 
gsutil acl ch -u tnkknzut25bezoq72bjbfmo5hu@spe-umbra-30.iam.gserviceaccount.com / 
: W gs: // ace-exam-bucket1
Agora que a conta de serviço tem acesso de gravação ao bloco, você pode criar uma exportação de 
um banco de dados usando este comando: 
gcloud sql export sql [INSTANCE_NAME] gs: // [BUCKET_NAME] / [FILE_NAME] \ 
 --database = [DATABASE_NAME] 
Por exemplo, o comando a seguir exportará o banco de dados MySQL para um 
arquivo de despejo SQL gravado no bucket ace-exam-bucket1: 
gcloud sql export sql ace-exam-mysql1 \ 
 gs: // ace-exam-buckete1 / ace-exam- mysqlexport.sql \ 
 --database = mysql 
Se você preferir exportar para um arquivo CSV, altere sql para csv no 
comando acima . Veja um exemplo: 
gcloud sql export csv ace-exam-mysql1 gs: //ace-exam-buckete1/ace-exam-mysql-export.csv \ 
 --database = mysql
Importar para um banco de dados usa um comando estruturado de forma semelhante. 
gcloud sql import sql [INSTANCE_NAME] gs: // [BUCKET_NAME] / [IMPORT_FILE_NAME] \ 
 --database = [DATABASE_NAME] 
Usando o banco de dados de exemplo, o bloco e o arquivo de exportação, é possível importar o arquivo usando este 
comando: 
gcloud sql import sql ace-exame-mysql1 gs: //ace-exam-buckete1/ace-exam-mysql-export.sql \ 
 --database = mysql 
Importando e exportando dados: Cloud Datastore A 
importação e exportação de dados do Datastore é feita através da linha de comando. O armazenamento de dados 
usa uma estrutura de dados de namespace para agrupar entidades que são exportadas. Você precisará 
especificar o nome do namespace usado pelas entidades que você está exportando. O padrão
namespace é simplesmente (padrão). 
320 Capítulo 13 ■ Carregando dados no armazenamento 
O comando de exportação do Cloud Datastore é o seguinte: 
gcloud datastore export --namespaces = "(padrão)" gs: // $ {BUCKET} 
Você pode exportar para um depósito chamado ace-exam-datastore1 usando Este comando: 
gcloud datastore export --namespaces = "(padrão)" gs: // ace-exam-datastore1 
O comando de importação do Cloud Datastore é o seguinte: 
gcloud datastore import gs: // $ {BUCKET} / [PATH] / [ FILE] .overall_export_metadata 
O processo de exportação criará uma pasta denominada ace-exam-datastore1 usando os dados 
e a hora da exportação. A pasta conterá um arquivo de metadados e uma pasta contendo
os dados exportados. O nome do arquivo de metadados usará a mesma data e hora usada para a 
pasta contida. A pasta de dados será nomeada após o namespace do 
banco de dados exportado do Datastore. Um exemplo de comando import é o seguinte: 
gcloud datastore import gs: // ace-exam-datastore1 / 2018-12-20T19: 13: 55_64324 / 
2018-12-20T19: 13: 55_64324.overall_export_metadata 
Importação e exportação de dados: 
usuários do BigQuery BigQuery pode exportar e importar tabelas usando o Cloud Console e a linha de comando. 
Para exportar uma tabela usando o console, navegue até a interface do console do BigQuery. Em 
Recursos, abra o conjunto de dados que contém a tabela que você deseja exportar. Clique no nome da tabela
para listar a descrição da tabela, como mostra a Figura 13.13. Observe a opção Exportar no 
canto superior direito. 
Figura 13.13 Lista detalhada de uma tabela do BigQuery 
À extrema direita, clique em Exportar para exibir uma lista de dois locais de exportação: Google Cloud 
Storage ou Data Studio, que é uma ferramenta de análise no GCP (consulte a Figura 13.14). 
Importando e exportando dados 321 
F igure 13.14 Escolhendo um local de destino para uma exportação do BigQuery 
Selecionar o Cloud Storage exibe um formulário como o mostrado na Figura 13.15. Digite o 
nome do intervalo para armazenar o arquivo de exportação. Escolha um formato de arquivo. As opções são CSV, Avro e 
JSON. Escolha um tipo de compactação. As opções são None ou Gzip para CSV e “deflate” 
e “snappy” para Avro.
Formatos de arquivo O 
BigQuery oferece várias opções de arquivos de exportação. CSV, abreviação de “valores separados por vírgula”, é um 
formato legível para humanos, adequado para pequenos conjuntos de dados que serão importados para ferramentas que 
suportam apenas o formato CSV. O CSV não é otimizado para armazenamento, portanto, ele não compacta ou usa uma 
codificação mais eficiente que o texto. Não é a melhor opção ao exportar grandes conjuntos de dados. 
O JSON também é um formato legível que tem vantagens e desvantagens semelhantes 
ao CSV. Uma diferença é que o JSON inclui informações de esquema com cada registro, 
enquanto o CSV usa uma linha de cabeçalho opcional com nomes de coluna no início do arquivo para 
descrever o esquema. 
O Gzip é um utilitário de compactação sem perdas amplamente utilizado.
O Avro é um formato binário compacto que suporta estruturas de dados complexas. Quando os dados são 
salvos no formato Avro, um esquema é gravado no arquivo juntamente com os dados. Esquemas são 
definidos em JSON. O Avro é uma boa opção para grandes conjuntos de dados, especialmente ao importar 
dados para outros aplicativos que leiam o formato Avro, incluindo o Apache Spark, que está 
disponível como um serviço gerenciado no Cloud Dataproc. Os arquivos Avro podem ser compactados usando 
os utilitários deflate ou snappy. Deflate produz arquivos compactados menores, mas 
é mais rápido. 
Figura 13.15 Especificando os parâmetros de saída para uma operação de exportação do BigQuery 
322 Capítulo 13 ■ Carregando dados no armazenamento
 Para exportar dados da linha de comando, use o comando bq extract. A estrutura é a 
seguinte: 
 bq extract --destination_format [FORMATO] --compressão [COMPRESSION_TYPE] 
--field_delimiter [DELIMITER] --print_header [BOOLEAN] [PROJECT_ID]: [DATASET]. 
[TABLE] gs: // [BUCKET] / [FILENAME] 
Veja um exemplo: 
 bq extract --destination_format CSV --compressão GZIP 'mydataset.mytable' 
gs: //example-bucket/myfile.zip   
 
 Lembre-se, a linha de comando A ferramenta para trabalhar com o BigQuery é bq, não 
gcloud. 
 Para importar dados para o BigQuery, navegue até a página do console do BigQuery e selecione um 
conjunto de dados para o qual você gostaria de importar dados. Clique em um conjunto de dados e selecione a guia Criar Tabela, como
mostrado na Figura 13.16. 
 figura 13.16 Ao visualizar um conjunto de dados, você tem a opção de criar uma tabela. 
 O formulário Criar Tabela aceita vários parâmetros, incluindo uma tabela de origem opcional, um 
projeto de destino, o nome do conjunto de dados, o tipo de tabela e o nome da tabela (consulte a Figura 13.17). 
Importando e exportando dados 327 
F igure 13.17 Criando uma tabela no BigQuery 
O campo Criar tabela de indica onde encontrar os dados de origem, se houver. Isso fornece 
uma maneira de criar uma tabela com base nos dados em uma tabela existente, mas padroniza para uma tabela vazia 
(veja a Figura 13.18). 
324 Capítulo 13 ■ Carregando Dados no Armazenamento 
Figura 13.18 Os dados podem ser importados de vários tipos de locais.
Você também precisará especificar o formato de arquivo do arquivo que será importado. As opções 
incluem CSV, JSON, Avro, Parquet, PRC e Backup do Cloud Datastore (consulte a Figura 13.19). 
Figura 13.19 Opções de formato de arquivo para importação 
Fornece informações de destino, incluindo projeto, nome do conjunto de dados, tipo de tabela e 
nome da tabela . O tipo de tabela pode ser um tipo nativo ou uma tabela externa. Se a tabela for externa, os dados serão 
mantidos no local de origem e apenas os metadados sobre a tabela serão armazenados no BigQuery. Isso é 
usado quando você tem grandes conjuntos de dados e não deseja carregá-los no BigQuery. 
Depois de especificar todos os parâmetros, clique em Criar Tabela para criar a tabela e carregar os dados.
Para carregar dados da linha de comando, use o comando bq load. Sua estrutura é a 
seguinte: 
bq load --autodetect --source_format = [FORMATO] [DATASET]. [TABELA] [PATH_TO_SOURCE] 
O parâmetro --autodetect tem carga bq detecta automaticamente o esquema da tabela a partir 
do arquivo de origem. Um exemplo de comando é o seguinte: 
bq load --autodetect --source_format = CSV mydataset.mytable gs: // ace-exam-biquery / 
mydata.csv 
Importando e exportando dados 327 
Importando e exportando dados: 
Usuários do Cloud Spanner Cloud Spanner podem importar e exportar dados usando o Cloud Console. 
Para exportar dados do Cloud Spanner, navegue até a seção Cloud Spanner do 
console. Você verá uma lista de instâncias do Spanner, conforme mostrado na Figura 13.20.
Figura 13.20 Listagem de instâncias de Spanner 
Clique no nome da instância que é a fonte de dados a ser exportada. Isso mostrará a 
página Detalhes da Instância (veja a Figura 13.21). 
Figura 13.21 Detalhes da instância do Spanner, com as guias Importar e Exportar 
Clique em Exportar para mostrar o formulário de Exportação, conforme mostrado na Figura 13.22. Você precisará inserir 
um intervalo de destino, o banco de dados a ser exportado e uma região para executar o trabalho. Observe que você precisa 
confirmar que haverá cobranças pela execução do Cloud Dataflow e que pode haver 
cobranças de saída de dados para dados enviados entre regiões. 
326 Capítulo 13 ■ Carregando dados no armazenamento 
F igure 13.22 Formulário de exportação para o Cloud Spanner
Para importar dados, clique na guia Importar para exibir o formulário Importar (veja a Figura 13.23). Você 
precisará especificar um intervalo de origem, um banco de dados de destino e uma região para executar um trabalho. 
A Cloud Spanner não tem um comando gcloud para exportar dados, mas você pode usar o 
Dataflow para exportar dados. Os detalhes da criação de trabalhos do Dataflow estão fora do 
escopo desta seção. Para mais detalhes, consulte a documentação do Cloud Dataflow em 
https://cloud.google.com/dataflow/docs/. 
Importando e exportando dados 327 
F igure 13.23 Formulário de importação para o Cloud Spanner 
Importando e exportando dados: Cloud Bigtable 
Ao contrário de outros bancos de dados do GCP, o Cloud Bigtable não tem uma opção de exportação e importação.
no Cloud Console ou no gcloud. Você tem duas outras opções: usar um aplicativo Java 
para importar e exportar ou usar a interface do HBase para executar comandos do HBase. 
Os comandos do HBase não estão incluídos na documentação do Google e não serão descritos 
em detalhes aqui. Para mais informações, consulte a documentação do HBase em https: // hbase. 
apache.org/book.html/. 
Para exportar uma tabela do Bigtable, você precisará fazer o download de um arquivo JAR, que é um 
programa compilado para a VM Java. O comando para baixar o arquivo é o seguinte: 
curl -f -O http://repo1.maven.org/maven2/com/google/cloud/bigtable/bigtablebeam-import/1.6.0/bigtable-beam-import-1.6 .0-shaded.jar 
328 Capítulo 13 ■ Carregando dados no armazenamento
o importar dados, você pode usar o mesmo arquivo JAR, mas precisará especificar a importação em 
vez de exportar no comando. Existem algumas mudanças nos parâmetros, que 
são explicadas a seguir. A estrutura do comando de importação é a seguinte: 
Além dos parâmetros especificados no comando de exportação, o comando import 
usa parâmetros para descrever padrões de nome de arquivo que descrevem os arquivos a serem importados. As 
exportações do Bigtable podem ser grandes o suficiente para exigir vários arquivos para armazenar todos os dados. Você também precisará 
especificar um intervalo que possa ser usado para armazenamento temporário durante a importação. 
Importando e exportando dados 329 
A seguir, um exemplo do comando import: 
Importando e exportando dados: Cloud Dataproc
O Cloud Dataproc não é um banco de dados como o Cloud SQL ou o Bigtable; em vez disso, é uma 
plataforma de análise de dados . Essas plataformas são projetadas mais para manipulação de dados, análise estatística, 
aprendizado de máquina e outras operações complexas do que para armazenamento e recuperação de dados. 
O Cloud Dataproc não foi projetado para ser um armazenamento persistente de dados. Para isso, você deve 
usar o Cloud Storage ou discos permanentes para armazenar os arquivos de dados que deseja analisar. 
O Cloud Dataproc possui comandos Importar e Exportar para salvar e restaurar 
dados de configuração de cluster . Esses comandos estão disponíveis, em beta, usando o gcloud. 
Para garantir que você tenha acesso aos comandos beta no gcloud, emita o seguinte comando: 
gcloud components install beta
O comando para exportar uma configuração de cluster do Dataproc é o seguinte: 
gcloud beta dataproc clusters export [CLUSTER_NAME] --destination = [PATH_TO_EXPORT_FILE] 
Um exemplo é o seguinte: 
gcloud beta clusters dataproc export ace-exam-dataproc-cluster 
--destination = gs : //ace-exam-bucket1/mydataproc.yaml 
Para importar um arquivo de configuração, use o comando import: 
gcloud beta dataproc clusters import [SOURCE_FILE] 
Por exemplo, para importar o arquivo criado no exemplo de exportação anterior, você poderia usar 
o seguinte : 
gcloud beta dataproc clusters import gs: //ace-exam-bucket1/mydataproc.yaml A 
importação e exportação de dados são operações comuns. O GCP fornece console e
ferramentas de linha de comando para a maioria dos serviços de banco de dados. Há também comandos beta para 
exportar e importar dados de configuração de cluster para o Dataproc. 
Capítulo 13 ■ Carregando dados em armazenamento 
Fazendo streaming de dados para o Cloud Pub / Sub 
Até aqui neste capítulo, você passou a maior parte do tempo movendo dados para e próximo do 
Cloud Storage, além de importar e exportar dados para bancos de dados. Agora vamos voltar sua 
atenção para trabalhar com o Cloud Pub / Sub, a fila de mensagens. 
Como engenheiro de nuvem, talvez seja necessário criar filas de mensagens para desenvolvedores de aplicativos. 
Embora os desenvolvedores provavelmente criem serviços que usem o Pub / Sub, os engenheiros da nuvem 
devem poder testar tópicos e assinaturas do Pub / Sub. Nós discutimos como criar
filas de mensagens no Capítulo 12. Aqui nosso foco será criar mensagens sobre tópicos e 
receber essas mensagens por meio de assinaturas. 
Os comandos do gcloud pubsub que você usará serão criar, publicar e extrair. Para criar um 
tópico, use o seguinte comando: 
gcloud pubsub topics create [TOPIC_NAME] 
O comando para criar uma inscrição é o seguinte: 
gcloud pubsub assinaturas create --topic [TOPIC_NAME] [SUBSCRIPTION_NAME] 
Por exemplo, para criar um tópico chamado ace -exam-topic1 e uma assinatura para esse tópico 
chamada ace-exam-sub1, você pode usar os seguintes comandos: 
gcloud pubsub topics criar ace-exam-topic1 
gcloud pubsub assinaturas create --topic = ace-exam-topic1 ace-exam-sub1
Agora, para testar se a fila de mensagens está funcionando corretamente, você pode enviar dados para o 
tópico usando o seguinte comando: os 
tópicos da nuvem pubsub publicam [TOPIC_NAME] --message [MESSAGE] 
e leem a mensagem da assinatura usando o seguinte: 
gcloud assinaturas pubsub pull --auto-ack [SUBSCRIPTION_NAME] 
Para escrever uma mensagem sobre o tópico e lê-la a partir da assinatura que você acabou de criar, você 
pode usar o seguinte: 
gcloud pubsub topics publish ace-exam-topic1 ––message "first ace exam mensagem " 
gcloud pubsub assinaturas pull - auto-ack ace-exam-sub1 
Resumo 331 
Desacoplando serviços usando filas de mensagens 
Um dos desafios dos sistemas distribuídos é que às vezes um serviço não pode
acompanhar o fluxo de dados. Isso pode criar um backlog em serviços que dependem do 
serviço atrasado. 
Por exemplo, um pico repentino no tráfego em um site de varejo pode sobrecarregar um 
serviço de rastreamento de inventário , que atualiza o estoque à medida que os clientes adicionam ou removem itens de suas 
cestas. O programa de inventário pode demorar para responder a um serviço que adicionou um item 
ao carrinho. Se esse serviço estiver aguardando uma resposta do serviço de inventário, ele também será 
atrasado. Esse tipo de comunicação síncrona é problemática quando os 
sistemas distribuídos estão sob carga. 
A melhor opção é dissociar a conexão direta entre os serviços. Por exemplo, o
A interface do usuário pode gravar uma mensagem em um tópico do Pub / Sub sempre que um item é adicionado ou 
removido da cesta de um cliente. O serviço de gerenciamento de inventário pode assinar 
este tópico e atualizar o sistema de inventário à medida que novas mensagens chegam. Se o 
sistema de inventário ficar lento, ele não afetará a interface do usuário porque está gravando em um 
tópico Pub / Sub , que pode ser escalonado a carga gerada pela interface do usuário. 
Resumo 
Neste capítulo, você observou as diferentes maneiras de carregar dados em sistemas de armazenamento, banco de dados e fila de mensagens. O Cloud Storage é organizado em torno de objetos em intervalos. 
O comando gsutil e o Cloud Console podem ser usados ​​para fazer upload de dados, bem como movê-lo
entre baldes. Você viu que o comando gsutil cp pode ser usado para copiar arquivos entre o 
Cloud Storage e as VMs. 
Os serviços de banco de dados fornecem utilitários de importação e exportação. Alguns, como o Cloud SQL e o 
BigQuery, disponibilizam esses serviços a partir do Cloud Console e da linha de comando. 
Outros, como o Bigtable e o Cloud Dataproc, possuem apenas opções de linha de comando. 
O Cloud Pub / Sub pode ser usado para separar aplicativos e melhorar a resiliência a picos de 
carga. Você viu como criar um tópico e assinaturas e como enviar dados para a 
fila de mensagens , onde eles podem ser lidos pelos assinantes. 
Saiba que o Cloud Spanner usa o serviço Dataflow para importar e exportar. Lá
Pode haver cobranças adicionais ao usar o Dataflow e mover dados entre regiões. Não 
há comando gcloud para importar ou exportar bancos de dados do Cloud Spanner. 
332 Capítulo 13 ■ Carregando dados no armazenamento 
Essencial do exame 
Saiba como carregar dados e mover dados em torno do Cloud Storage. O Cloud Storage é 
amplamente usado em vários casos de uso, incluindo armazenamento e arquivamento a longo prazo, 
transferências de arquivos e compartilhamento de dados. Entenda a estrutura dos comandos da gsutil, que é 
diferente do gcloud. Os comandos da gsutil iniciam com a gsutil seguida de uma operação, 
como copiar ou criar o intervalo. Certifique-se de conhecer a sintaxe dos 
comandos copy (cp), move (mv) e make bucket (mb). Você pode copiar arquivos do Cloud Storage para VMs e vice-versa.
Além disso, saiba que o comando gsutil acl ch -u é usado para alterar permissões em objetos. 
Entenda como a importação e a exportação funcionam com o Cloud SQL. Importar e exportar 
dados de bancos de dados são operações comuns. Você pode usar o comando gsutil acl ch para 
alterar as permissões em um intervalo do Cloud Storage. Você pode realizar importações e exportações do 
console e da linha de comando. 
Saiba que você pode exportar entidades de um Cloud Datastore. Exportações e importações são feitas 
no nível dos namespaces. Não há uma opção do Cloud Console para exportar e importar 
do Datastore. 
Entenda como exportar e importar dados do BigQuery. O BigQuery tem uma variedade de
opções para a origem dos dados a serem importados. Os dados podem ser compactados quando exportados para economizar 
espaço. O BigQuery pode exportar dados em vários formatos, incluindo CSV, JSON e Avro. 
Saiba que o comando bq é usado para importar e exportar a partir da linha de comando. 
Lembre-se de que o Bigtable e o Cloud Dataproc são diferentes de outras 
funções de importação e exportação . O Bigtable não possui um console ou recurso de linha de comando para importar ou 
exportar dados. Um programa Java é executado a partir da linha de comandos para importar ou exportar dados do 
Bigtable. O Cloud Dataproc é diferente porque não é projetado como um armazenamento de dados persistente. 
É uma ferramenta de análise de dados. Ao exportar do Dataproc, você está exportando a 
configuração do cluster , não os dados no cluster.
Saiba que o Pub / Sub é usado para enviar mensagens entre serviços. Pub / Sub permite maior 
resiliência a flutuações na carga. Se um serviço atrasar, seu trabalho pode se acumular em uma 
fila Pub / Sub sem forçar o serviço que gera esses dados a aguardar. 

Neste capítulo, voltamos nossa atenção para a rede, começando 
com nuvens virtuais privadas (VPCs). Você aprenderá como criar VPCs com sub-redes padrão e personalizadas. Você aprenderá a 
criar configurações de rede personalizadas no Compute Engine 
para casos em que as configurações de rede padrão não atendem às suas necessidades. Em seguida, mostraremos 
como configurar regras de firewall e criar redes privadas virtuais (VPNs). 
Criando uma nuvem privada virtual 
com sub-redes
VPCs são versões de software de redes físicas que vinculam recursos em um projeto. O GCP cria automaticamente um VPC quando você cria um projeto. Você pode criar VPCs adicionais e 
modificar as VPCs criadas pelo GCP. 
As VPCs são recursos globais, portanto, não estão vinculadas a uma região ou zona específica. Recursos, 
como máquinas virtuais do Compute Engine (VMs) e clusters do Kubernetes Engine, podem se comunicar entre si, supondo que o tráfego não seja bloqueado por uma regra de firewall. 
As VPCs contêm sub-redes, sub-redes de chamadas, que são recursos regionais. As sub-redes têm 
um intervalo de endereços IP associados a elas. As sub-redes fornecem endereços internos privados. 
Os recursos usam esses endereços para se comunicar entre si e com as APIs e os 
serviços do Google .
In addition to VPCs associated with projects, you can create a shared VPC within
an organization. The shared VPC is hosted in a common project. Users in other projects who have sufficient permissions can create resources in the shared VPC. You
can also use VPC peering for interproject connectivity, even if an organization is not
defined.
In this section, you will create a VPC with subnets using Cloud Console and gcloud, and
then turn your attention to creating a shared VPC.
Creating a Virtual Private Cloud with Cloud Console
To create a VPC in Cloud Console, navigate to the VPC page, as shown in Figure 14.1.
Clicking Create VPC opens the form to create a VPC, as shown in Figure 14.2. Figure 14.2
mostra que você pode atribuir um nome e uma descrição a um novo VPC. Também mostra uma lista de sub-redes 
que serão criadas no VPC. Quando um VPC é criado, as sub-redes são criadas em cada região. 
O GCP escolhe um intervalo de endereços IP para cada sub-rede ao criar uma rede de modo automático. 
Criando uma nuvem privada virtual com sub-redes 339 
Figura 14.1 A seção VPC do Cloud Console 
Figura 14.2 Formulário para criar uma VPC no Cloud Console, parte 1 
340 Capítulo 14 ■ Rede na nuvem: nuvens virtuais privadas 
Alternativamente, você pode criar uma ou mais sub-redes personalizadas, selecionando a guia Personalizado 
na seção Sub-rede (Figura 14.3). Isso exibe outro formulário que permite especificar
uma região e um intervalo de endereços IP. O intervalo de IP é especificado na notação de roteamento interdomínio sem classe (CIDR). (Consulte a barra lateral “Visão geral da notação CIDR” na página 357 para obter detalhes 
sobre como especificar o endereço IP usando essa notação.) Você pode desativar o Acesso Privado ao Google. 
Isso permite que as VMs na sub-rede acessem os serviços do Google sem atribuir um 
endereço IP externo à VM. Você também pode ativar o registro do tráfego de rede configurando a 
opção Logs de Fluxo como ativado. 
Figura 14.3 Criando uma sub-rede personalizada A 
Figura 14.4 mostra a segunda parte do formulário VPC, que inclui regras de firewall, 
configuração de roteamento dinâmico e uma política de servidor DNS. A seção Regras do firewall lista regras que
pode ser aplicado ao VPC. No exemplo da Figura 14.4, a regra permite que o ingresso, que é 
o tráfego TCP de entrada na porta 22, permita o acesso SSH. O intervalo de IP de 0.0.0.0/0 permite o 
tráfego de todos os endereços IP de origem. 
Criando uma nuvem privada virtual com sub-redes 341 
Figura 14.4 Formulário para criar uma VPC no Cloud Console, parte 2 
A opção de roteamento dinâmico determina quais rotas são aprendidas. O roteamento regional fará com 
que os roteadores do Google Cloud aprenda rotas na região. O roteamento global permitirá que os 
roteadores do Google Cloud aprendam rotas em todas as sub-redes no VPC. 
A política de servidor DNS opcional permite escolher uma política de DNS que habilite o nome DNS
resolução fornecida pelo GCP ou faz alterações na ordem de resolução de nomes. (Consulte o Capítulo 15 
para obter mais detalhes.) 
Depois de especificar os parâmetros e criar um VPC, ele aparecerá na 
listagem do VPC e mostrará informações sobre o VPC e suas sub-redes, conforme mostrado na Figura 14.5. 
Figura 14.5 Listagem de VPCs e sub-redes 
342 Capítulo 14 ■ Rede na nuvem: nuvens virtuais privadas 
Criação de uma nuvem privada virtual com gcloud 
O comando gcloud para criar uma VPC é gcloud compute networks create. Por exemplo, 
para criar um VPC no projeto padrão com sub-redes geradas automaticamente, use 
o seguinte comando: 
gcloud compute networks crie ace-exam-vpc1 --subnet-mode = auto
Você também pode configurar sub-redes personalizadas criando uma rede VPC especificando a 
opção personalizada e criando sub-redes nesse VPC. O primeiro comando para criar um VPC personalizado 
chamado ace-exam-vpc1 é o seguinte: 
gcloud compute networks crie ace-exam-vpc1 --subnet-mode = custom 
Em seguida, você pode criar uma sub-rede usando o comando gcloud compute networks subnet create 
. Este comando requer que você especifique um VPC, a região e o intervalo de IP. 
Como opção, você pode ativar as configurações do Private Google Access e do Flow Logs adicionando os 
sinalizadores apropriados. 
Aqui está um exemplo de comando para criar uma sub-rede chamada ace-exam-vpc-subnet1 no 
ace-exam-vpc1 VPC. Essa sub-rede é criada na região us-west2 com um intervalo IP de
10.10.0.0/16. As configurações de Private IP Access e Flow Logs estão ativadas. 
gcloud beta computar redes sub-redes criar ace-exam-vpc-subnet1 --network = aceexam-vpc1 --region = us-west2 --range = 10.10.0.0 / 16 --enable-private-ip-googleaccess --enable-flow -logs 
Compreendendo a notação CIDR 
Quando você especifica intervalos de endereços IP, você usa algo chamado CIDR (classless interdomain routing). O nome deriva de redes IP antigas que foram definidas em 
três classes fixas: A, B e C. Uma estrutura de endereço de rede sem classe foi criada para 
superar as limitações de uma estrutura de roteamento baseada em classe, particularmente a falta de 
flexibilidade na criação de sub-redes dimensionadas. 
O CIDR usa o mascaramento de sub-rede de tamanho variável (VLSM) para permitir que os administradores de rede
defina redes com o número de endereços que elas precisam, não o número fixo que 
foi alocado à rotina interdomínio de modelo de classe mais antiga. 
Os endereços CIDR consistem em dois conjuntos de números, um endereço de rede para identificar 
uma sub-rede e um identificador de host. Esses números são escritos usando a notação CIDR, 
que consiste em um endereço de rede e uma máscara de rede. Exemplos de endereços de rede, de 
acordo com a especificação RFC1918, são: 
10.0.0.0 
172.16,0.0 
192.168.0.0 
Criação de uma nuvem privada virtual com sub-redes 343 A 
notação CIDR adiciona uma barra (/) e um número indicando quantos bits de um endereço IP 
alocar para a máscara de rede, que determina quais endereços estão dentro do bloco de
o endereço e quais não são. 
Por exemplo, 192.168.0.0/16 significa que 16 bits dos 32 bits de um endereço IP são usados ​​para 
especificar a rede, e 16 bits são usados ​​para especificar o endereço do host. Com 16 bits, você 
pode criar 216 ou 65.536 endereços. 
O bloco CIDR 172.16.0.0/12 indica que 12 bits são usados ​​para especificar a rede e 20 bits são usados ​​para especificar endereços de host. Com 20 bits, você pode criar até 
1.048.576 endereços. Em geral, quanto menor o número após a barra, mais 
endereços estarão disponíveis. Você pode experimentar as opções de bloco do CIDR usando uma calculadora CIDR como a que está em www.subnet-calculator.com/cidr.php. 
Criando uma nuvem privada virtual compartilhada usando gcloud
Se você quiser criar um VPC compartilhado, use o comando gcloud gcloud compute 
shared-vpc. 
Antes de executar comandos para criar um VPC compartilhado, você precisará atribuir a um 
membro da organização a função Administrador de VPC compartilhado no nível da organização ou no nível da pasta. Para atribuir 
a função Administrador de VPC compartilhado, que usa o descritor roles / compute.xpnAdmin, você deve 
emitir este comando: 
gcloud organizations add-iam-policy-binding [ORG_ID] 
--membro = 'usuário: [EMAIL_ADDRESS]' 
--role = "roles / compute.xpnAdmin" 
[ORG_ID] é o identificador da organização da organização que usa a política. Você pode encontrar um 
ID de organização com a lista de organizações do comando gcloud. Se preferir atribuir
a função Administrador de VPC Compartilhado para uma pasta, você pode usar este comando: 
gcloud beta gerenciador de recursos pastas add-iam-policy-binding [FOLDER_ID] - 
membro = 'usuário: [EMAIL_ADDRESS]' 
--role = "roles / compute .xpnAdmin " 
[FOLDER_ID] é o identificador da pasta da política. Você pode obter IDs de pasta usando este 
comando: 
gcloud beta lista de pastas do gerenciador de recursos --organization = [ORG_ID] 
Para saber mais sobre funções e privilégios, consulte o Capítulo 17. 
Depois de definir a função Administrador de VPC Compartilhada no nível da organização, pode emitir 
o comando shared-vpc: 
gcloud compute shared-vpc enable [HOST_PROJECT_ID] 
344 Capítulo 14 ■ Rede na nuvem: nuvens privadas virtuais
Se você estiver compartilhando a VPC no nível da pasta, use este comando: 
gcloud beta compute shared-vpc enable [HOST_PROJECT_ID] 
Agora que a VPC compartilhada é criada, você pode associar projetos usando o comando gcloud 
compute shared-vpc associate-projects. No nível da organização, você pode 
usar este comando: 
gcloud compute shared-vpc projetos associados add [SERVICE_PROJECT_ID] \ 
 --host-project [HOST_PROJECT_ID] 
No nível da pasta, o comando para associar pastas é o seguinte: 
gcloud beta compute shared -vpc-projects associados add [SERVICE_PROJECT_ID] \ 
 --host-project [HOST_PROJECT_ID] 
Alternativamente, o peering VPC pode ser usado para o tráfego de objetos quando uma organização
não existe. O peering de VPC é implementado usando o comando gcloud compute networks peerings 
create. Por exemplo, você observa duas VPCs especificando peerings em cada rede. 
Veja um exemplo: 
gcloud compute redes peerings criar peer-ace-exam-1 \ - 
 rede ace-exam-network-A \ 
 --peer-project ace-exame-projeto-B \ 
 --peer-network ace-exam- network-B \ 
 --auto-create-routes 
E, em seguida, crie um peering na outra rede usando: 
gcloud compute networks peerings crie peer-ace-exam-1 \ - 
 rede ace-exam-network-B \ 
 --peer- projeto ace-exam-projeto-A \ 
 --peer-network ace-exame-rede-A \ - 
 auto-criar-rotas
Esse peering permitirá que o tráfego privado flua entre as duas VPCs. 
Implantando o Compute Engine 
com uma rede personalizada 
Você pode implantar uma VM com configurações de rede personalizadas usando o console e a linha de comando. 
Navegue até a seção Compute Engine do console e abra o 
formulário Create Instance , como mostrado na Figura 14.6. 
Implantação do Compute Engine com uma rede personalizada 345 
F igure 14.6 Formulário preliminar para criar uma instância no Cloud Console 
Clique em Gerenciamento, Segurança, Discos, Rede, contratação única para expandir os 
formulários opcionais e clique na guia Rede para exibir um formulário semelhante à Figura 14.7 .
Observe que, neste formulário, você pode definir tags de rede. Clique em Add Network Interface para exibir um formulário como o mostrado na Figura 14.8. Neste formulário, você pode escolher uma rede personalizada. 
Neste exemplo, estamos escolhendo ace-exam-vpc1, que criamos anteriormente no capítulo. 
Também selecionamos uma sub-rede nesse formulário. 
346 Capítulo 14 ■ Rede na nuvem: Nuvens privadas virtuais 
F igure 14.7 Formulário de configuração de rede 
Figura 14.8 Formulário para adicionar uma interface de rede personalizada 
A partir deste formulário, você também pode especificar um endereço IP estático ou escolher um 
endereço efêmero personalizado usando o campo interno primário. Configuração de IP. O menu suspenso External IP permite que você 
tenha um IP externo efêmero.
Você também pode criar uma instância para ser executada em uma sub-rede específica usando o comando gcloud compute 
instances create com os parâmetros Subnet e Zone. 
gcloud compute instances create [INSTANCE_NAME] --subnet [SUBNET_NAME] --zone 
[ZONE_NAME] 
Criando regras de firewall para uma nuvem privada virtual 347 
Criando regras de firewall para uma 
nuvem virtual privada As 
regras de firewall são definidas no nível da rede e usadas para controlar o fluxo de tráfego de rede para VMs. 
Regras de firewall permitem ou negam um tipo de tráfego em uma porta; por exemplo, uma regra pode permitir o 
tráfego TCP para a porta 22. Eles também são aplicados ao tráfego em uma direção,
(entrada) ou tráfego de saída (saída). É importante observar que o firewall é stateful, o 
que significa que, se o tráfego for permitido em uma direção e uma conexão estabelecida, ela será permitida 
na outra direção. Os conjuntos de regras de firewall são stateful, portanto, se uma conexão for permitida, como 
estabelecer uma conexão SSH na porta 22, todo o tráfego posterior correspondente a essa regra será permitido, desde que a conexão esteja ativa. Uma conexão ativa é aquela com pelo menos um pacote 
trocado a cada dez minutos. 
Estrutura das regras de 
firewall As regras de firewall consistem em vários componentes: 
■ Direção: entrada ou saída. 
■ Prioridade: regras de maior prioridade são aplicadas; qualquer regra com menor prioridade que corresponda
não são aplicados. A prioridade é especificada por um inteiro de 0 a 65535. 0 é a 
prioridade mais alta e 65535 é a mais baixa. 
■ Ação: permita ou negue. Apenas um pode ser escolhido. 
■ Destino: uma instância à qual a regra se aplica. Os destinos podem ser todas as instâncias de uma rede, 
instâncias com tags de rede específicas ou instâncias que usam uma conta de serviço específica. 
■ Origem / destino: a fonte se aplica a regras de ingresso e especifica intervalos de IP de origem, 
instâncias com tags de rede específicas ou instâncias que usam uma conta de serviço específica. 
Você também pode usar combinações de intervalos de IP de origem e tags de rede e combinações 
de intervalos de IP de origem e contas de serviço usadas por instâncias. O endereço IP 0.0.0.0/0
indica qualquer endereço IP. O parâmetro Destination usa apenas intervalos de IP. 
■ Protocolo e porta: um protocolo de rede, como TCP, UDP ou ICMP, e um número de porta. Se nenhum protocolo for especificado, a regra se aplicará a todos os protocolos. 
■ Status de imposição: as regras de firewall estão ativadas ou desativadas. As regras desativadas não são 
aplicadas, mesmo se corresponderem. Às vezes, a desativação é usada para solucionar problemas com o 
tráfego que passa quando não deve ou não deve passar quando deveria. 
Todas as VPCs começam com duas regras implícitas: uma permite o tráfego de saída para todos os destinos 
(endereço IP 0.0.0.0/0) e uma nega todo o tráfego de entrada de qualquer origem (endereço IP 
0.0.0.0/0). Ambas as regras implícitas têm prioridade 65535, portanto você pode criar outras regras com
negar ou permitir o tráfego conforme necessário. Você não pode excluir uma regra implícita. 
348 Capítulo 14 ■ Rede na nuvem: Nuvens privadas virtuais 
Quando uma VPC é criada automaticamente, a rede padrão é criada com quatro 
regras de rede . Estas regras permitem o seguinte: 
■ O tráfego de entrada a partir de qualquer instância VM na mesma rede 
■ tráfego TCP de entrada na porta 22, permitindo SSH 
tráfego ■ Incoming TCP na porta 3389, permitindo Microsoft Remote Desktop Protocol 
(RDP) 
■ Incoming Internet Control Message Protocol ( ICMP) de qualquer origem na 
rede 
Todas as regras padrão têm prioridade 65534. 
Criando regras de firewall usando o Cloud Console
Para criar ou editar regras de firewall, navegue até a seção VPC do console e selecione a 
opção Firewall no menu VPC (veja a Figura 14.9). 
Figura 14.9 Lista de regras de firewall na seção VPC do Cloud Console 
Clique em Criar regra de firewall para criar uma nova regra de firewall. Isso mostra um formulário semelhante à 
Figura 14.10. 
Nesse formulário, você especifica um nome e uma descrição da regra de firewall. Você pode optar por 
ativar ou desativar o registro. Se estiver ligado, as informações de registro serão capturadas no Stackdriver. (Consulte o 
Capítulo 18 para obter mais informações sobre o log do Stackdriver.) Você também precisa especificar a rede no 
VPC para aplicar a regra. 
Criando regras de firewall para uma nuvem privada virtual 349
Figura 14.10 Criar um formulário de regra de firewall 
Capítulo 3 ■ Networking na nuvem: Nuvens Privadas Virtuais 
Em seguida, você precisará especificar uma prioridade, direção, ação, metas e fontes. A prioridade pode 
ser inteiros no intervalo de 0 a 65535. A direção pode ser entrada ou saída. A ação pode ser permitir 
ou negar. Os alvos são escolhidos de uma lista suspensa; as opções são mostradas na Figura 14.11. 
Figura 14.11 Lista de tipos de destino 
Se você escolher tags ou contas de serviço, poderá especificar as tags ou o nome da 
conta de serviço. Você também pode especificar filtros de origem como intervalos de IP, sub-redes, origem
tags ou contas de serviço. O GCP permite um segundo filtro de origem, se você quiser usar uma combinação de condições. Uma lista de filtros de origem é mostrada na Figura 14.12. 
Figura 14.12 Lista de tipos de filtro de origem 
Por fim, você especifica o protocolo e as portas, escolhendo entre as 
opções Permitir Todos, Especificar Protocolos e Portas. Se você escolher o último, você pode especificar protocolos e portas. 
A Figura 14.13 mostra a listagem da regra de firewall criada usando os parâmetros especificados 
na Figura 14.10. 
Figura 14.13 Listagem de regra de firewall criada usando configuração anterior 
Criando regras de firewall usando gcloud 
O comando para trabalhar com regras de firewall a partir da linha de comando é gcloud compute
regras de firewall. Com este comando, você pode criar, excluir, descrever, atualizar e listar 
regras de firewall. 
Criação de uma Rede Privada Virtual 351 
Há uma série de parâmetros usados com gcloud computação firewall de regras criar: 
■ --action 
■ --allow 
■ --description 
■ --destination-ranges 
■ --direction 
■ --network 
■ - prioridade 
■ --source-ranges 
■ --source-service-accounts 
■ --source-tags 
■ --target-service-accounts 
■ --target-tags 
Por exemplo, para permitir todo o tráfego TCP nas portas 20000 a 25000, use isso: 
gcloud compute firewall-rules criar ace-exam-fwr2 - rede ace-exam-vpc1 
–-allow tcp: 20000-25000
Criando uma rede privada virtual As 
VPNs permitem que você envie com segurança o tráfego de rede da rede do Google para sua própria rede. Você pode criar uma VPN usando o Cloud Console ou a linha de comando. 
Criando uma rede privada virtual usando o Cloud Console 
Para criar uma VPN usando o Cloud Console, navegue até a seção Conectividade Híbrida do 
console, como mostra a Figura 14.14. 
Figura 14.14 Seção Conectividade Híbrida do Cloud Console 
352 Capítulo 14 ■ Rede na Nuvem: Nuvens Privadas Virtuais 
Clique em Criar Conexão VPN para exibir o formulário mostrado na Figura 14.15. 
Figura 14.15 Criar um formulário de conexão VPN 
Criando uma rede privada virtual 353
Nesse formulário, você especifica um nome e uma descrição da VPN. Na seção denominada 
Gateway VPN do Google Compute Engine, você configura a extremidade do GCP da conexão VPN. Isso inclui especificar uma rede, a região que contém a rede e um 
endereço IP estático . Se você não criou um endereço IP, crie um selecionando Criar 
endereço IP no menu suspenso do parâmetro Endereço IP. Ele exibirá uma caixa de diálogo 
como a da Figura 14.16. 
Figura 14.16 Criando um endereço IP estático 
Na seção Túneis, você configura o outro ponto final da rede na VPN. Você 
especifica um nome, uma descrição e um endereço IP do gateway da VPN na sua rede. Você pode
especificar qual versão do protocolo IKE (Internet Key Exchange) deve ser usada. Você terá que 
especificar um segredo compartilhado, que é uma seqüência secreta de caracteres, que seu navegador pode criar para você, se você clicar em Gerar. Você precisará deste segredo compartilhado ao configurar seu 
endpoint VPN. 
Na seção Opções de roteamento, você pode escolher roteamento dinâmico, baseado em rota ou baseado em política 
. 
O roteamento dinâmico usa o protocolo BGP para aprender rotas nas suas redes. Você precisará 
selecionar ou criar um roteador na nuvem. Se você não criou um, poderá selecionar Criar Cloud 
Router na lista suspensa no parâmetro Cloud Router. Isso exibirá um formulário 
como a Figura 14.17. 
Figura 14.17 Criando um roteador de nuvem
354 Capítulo 14 ■ Rede na nuvem: nuvens virtuais privadas 
Nesse formulário, forneça um nome e uma descrição. Você também precisará especificar um 
número de sistema autônomo privado (ASN) usado pelo protocolo BGP. O ASN é um número no 
intervalo 64512–65534 ou 4000000000–4294967294. Cada roteador de nuvem que você criar precisará de 
um ASN exclusivo. 
Se você escolher roteamento baseado em rota, precisará inserir os intervalos de IP da 
rede remota . Se você escolher o roteamento baseado em políticas, precisará inserir intervalos de IP remotos, 
sub-redes locais que usarão a VPN e intervalos de IP locais. 
Análises na 
ciência de dados em nuvem e análise de dados são cada vez mais importantes para as empresas. Derivar
insights dessas práticas, você precisa dos dados e das ferramentas. Os dados sobre clientes, 
vendas e outros tipos de transações geralmente são armazenados em um banco de dados no data 
center de uma empresa . Os analistas de ferramentas que você deseja usar, como os serviços de aprendizado de máquina e de ignição, estão 
prontamente disponíveis na nuvem. Muitas organizações têm práticas de segurança para proteger os dados 
e não permitiriam que um analista, por exemplo, baixasse alguns dados e os copiasse 
em uma conexão de Internet não segura para a nuvem. Em vez disso, os engenheiros de rede e nuvem 
criariam uma VPN entre o data center da empresa e o GCP. Isso garantiria que 
o tráfego de rede entre o data center e a nuvem seja criptografado. Os analistas obtêm acesso
aos dados e ferramentas de que precisam, e os profissionais de segurança da informação na organização são capazes de proteger a confidencialidade e a integridade dos dados. 
Criando uma rede privada virtual usando gcloud 
Para criar uma VPN na linha de comando, você pode usar esses três comandos: 
gcloud compute target-vpn-gateways 
gcloud compute forwarding-rule 
gcloud compute vpn-tunnels 
O formato do gcloud compute target O comando -vpn-gateways é o seguinte: 
gcloud compute vpn-tunnels create NOME --peer-address = PEER_ADDRESS --sharedsecret = SHARED_SECRET --target-vpn-gateway = TARGET_VPN_GATEWAY 
NAME é o nome do túnel. PEER_ADDRESS é o endereço IPv4 do túnel remoto
endpoint. SHARED_SECRET é uma string secreta. TARGET_VPN_GATEWAY é uma referência ao 
IP do gateway de VPN de destino . 
O formato da regra de encaminhamento de computação gcloud é o seguinte: 
gcloud compute forwarding-rules cria NAME --TARGET_SPECIFICATION = VPN_GATEWAY 
Essenciais do exame 355 
NAME é o nome da regra de encaminhamento. TARGET_SPECIFICATION é um dos vários 
tipos de destino , incluindo target-instance, target-http-proxy e --target-vpn-gateway. Para 
obter detalhes adicionais, consulte a documentação em https://cloud.google.com/sdk/gcloud/ 
reference / compute / forwarding-rules / create. 
O formato do comando gcloud compute vpn-tunnels é o seguinte:
gcloud compute vpn-tunnels create NOME --peer-address = PEER_ADDRESS --sharedsecret = SHARED_SECRET --target-vpn-gateway = TARGET_VPN_GATEWAY 
NAME é o nome do túnel VPN, PEER_ADDRESS é o endereço IPv4 do 
túnel remoto , SHARED_SECRET é um string secreta, e TARGET_VPN_GATEWAY é uma referência a um 
gateway VPN. 
Resumo 
Este capítulo analisou como criar VPCs e VPNs. As VPCs definem redes no 
Google Cloud para vincular seus recursos do GCP. As VPNs no GCP são usadas para vincular suas 
redes do GCP a suas redes internas. Discutimos como criar VPCs, VPCs compartilhados 
e sub-redes. Houve uma descrição da notação CIDR. Você também aprendeu a configurar VMs com conexões de rede personalizadas. Em seguida, revisamos as regras de firewall e
como criá-los. O capítulo concluiu com a discussão das etapas necessárias para criar 
uma VPN. 
Fundamentos do exame 
Saiba que os VPCs são data centers lógicos na nuvem e as VPNs são conexões seguras 
entre suas sub-redes VPC e sua rede interna. Seus recursos de nuvem estão em um 
VPC. As VPCs têm sub-redes e regras de roteamento para rotear o tráfego entre sub-redes. Você controla 
o fluxo de tráfego usando regras de firewall. 
Saiba que as VPCs criam sub-redes em cada região quando estão no modo automático. Você pode criar 
sub-redes adicionais . Cada sub-rede tem um intervalo de endereços IP. Regras de firewall são aplicadas a sub-redes, também 
chamadas de redes. Os roteadores podem ser configurados para aprender apenas rotas regionais ou rotas globais.
Entenda como ler e calcular a notação CIDR. A notação CIDR representa uma 
máscara de sub- rede e o tamanho do endereço IP disponível no intervalo IP. Quanto menor o tamanho da máscara de sub-rede, 
que é o número após a barra em um bloco CIDR, mais endereços IP estarão disponíveis. 
O formato do endereço CIDR é um endereço IP seguido por uma barra, seguido pelo tamanho 
da máscara de sub-rede, por exemplo, 10.0.0.0/8. 
Saiba que as VPCs podem ser criadas usando comandos gcloud. Um VPC pode ser criado com 
gcloud compute networks create. Uma VPC compartilhada pode ser criada usando gcloud beta 
356 Capítulo 14 ■ Rede na nuvem: nuvens privadas virtuais 
computam shared-vpc. As VPCs compartilhadas podem ser compartilhadas no nível da rede ou da pasta. Você
precisará vincular as políticas de gerenciamento de identidade e acesso (IAM) no 
nível organizacional ou de pasta para habilitar as funções de Administrador de VPC Compartilhado. O emparelhamento VPC pode ser usado para 
conectividade entre objetos . 
Entenda que você pode adicionar interfaces de rede a uma VM. Você pode configurar essas interfaces para usar uma sub-rede específica. Você pode atribuir endereços IP temporários ou estáticos. 
Saiba que as regras de firewall controlam o fluxo do tráfego de rede. As regras de firewall consistem em 
direção, prioridade, ação, destino, origem / destino, protocolos e porta e 
status de imposição . As regras de firewall são aplicadas a uma sub-rede. 
Saiba como criar uma VPN com o Cloud Console. VPNs roteiam o tráfego entre o seu
recursos em nuvem e sua rede interna. As VPNs incluem gateways, regras de encaminhamento 
e túneis. 
Este capítulo continua o foco na rede, 
configurando especificamente o Sistema de Nomes de Domínio (DNS), o balanceamento de carga e o gerenciamento de endereços IP. O Cloud DNS é um 
serviço gerenciado que fornece serviços de nomenclatura de domínio autoritativo. Ele é projetado para alta disponibilidade, baixa latência e escalabilidade. Os serviços de balanceamento de carga no Google Cloud Platform 
(GCP) oferecem cinco tipos de balanceadores de carga para atender a diversas necessidades. Neste capítulo, você 
verá como o HTTP (S), o Proxy SSL, o Proxy TCP, a Rede TCP / UDP e a Rede TCP / UDP Interna 
diferem e quando usar cada um deles. Os engenheiros de nuvem também devem estar familiarizados com
gerenciamento de endereços IP, em particular, o gerenciamento de 
blocos CIDR (Classless Inter-Domain Routing) e a compreensão de como reservar endereços IP. Este capítulo, em combinação 
com o Capítulo 14, fornece uma visão geral dos tópicos de rede abordados no 
exame Associate Cloud Engineer. 
Configurando o Cloud DNS 
Cloud O DNS é um serviço do Google que fornece resolução de nomes de domínio. No 
nível mais básico , os serviços DNS mapeiam nomes de domínio, como example.com, para endereços IP, como 
35.20.24.107. Uma zona gerenciada contém registros DNS associados a um sufixo de nome DNS, 
como aceexamdns1.com. Registros DNS contêm detalhes específicos sobre uma zona. Por exemplo, 
um registro A mapeia um nome de host para endereços IP no IPv4. Os registros AAAA são usados ​​no IPv6 para
mapear nomes para endereços IPv6. Os registros CNAME contêm o nome canônico, que contém 
nomes de alias de um domínio. Nesta seção, você aprenderá a configurar serviços DNS no 
GCP, que consiste em criar zonas e adicionar registros. 
Criando zonas gerenciadas de DNS usando o Cloud Console 
Para criar uma zona gerenciada usando o Cloud Console, navegue até a seção Serviços de rede 
do console. Clique em Cloud DNS. Isso exibe um formulário como o da Figura 15.1. 
Clique em Create Zone para exibir um formulário como o mostrado na Figura 15.2. 
Primeiro, selecione um tipo de zona, que pode ser público ou privado. 
Zonas públicas são acessíveis da Internet. Essas zonas fornecem servidores de nomes que
responder a consultas de qualquer fonte. As zonas privadas fornecem serviços de nome para seus 
recursos do GCP , como máquinas virtuais (VMs) e balanceadores de carga. As zonas privadas respondem apenas 
a consultas originadas de recursos no mesmo projeto da zona. 
No formulário, forneça um nome e uma descrição de zona. Especifique o nome DNS, que deve 
ser o sufixo de um nome DNS, como aceexamdns1.com. 
Configurando o Cloud DNS 363 
Fi gure 15.1 Página Network Services Cloud DNS 
Fi gure 15.2 Crie uma zona DNS pública. 
Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Você pode habilitar o DNSSEC, que é a segurança do DNS. Ele fornece uma autenticação forte de
clientes que se comunicam com serviços DNS. O DNSSEC é projetado para evitar falsificação (um cliente 
parece ser algum outro cliente) e envenenamento de cache (um cliente envia informações incorretas para atualizar o servidor DNS). 
Se você optar por criar uma zona privada, um formulário como a Figura 15.3 será exibido. 
Fi gura 15.3 Crie uma zona DNS privada. 
Além dos parâmetros definidos para uma zona pública, você precisará especificar as redes 
que terão acesso à zona privada. 
Depois de criar zonas, a página Cloud DNS listará as zonas, conforme mostrado na Figura 15.4. 
Clique no nome de uma zona para ver seus detalhes. Conforme mostrado na Figura 15.5, os detalhes da zona 
incluem uma lista de registros associados à zona. Quando uma zona é criada, NS e SOA
registros são adicionados. NS é um registro do servidor de nomes que possui o endereço de um 
servidor autoritativo que gerencia as informações da zona. SOA é um começo de registro de autoridade, que 
possui informações autoritativas sobre a zona. Você pode adicionar outros registros, como 
registros A e CNAME. 
Configurando o Cloud DNS 365 
Fi gure 15.4 Lista de zonas DNS 
Figura 15.5 Lista de registros em uma zona DNS 
Para adicionar um registro A, clique em Add Record Set para exibir um formulário como o da Figura 15.6. 
Selecione A como um tipo de registro de recurso e especifique um endereço IPv4 do servidor que mapeia 
nomes de domínio para endereços IP para essa zona. 
O TTL, conhecido como tempo de vida, e os parâmetros da Unidade TTL especificam por quanto tempo o registro
pode viver em um cache. Esse é o período em que os resolvedores de DNS devem armazenar os dados em cache antes de 
consultar o valor novamente. Os resolvedores de DNS executam operações de pesquisa mapeando 
nomes de domínio para endereços IP. Se você quiser especificar vários endereços IP no registro, clique em Adicionar 
Item para adicionar outros endereços IP. 
366 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Fi gura 15.6 Crie um conjunto de registros A. 
Você também pode adicionar registros de nome canônico usando o formulário Adicionar conjunto de registros. Nesse caso, 
selecione CNAME como o tipo de registro de recurso, conforme mostrado na Figura 15.7. 
Fi gura 15.7 Crie um registro CNAME. 
O registro CNAME recebe um nome ou alias de um servidor. O nome DNS e o TTL
os parâmetros são os mesmos que no exemplo de registro A. 
Além disso, o DNS Forwarding agora está disponível, o que permite que suas consultas DNS sejam passadas para 
um servidor DNS local se você estiver usando Cloud VPN ou Interconnect. 
Criando zonas gerenciadas por DNS usando gcloud 
Para criar zonas DNS e adicionar registros, você usará as 
transações gcloud beta dns managed-zones e gcloud dns record-sets. 
Configurando carga Balancers 367 
Para criar uma zona pública gerenciada chamada ace-exame-zone1 com o aceexamzone sufixo DNS 
.com, você pode usar isto: 
dns gcloud beta-zonas geridas criar ace-exame-zone1 --description = --dnsname = aceexamzone. com. 
Para tornar esta uma zona privada, você adiciona o parâmetro --visibility definido como private.
gcloud beta dns managed-zones cria ace-exam-zone1 --description = --dnsname = aceexamzone.com. --visibility = private --networks = default 
Para adicionar um registro A, você inicia uma transação, adiciona as informações do registro A e, em seguida, 
executa a transação. 
As transações são iniciadas com o início da transação de conjuntos de registros do gcloud dns. Os conjuntos de registros 
são adicionados usando a adição de transação de conjuntos de registros gcloud dns, e as transações são concluídas 
usando o gcloud dns record-sets-transaction execute. Juntos, os passos são os seguintes: 
gcloud dns record-sets início da transação --zone = ace-exam-zone1 
gcloud dns conjuntos de registros transação add 192.0.2.91 --name = aceexamzone.com. --ttl = 300 
--type = A --zone = ace-exam-zone1
transação de conjuntos de registros do gcloud dns execute --zone = ace-exam-zone1. 
Para criar um registro CNAME, 
usaríamos comandos semelhantes: gcloud dns record-sets transação start --zone = ace-exam-zone1 
gcloud dns conjuntos de registros transaction add server1.aceexamezone.com. - 
name = www2.aceexamzone.com --ttl = 300 --type = CNAME --zone = ace-exam-zone1 
gcloud dns conjuntos de registros transação executar --zone = ace-exam-zone1 
Configurando os balanceadores de 
carga Os balanceadores de carga distribuem a carga de trabalho para os servidores que executam um aplicativo. Nesta seção, 
discutiremos os diferentes tipos de balanceadores de carga e como configurá-los. 
Tipos de balanceadores de carga
Load balancers can distribute load within a single region or across multiple regions. The
several load balancers offered by GCP are characterized by three features:
■ Global versus regional load balancing
■ External versus internal load balancing
■ Traffic type, such as HTTP and TCP
368 Chapter 15 ■ Networking in the Cloud: DNS, Load Balancing, and IP Addressing
Global load balancers are used when an application is globally distributed. Regional
load balancers are used when resources providing an application are in a single region.
There are three global load balancers:
■ HTTP(S), which balances HTTP and HTTPS load across a set of backend instances
■ Proxy SSL, que finaliza as conexões SSL / TLS, que são conexões seguras da camada de soquete. Esse tipo é usado para tráfego não HTTPS. 
■ Proxy TCP, que finaliza as sessões TCP no balanceador de carga e, em seguida, encaminha o 
tráfego para os servidores de back-end. 
Os balanceadores de carga regionais são os seguintes: 
■ TCP / UDP interno, que equilibra o tráfego TCP / UDP em redes privadas que hospedam VMs internas 
■ Rede TCP / UDP, que permite o balanceamento com base no protocolo IP, endereço e porta. 
Esse balanceador de carga é usado para tráfego SSL e TCP não suportado pelos 
balanceadores de carga Proxy SSL e Proxy TCP, respectivamente. 
Os balanceadores de carga externos distribuem o tráfego da Internet, enquanto os balanceadores de carga internos
distribuir tráfego originado no GCP. O balanceador de carga TCP / UDP 
interno é o único balanceador de carga interno. Os 
balanceadores de carga HTTP (S), Proxy SSL, Proxy TCP e Rede TCP / UDP são todos externos. 
Você também precisará considerar o tipo de tráfego ao escolher um balanceador de carga. O 
tráfego HTTP e HTTPS precisa usar o balanceamento de carga global externo. O tráfego TCP pode usar 
balanceadores de carga externos globais, regionais externos ou regionais internos. O tráfego UDP pode usar 
balanceamento de carga regional ou interno externo regional. 
Balanceamento de carga e alta disponibilidade Os 
aplicativos que precisam estar altamente disponíveis devem usar balanceadores de carga para distribuir o tráfego e monitorar a integridade das VMs no back-end. Uma empresa que oferece acesso à API para
os dados do cliente precisarão considerar como aumentar ou diminuir a escala em resposta a alterações na 
carga e como garantir alta disponibilidade. 
A combinação de grupos de instâncias (Capítulo 6) e balanceadores de carga resolve os dois problemas. Os grupos de instâncias podem gerenciar o escalonamento automático e os balanceadores de carga podem executar 
verificações de integridade . Se uma VM não estiver funcionando, as verificações de integridade falharão e tirarão a VM com falha 
de rotação para o tráfego. É menos provável que os usuários da API obtenham códigos de resposta com falha quando os 
grupos de instâncias mantêm um número adequado de VMs ativas e os balanceadores de carga impedem que 
qualquer tráfego seja roteado para servidores com falha. 
Configurando os balanceadores de carga usando o Cloud Console
Para criar um balanceador de carga no Cloud Console, navegue até a seção Serviços de rede e 
selecione Load Balancing, conforme mostrado na Figura 15.8. 
Configurando os balanceadores de carga 389 
Fi gure 15.8 Serviços de rede, seção de balanceamento de carga 
O primeiro passo para criar um balanceador de carga é decidir sobre o tipo. Neste exemplo, você 
criará um balanceador de carga TCP (veja a Figura 15.9). 
Fi gure 15.9 Criar opções de um balanceador de carga 
Depois de selecionar a opção do balanceador de carga TCP, um formulário como a Figura 15.10 aparece. Selecione 
apenas entre minhas VMs para balanceamento de carga particular. Esse balanceador de carga será usado em uma 
única região e você não descarregará o processamento de TCP ou SSL.
370 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Fi gure 15.10 Criando um balanceador TCP 
Agora, você começará um processo de três etapas, conforme mostrado na Figura 15.11. Você configurará 
o back-end e o front-end e, em seguida, revisará a configuração antes de criar o 
balanceador de carga . 
Figura 15.11 Processo de três etapas para configurar um balanceador de 
carga 371 
Para configurar o back-end, especifique um nome, uma região, a rede e os back-ends. 
Backends são VMs que terão carga distribuída para eles. Neste exemplo, duas 
VMs existentes são especificadas como back-ends (consulte a Figura 15.12). 
Fi gure 15.12 Configurando o backend
372 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Você pode configurar uma verificação de integridade para o back-end. Isso trará um formulário separado, conforme 
mostrado na Figura 15.13. 
Fi gura 15.13 Criando uma verificação de saúde 
Na verificação de saúde, você especifica um nome, um protocolo e uma porta e um conjunto de critérios de saúde. 
Nesse caso, você verifica os back-ends a cada 5 segundos e espera por uma resposta de até 
5 segundos. Se você tiver dois períodos consecutivos em que a verificação de integridade falha, o servidor 
será considerado insalubre e retirado da rotação de balanceamento de carga. 
Em seguida, você configura o frontend usando o formulário na Figura 15.14. Você especifica um nome
uma sub-rede e uma configuração IP interna, que neste caso é efêmera (consulte 
“Gerenciando Endereços IP” na página 375 para obter mais informações sobre os tipos de endereços IP). Você também especifica 
a porta que terá seu tráfego encaminhado para o back-end. Neste exemplo, você está 
encaminhando tráfego na porta 80. 
Configurando o balanceador de carga 373 
Configurando o frontend 
O último passo antes de criar o frontend é revisar a configuração, como mostrado na 
Figura 15.15. 
Fi gure 15.15 Revendo a configuração do balanceador de carga 
374 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Depois de criar o balanceador de carga, você verá a lista de balanceadores de carga existentes no
console (veja a Figura 15.16). 
Fi gure 15.16 Listagem de balanceadores de carga 
Configurando balanceadores de carga Usando gcloud 
Nesta seção, revisaremos as etapas necessárias para criar um balanceador de carga de rede. Essas são 
boas opções quando você precisa carregar os protocolos de balanceamento, além do HTTP (S). 
O comando gcloud compute forward-rules é usado para encaminhar o tráfego que corresponde a um 
endereço IP para o balanceador de carga. 
gcloud compute forwarding-rules criar ace-exam-lb --port = 80 
--target-pool ace-exam-pool 
Esse comando direciona o tráfego para qualquer VM no ace-exam-pool para o balanceador de carga chamado de 
ace-exam-lb.
Target pools are created using the gcloud compute target-pools create command.
Instances are added to the target pool using the gcloud compute target-pools addinstances command. For example, to add VMs ig1 and ig2 to the target pool called aceexam-pool, use the following command:
gcloud compute target-pools add-instances ace-exam-pool --instances ig1,ig2
Managing IP Addresses 375
 Managing IP Addresses
 The exam topics for the Associate Cloud Engineer certifi cation specifi cally identifi es two IP
address–related topics: expanding CIDR blocks and reserving IP addresses.
  
 It is also important to understand the difference between ephemeral and
endereços IP estáticos. Endereços IP estáticos são atribuídos a um projeto até
eles são liberados. Estes são usados ​​se você precisar de um endereço IP fixo para um serviço, como um site. Endereços IP efêmeros existem somente enquanto o 
recurso estiver usando o endereço IP, como em uma VM que esteja executando um aplicativo 
acessado somente por outras VMs no mesmo projeto. Se você excluir ou interromper uma VM, os 
endereços efêmeros serão liberados. 
 Expandindo blocos CIDR Blocos 
 CIDR definem um intervalo de endereços IP que estão disponíveis para uso em uma sub-rede. Se você 
precisar aumentar o número de endereços disponíveis, por exemplo, se precisar expandir o 
tamanho dos clusters em execução em uma sub-rede, use o comando gcloud compute networks subnets 
expand-ip-range. Leva o nome da sub-rede e um novo comprimento prefi x. o
prefi x length determina o tamanho da máscara de rede. 
 Por exemplo, para aumentar o número de endereços em ace-exame-Subnet1 para 65.536, você 
definir a duração prefi x para 16: 
 redes gcloud computação sub-redes expandir-ip-gama ace-exame-Subnet1 prefix-length 16 
 Este assume a O comprimento do preffi x era maior que 16 antes de emitir este comando. O 
comando expand-ip-range é usado apenas para aumentar o número de endereços. Você não pode 
diminuí-los, no entanto. Você teria que recriar a sub-rede com um número menor de 
endereços. 
 Reservando endereços 
 IP Os endereços IP externos estáticos podem ser reservados usando o Cloud Console ou a linha de comando.
Para reservar um endereço IP estático usando o Cloud Console, navegue até a seção Virtual Private Cloud 
(VPC) do console e selecione Endereços IP externos. 
 Isso exibirá um formulário como o mostrado na Figura 15.17. 
37.1 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Fi gure 15.17 Lista de endereços IP estáticos reservados 
Clique em Reserve Static Address para exibir o formulário para reservar um endereço IP (consulte a Figura 15.18). 
Ao reservar um endereço IP, você precisará especificar um nome e uma descrição opcional. Você pode ter a opção de usar a camada de serviço padrão de baixo custo para rede, 
which uses the Internet for some transfer of data. The Premium tier routes all traffic over
Google’s global network. You will also need to determine whether the address is in IPv4 or
IPv6 and whether it’s regional or global. You can attach the static IP address to a resource
as part of the reservation process, or you can keep it unattached.
Reserved addresses stay attached to a VM when it is not in use and stay attached until
released. This is different from ephemeral addresses, which are released automatically when
a VM shuts down.
To reserve an IP address using the command line, use the gcloud command gcloud beta
compute addresses create. For example, to create a static IP address in the us-west2
região, que usa a camada Premium, use este comando:
gcloud beta compute address crie ace-exam-reserved-static1 --region = us-west2 
--network-tier = PREMIUM 
Resumo 377 
Fi gure 15.18 Reservando um endereço IP estático 
Resumo 
O exame Associate Cloud Engineer pode testar seus conhecimentos sobre o Cloud DNS, balanceamento de carga e gerenciamento de endereços IP. O Cloud DNS é um serviço de nomes autoritativo para mapear 
nomes de domínio para endereços IP. Você pode configurar zonas DNS públicas ou privadas. Você também 
precisará estar familiarizado com o balanceamento de carga e os diferentes tipos de balanceadores de carga. Alguns 
balanceadores de carga são regionais e alguns são globais. Algumas são apenas para uso interno e outras 
suportam fontes externas de tráfego. O capítulo também revisou como expandir o número de
endereços disponíveis em uma sub-rede e discutiram como reservar endereços IP. 
378 Capítulo 15 ■ Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 
Exam Essentials 
Entenda que o Cloud DNS é usado para mapear nomes de domínio para endereços IP. Se você quiser dar 
suporte a consultas da Internet, use uma zona DNS pública. Use uma zona DNS privada somente se 
você quiser aceitar consultas de recursos em seu projeto. 
Saiba que as entradas de DNS, como example.com, podem ter vários registros associados a elas. 
O registro A especifica o endereço de um resolvedor DNS que mapeia nomes de domínio para 
endereços IP . Registros CNAME armazenam o nome canônico do domínio. 
Saiba como os balanceadores de carga são diferenciados. Os balanceadores de carga são diferenciados com base
em balanceamento de carga global versus regional, balanceamento de carga externo versus interno e os 
protocolos suportados. Os balanceadores globais distribuem a carga entre as regiões, enquanto os 
balanceadores de carga regionais funcionam em uma região. Os balanceadores de carga internos equilibram o tráfego apenas de dentro do 
GCP, não de fontes externas. Alguns balanceadores de carga são específicos do protocolo, como 
balanceadores de carga HTTP e SSL. 
Conheça os cinco tipos de balanceadores de carga e quando eles devem ser usados. Os cinco são: HTTP (S), 
Proxy SSL , Proxy TCP, TCP / UDP Interno e Rede TCP / UDP. 
O HTTP (S) equilibra o carregamento HTTP e HTTPS. 
O Proxy SSL encerra as conexões SSL / TLS. 
Proxy TCP termina sessões TCP.
O TCP / UDP interno equilibra o tráfego TCP / UDP em redes privadas que hospedam VMs internas 
O balanceamento de carga de rede TCP / UDP é baseado no protocolo IP, endereço e porta. 
Entenda que a configuração de um balanceador de carga pode exigir a configuração do frontend 
e do back-end. O balanceador de carga de rede pode ser configurado especificando uma 
regra de encaminhamento que direciona o tráfego para o balanceador de carga para as VMs no pool de destino. 
Saiba como aumentar o número de endereços IP em uma sub-rede. Use o comando gcloud compute subnets da 
rede expand-ip-range para aumentar os endereços IP em uma sub-rede. O 
número de endereços só pode aumentar. O comando expand-ip-range não pode ser usado para 
diminuir o número de endereços.
Saiba como reservar um endereço IP usando o console e o comando gcloud beta compute 
address create. Os endereços IP reservados continuam disponíveis para o seu projeto, mesmo que não estejam anexados a um recurso. Conheça a diferença entre 
os serviços de rede Premium e Standard. 

Ao longo deste guia de exame, você aprendeu a implantar recursos de 
computação, armazenamento e rede e, agora, 
voltará sua atenção para a implantação de aplicativos. O Cloud 
Launcher é o mercado do Google Cloud Platform (GCP), onde você pode encontrar aplicativos pré-configurados que estão prontos para serem implantados no Google Cloud. 
O Google deu ao Cloud Launcher um novo nome: Marketplace. A nuvem associada
O guia de certificação de engenheiros refere-se ao serviço como Cloud Launcher, por isso continuaremos nos 
referindo a ele como o Cloud Launcher neste capítulo. Você verá como usar o Deployment Manager 
para configurar modelos, que podem lançar seus próprios aplicativos personalizados no Google 
Cloud. O Cloud Launcher e o Deployment Manager permitem que os usuários implementem aplicativos e os recursos 
necessários de computação, armazenamento e rede sem precisar configurar esses 
recursos por conta própria. 
Implantando uma solução usando o 
Cloud Launcher O 
Cloud Launcher é um repositório central de aplicativos e conjuntos de dados que podem ser implantados em 
seu ambiente do GCP. Trabalhar com o Cloud Launcher é um processo de duas etapas: navegação
para uma solução que atenda às suas necessidades e implemente a solução. 
Navegar no Cloud Launcher e visualizar soluções 
Para visualizar as soluções disponíveis no Cloud Launcher, navegue até a seção do Marketplace. 
O Marketplace é outro nome para a página do Cloud Launcher no Cloud Console. Isso 
exibirá uma página como a mostrada na Figura 16.1. 
A página principal do Cloud Launcher mostra algumas soluções em destaque. 
As soluções mostradas na Figura 16.1 incluem o SAP HANA, um 
aplicativo de aprendizagem profunda da NVIDIA , e um pacote de firewall de redes Palo Alto. Existem também alguns 
sistemas populares de código aberto, incluindo uma pilha Linux, Apache, MySQL e PHP (LAMP) e uma 
plataforma de blog WordPress. 
Implantando uma solução usando o Cloud Launcher 385
Figura 16.1 Página principal do Cloud Launcher 
Você pode pesquisar ou navegar por filtro para ver a lista de soluções. A Figura 16.2 mostra 
a lista de categorias de soluções disponíveis. 
Você pode restringir o conjunto de soluções exibidas na página principal escolhendo uma 
categoria específica . Por exemplo, se você filtrar para ver apenas conjuntos de dados, verá uma lista de conjuntos de dados, 
como mostrado na Figura 16.3. 
386 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 
Figura 16.3 Conjuntos de dados disponíveis no Cloud Launcher 
Figura 16.2 Filtrando por categoria 
Implantando uma solução usando o Cloud Launcher 387 
Você pode ver uma lista de sistemas operacionais disponíveis na Figura 16.4.
Figura 16.4 Sistemas operacionais disponíveis no Cloud Launcher 
Observe que você pode filtrar ainda mais a lista de sistemas operacionais por tipo de licença. 
Os tipos de licença são gratuitos, pagos e trazem sua própria licença (BYOL). Sistemas operacionais gratuitos incluem opções Linux e FreeBSD. Os sistemas operacionais pagos incluem sistemas operacionais 
Windows e Linux com suporte corporativo. Você será cobrado uma 
taxa com base no seu uso e essa cobrança será incluída no faturamento do seu GCP. A 
opção BYOL inclui dois sistemas operacionais Linux suportados que exigem que você tenha 
uma licença válida para executar o software. Você é responsável por adquirir a licença antes de 
executar o software. 
A Figura 16.5 mostra uma amostra das ferramentas do desenvolvedor disponíveis no Cloud Launcher. Estes
incluem o WordPress, um aplicativo de backup e recuperação e um 
sistema de gerenciamento de documentos . 
388 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 
 figura 16.5 Ferramentas de desenvolvedor disponíveis no Cloud Launcher 

 Observe que há duas opções do WordPress. O Cloud Launcher pode 
ter o mesmo aplicativo fornecido por vários fornecedores. É melhor 
revisar a descrição de cada opção para encontrar a mais adequada às 
suas necessidades. 
 Vamos dar uma olhada no tipo de informação fornecida junto com as soluções listadas no 
Cloud Launcher. A Figura 16.6 mostra a maior parte das informações disponíveis. Inclui uma 
visão geral, informações sobre preços e detalhes sobre o conteúdo do pacote. Há também
informações sobre onde a solução será executada no GCP. 
 O lado esquerdo da página lista os detalhes do conteúdo da solução. A Figura 16.7 
mostra o conteúdo de um pacote do WordPress, que inclui os 
componentes do servidor web Apache, MySQL e PHP. A lista também especifica o sistema operacional e os tipos de recursos 
que serão usados. 
Implantando uma solução usando o Cloud Launcher 389 
Figura 16.6 Visão geral da página de uma solução do WordPress 
Figura 16.7 Detalhes do conteúdo do pacote de solução 
390 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 
No lado direito da página estão as informações de preço (consulte a Figura 16.8). ). Estes são estimados
custos para executar a solução, conforme configurado, por um mês, o que inclui os custos de 
VMs, discos permanentes e outros recursos. A estimativa de preço também inclui descontos 
para uso sustentado de recursos do GCP, que são aplicados à medida que você alcança um limite com base na 
quantidade de tempo que um recurso é usado. 
Figura 16.8 Estimativas de preços para a solução WordPress 
Implantando as soluções do Cloud Launcher 
Depois de identificar uma solução que atenda às suas necessidades, você pode iniciá-la no Cloud Launcher. 
Vá para a página de visão geral do produto que você gostaria de lançar, conforme mostrado na Figura 16.9. 
Figura 16.9 Inicie uma solução Cloud Launcher a partir da página de visão geral do 
produto.
Isso gerará um formulário como o mostrado na Figura 16.10. 
O conteúdo do formulário varia de acordo com o aplicativo, mas muitos parâmetros são comuns 
nas soluções. Nesse formulário, você especifica um nome para a implantação, uma zona e o 
tipo de máquina, que é pré-configurado. Você também deve especificar um email de administrador. 
Opcionalmente, você pode instalar uma ferramenta PHP chamada phpMyAdmin, que é útil para administrar o 
WordPress e outros aplicativos PHP. 
Como implantar uma solução usando o Cloud Launcher 391 
Você pode escolher o tipo e o tamanho do disco permanente. Neste exemplo, a solução será 
implantada em um servidor de 1 vCPU com 3,75 GB de memória e um disco de inicialização de 10 GB usando
discos persistentes. Se você quisesse, você poderia optar por um disco SSD para o disco de inicialização. Você 
também pode alterar o tamanho do disco de inicialização. 
Na seção Rede, você pode especificar a rede e a sub-rede para iniciar a VM. 
Você também pode configurar regras de firewall para permitir o tráfego HTTP e HTTPS. 
Se você expandir o link Mais abaixo da seção Rede, você verá opções para 
configurar endereços IP (veja a Figura 16.11). Você pode optar por ter uma 
figura externa efêmera 16.10 A forma de lançamento de uma solução WordPress no Cloud Launcher 
392 Capítulo 16 ■ Implantando Aplicativos com o 
IP do Cloud Launcher ou nenhum IP externo. Se você estiver hospedando um site, escolha um endereço externo para que o site seja
acessível de fora do projeto GCP. IP estático não é uma opção. Você também pode especificar 
intervalos de IP de origem para o tráfego HTTP e HTTPS. 
Figura 16.11 Parâmetros adicionais para a configuração do IP 
Além dos parâmetros descritos anteriormente, a página inicial também exibirá informações gerais, como mostrado na Figura 16.12. 
Figura 16.12 Visão geral da solução mostrada no formulário de lançamento 
Clique no botão Implantar para iniciar a implantação. Isso abrirá o Deployment Manager 
e mostrará o progresso da implantação (veja a Figura 16.13). 
Implantando uma solução usando o Cloud Launcher 393 
F igure 16.13 Cloud Deployment Manager iniciando o WordPress 
Quando o processo de inicialização estiver concluído, você verá informações resumidas sobre o
implantação e um botão para iniciar o painel de administração, como mostrado na Figura 16.14. 
Figura 16.14 Informações sobre a instância do WordPress implantada 
394 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 
Ao clicar no botão Fazer Logon no Painel do Administrador, você acessa o login do WordPress (veja a 
Figura 16.15). Você pode efetuar login usando o nome de usuário e a senha temporários fornecidos no 
formulário de informações após a conclusão da implantação. 
Figura 16.15 Efetuando login no WordPress 
Implantando um aplicativo usando o 
Deployment Manager 
Além de iniciar as soluções listadas no Cloud Launcher, você pode criar seus próprios 
arquivos de configuração de solução para que os usuários possam iniciar soluções pré-configuradas.
Arquivos de Configuração do 
Deployment Manager Os arquivos de configuração do Deployment Manager são gravados na sintaxe YAML. Os 
arquivos de configuração começam com os recursos da palavra, seguidos pelas entidades de recursos, que são definidas usando 
três campos: 
■ name, que é o nome do 
tipo de recurso ■, que é o tipo do recurso, como compute.v1.instance. 
Implantando um aplicativo usando o Deployment Manager 395 
 ■ propriedades, que são pares chave-valor que especificam os parâmetros de configuração para o 
recurso. Por exemplo, uma VM tem propriedades para especificar o tipo de máquina, os discos e as interfaces de rede. 
 Para obter informações sobre a sintaxe do YAML, consulte a documentação oficial em 
https://yaml.org/start.html.
 Um exemplo simples que define uma máquina virtual chamada ace-exam-deployment-vm começa 
com o seguinte: 
 resources: 
 - type: compute.v1.instance 
 nome: ace-exam-deployment-vm 
 Em seguida, você pode adicionar propriedades, como tipo de máquina, configuração de disco e interfaces de rede. 
 A seção de propriedades do arquivo de configuração começa com as propriedades da palavra. Para cada 
propriedade, existe um único par de valores-chave ou uma lista de pares de valores-chave. A propriedade de tipo de máquina possui um único par de valores-chave, com a chave sendo machineType. Os discos têm várias propriedades, portanto, seguindo o termo discos, há uma lista de pares de valores-chave. Continuando o exemplo 
de ace-exam-deployment-vm, a estrutura é a seguinte: 
 recursos:
 - type: compute.v1.instance 
 nome: ace-exam-deployment-vm 
 propriedades: 
 machineType: [MACHINE_TYPE_URL] 
 discos: 
 [KEY]: [VALUE] 
 [KEY]: [VALUE] 
 Neste exemplo, o tipo de máquina seria um URL a uma especificação de recurso da API do Google, 
como a seguinte: 
https://www.googleapis.com/compute/v1/projects/[PROJECT_ID]/zones/us-central1-f 
/ machineTypes / f1-micro 
 Observe que há uma referência a [PROJECT_ID], que seria substituída por um 
ID de projeto real em um arquivo de configuração. Os discos têm propriedades como deviceName, type e 
Booleans, indicando se o disco é um disco de inicialização ou deve ser autodeleted. Vamos continuar
no exemplo anterior, adicionando a especificação do tipo de máquina e algumas propriedades do disco: 
 
Essa configuração especifica uma implantação denominada quickstart-deployment-vm, que 
será executada na zona us-central1-f. A implantação usará um f1-micro executando uma 
distribuição Debian do Linux. Um endereço IP externo será atribuído. 
 Antes de executar este modelo, você precisaria substituir [MY_PROJECT] pelo seu ID de projeto e [FAMILY_NAME] pelo nome de uma família de imagens do Debian, como debian-9. Você 
pode encontrar uma lista de imagens na seção Compute Engine do Cloud Console na guia Imagens. 
Você também pode listar imagens usando o comando gcloud compute images list. 
 Arquivos de modelo do Deployment Manager
 Se as suas configurações de implantação estiverem se tornando complicadas, você poderá usar 
modelos de implantação . Modelos são outro arquivo de texto que você usa para definir recursos e importar esses 
recursos para arquivos de configuração. Isso permite reutilizar as definições de recursos em vários 
locais. Modelos podem ser escritos em Python ou Jinja2, uma linguagem de templates. 
 Para obter informações sobre a sintaxe Jinja2, consulte a documentação oficial em 
http://jinja.pocoo.org/docs/2.10/. 
398 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 
Como engenheiro de nuvem associado, você deve saber que o Google recomenda o uso do 
Python para criar arquivos de modelo, a menos que os modelos sejam relativamente simples; nesse caso, é 
apropriado usar o Jinja2.
Iniciando um modelo do Deployment Manager 
É possível iniciar um modelo de implantação usando o comando gcloud deployment-manager deployments 
create. Por exemplo, para implantar o modelo a partir da documentação do Google, use 
o seguinte: 
implantações de implantação-gerente do gcloud criar quickstart-implantação --config 
vm.yaml 
Você também pode descrever o estado de uma implantação com o comando descrever, como se segue: 
implantação gloud As implantações de gerenciamento descrevem a implantação de início rápido 
Fornecendo um serviço implantável 
Em grandes empresas, grupos diferentes geralmente desejam usar o mesmo serviço, como um banco de dados.
aplicação científica, para entender os padrões de compra do cliente. Os gerentes de produto em toda a organização podem querer usar isso. Os desenvolvedores de software podem criar uma 
única instância dos recursos de aplicativos e vários usuários trabalham com essa única 
instância. Esta é uma estrutura co-hospedada. Isso tem algumas vantagens se você tiver uma única 
equipe de DevOps que suporte todos os usuários. 
Como alternativa, você pode permitir que cada usuário ou pequeno grupo de usuários tenha sua própria 
instância de aplicativo . Isso tem várias vantagens. Os usuários poderiam executar o aplicativo em seus próprios projetos, 
simplificando a alocação de cobranças de recursos, já que o projeto seria vinculado às 
contas de faturamento dos usuários . Além disso, os usuários podem aumentar ou diminuir os recursos conforme necessário para seu caso de uso.
Uma possível desvantagem é que os usuários podem não se sentir confortáveis ​​em configurar os 
recursos do Google Cloud . O Deployment Manager soluciona esse problema, tornando relativamente simples 
implantar um aplicativo e recursos em um processo repetitivo. Alguém que pode executar um 
comando gcloud deployment-manager poderia implantar recursos de aplicativo de 
maneira semelhante à maneira como os usuários implantam aplicativos no Cloud Launcher. 
O 
Cloud Launcher e o Cloud Deployment Manager foram desenvolvidos para facilitar a 
implantação de recursos no GCP. O Cloud Launcher é onde fornecedores de terceiros podem oferecer aplicativos implantáveis ​​baseados em software proprietário ou de código aberto. Quando uma aplicação é 
essencial ao exame 399
implantados no Cloud Launcher, recursos como VMs, intervalos de armazenamento e 
discos permanentes são criados automaticamente sem intervenção humana adicional. O Deployment 
Manager oferece aos engenheiros de nuvem a capacidade de definir arquivos de configuração que descrevem 
os recursos que eles gostariam de implantar. Uma vez definidos, os engenheiros da nuvem podem usar os 
comandos do gcloud para implantar os recursos e listar seu status. O Deployment Manager 
é especialmente útil em organizações nas quais você deseja implantar recursos facilmente, sem exigir que os usuários desses recursos entendam os detalhes de como configurar 
recursos do GCP. 
Fundamentos do exame 
Entenda como procurar soluções usando a seção Cloud Launcher do Cloud
Console. Você pode usar filtros para restringir sua pesquisa a tipos específicos de soluções, como 
sistemas operacionais e ferramentas de desenvolvedor. Pode haver várias opções para um único aplicativo, como o WordPress. Isso ocorre porque vários fornecedores fornecem configurações. Revise 
a descrição de cada um para entender o que melhor atende às suas necessidades. 
Saiba como implantar uma solução no Cloud Launcher. Entenda como configurar uma 
implantação do Cloud Launcher no Cloud Console. Entenda que quando você inicia uma 
solução, você pode ser solicitado para configurações específicas do aplicativo. Por exemplo, 
com o WordPress você pode ser solicitado a instalar o phpMyAdmin. Você também pode ter a 
oportunidade de configurar atributos de configuração comuns, como o tipo de máquina
e tipo de disco de inicialização. 
Entenda como usar a seção Gerenciador de Implantação do console para monitorar a 
deployment. It may be a few minutes from the time you launch a configuration to the time
it is ready to use. Note that once the application is ready, you may be provided additional
information, such as a username and password to log in.
Know that Deployment Manager is a GCP service for creating configuration files that
define resources to use with an application. These configuration files use YAML syntax.
They are made up of resource specifications that use key-value pairs to define properties of
the resource.
Know that resources in a configuration file are defined using a name, type, and set of
properties. The properties vary by type. The machine type can be defined using just a
URL que aponta para um tipo de máquina disponível em uma região. Os discos têm várias propriedades, 
incluindo um nome de dispositivo, um tipo e se o disco é um disco de inicialização. 
Se os seus arquivos de configuração estão ficando longos ou complicados, você pode modularizá-los usando 
modelos. Modelos definem recursos e podem ser importados para outros modelos. Modelos 
são arquivos de texto escritos em Jinja2 ou Python. 
Saiba que você pode ativar um arquivo de configuração de implantação usando o gcloud deploymentmanager deployments create. Você pode analisar o status de uma implantação usando o gcloud 
deployment-manager deployments-describe.
400 Capítulo 16 ■ Implantando aplicativos com o Cloud Launcher 

Os engenheiros do Google Cloud podem esperar gastar um tempo significativo 
trabalhando com controles de acesso. Este capítulo 
fornece instruções sobre como executar várias tarefas comuns, 
incluindo gerenciamento de atribuições de gerenciamento de identidades e acesso (IAM), criação de 
funções personalizadas , gerenciamento de contas de serviço e exibição de logs de auditoria. 
É importante saber que a maneira preferida de atribuir permissões a usuários, grupos 
e contas de serviço é através do sistema IAM. No entanto, o Google Cloud nem sempre 
tem o IAM. Antes disso, as permissões eram concedidas usando o que agora é conhecido como primitivo
papéis, que são bastante grosseiros. Papéis primitivos podem ter mais permissões do que você 
deseja que uma identidade tenha. Você pode restringir permissões usando escopos. Neste capítulo, 
descreveremos como usar funções e escopos primitivos, bem como o IAM. A partir de agora, é uma 
prática recomendada usar o IAM para controle de acesso. 
Gerenciando Identidades e Acesso 
Gerenciamento 
Quando você trabalha com IAM, existem algumas tarefas comuns que precisam ser executadas: 
Visualizando contábeis de IAM ■ 
■ Atribuir funções do IAM 
■ Definindo funções personalizadas 
Vejamos como executar cada uma dessas tarefas. 
Exibindo 
atribuições de gerenciamento de identidade e acesso à conta
Você pode ver as atribuições de IAM da conta no Cloud Console navegando para a 
seção IAM e administrador. Nessa seção, selecione IAM no menu de navegação para exibir um formulário 
como o mostrado na Figura 17.1. O exemplo na figura mostra uma lista de identidades filtradas 
pelo nome do membro. 
Neste exemplo, o usuário dan@gcpcert.com possui três funções: Admin do App Engine, 
Admin do BigQuery e Proprietário. O administrador do Google App Engine e o administrador do BigQuery são 
funções predefinidas do IAM. Proprietário é um papel primitivo. 
Gerenciando o gerenciamento de identidades e acesso 407 
F igure 17.1 Lista de permissões filtrada por membro 
As funções primitivas foram usadas antes do IAM. Existem três funções primitivas: proprietário, editor,
e visualizador. Os espectadores têm permissão para realizar operações somente leitura. Os editores têm 
permissões de visualizador e permissão para modificar uma entidade. Os proprietários têm permissões de editor e podem 
gerenciar funções e permissão em uma entidade. Os proprietários também podem configurar o faturamento de um projeto. 
As funções do IAM são coleções de permissões. Eles são personalizados para fornecer identidades apenas com 
as permissões necessárias para executar uma tarefa e não mais. Para ver uma lista de usuários atribuídos a uma 
função, clique na guia Funções no formulário do IAM. Isso mostrará uma exibição semelhante à da Figura 17.2. 
Figura 17.2 Lista de identidades atribuídas ao App Engine Admin e ao Editor 
408 Capítulo 17 ■ Configurando o acesso e a segurança
 Este formulário mostra uma lista de funções com o número de identidades atribuídas a essa função entre 
parênteses. Clique na seta ao lado do nome de uma função para exibir uma lista de identidades com 
essa função. Observe que as funções primitivas e pré-definidas do IAM estão incluídas nessa lista. 
 Você também pode ver uma lista de usuários e funções atribuídos em um projeto usando o comando 
gcloud projects get-iam-policy. Por exemplo, para listar as funções atribuídas aos usuários em um projeto 
com o ID do projeto ace-exam-project, use: 
 gcloud projects get-iam-policy ace-exam-project 
 As funções predefinidas são agrupadas por serviço. Por exemplo, o App Engine tem cinco funções: 
 ■ Admin do Google App Engine, que concede permissão de leitura, gravação e modificação para
configurações de aplicativo e configuração. O nome da função usado nos comandos do gcloud 
é roles / appengine.appAdmin. 
 ■ Admin do serviço do App Engine, que concede acesso somente leitura às configurações 
e acesso de gravação às configurações no nível do módulo e da versão. O nome da função usado nos 
comandos do gcloud é roles / appengine.serviceAdmin. 
 ■ App Engine Deployer, que concede acesso somente leitura a configurações 
e configurações de aplicativos e acesso de gravação para criar novas versões. Usuários com apenas a 
função de Deployer do App Engine não podem modificar ou excluir versões existentes. O nome da função usado nos 
comandos do gcloud é roles / appengine.deployer. 
 ■ App Engine Viewer, que concede acesso somente leitura à configuração do aplicativo e
definições. O nome da função usado nos comandos do gcloud é roles / appengine.appViewer. 
 ■ Visualizador de código do App Engine, que concede acesso somente leitura a todas as configurações de aplicativos, configurações e códigos-fonte implantados. O nome da função usado nos comandos do gcloud é 
roles / appengine.codeViewer. 
  
 Embora você não precise conhecer todos eles, é útil revisar papéis predefinidos para entender os padrões de como eles são definidos. Para mais 
detalhes, consulte a documentação do Google Cloud em: https://cloud.google 
.com / iam / docs / understanding-roles. 
 Atribuindo funções de gerenciamento de identidade e acesso a 
contas e grupos 
 Para adicionar funções do IAM a contas e grupos, navegue até a seção IAM e administrador do
console. Selecione IAM no menu. Clique no link Adicionar na parte superior para exibir um formulário como 
o mostrado na Figura 17.3. 
 Especifique o nome de um usuário ou grupo no parâmetro chamado Novos Membros. Clique em Selecionar 
uma função para adicionar uma função. Você pode adicionar várias funções. Ao clicar na seta para baixo no 
parâmetro Função, você verá uma lista de serviços e suas funções associadas. Você pode escolher as 
funções dessa lista. Veja a Figura 17.4 para um exemplo de um subconjunto da lista, mostrando as funções 
do BigQuery. 
Gerenciando o gerenciamento de identidades e acesso 409 
Figura 17.3 A opção Adicionar no IAM é onde você pode atribuir aos usuários ou grupos uma ou 
mais funções. 
Figura 17.4 A lista suspensa nos parâmetros Funções mostra as funções disponíveis
agrupados por serviço. 
Se você quiser saber quais permissões são concedidas quando você atribui uma 
função, é possível listar essas permissões na linha de comando ou no console. Você também pode ver 
quais permissões são atribuídas a uma função usando o comando gcloud iam roles describe. 
Por exemplo, a Figura 17.5 mostra a lista de permissões na função do Deployer do App Engine. 
410 Capítulo 17 ■ Configurar Acesso e Segurança 
F IGURA 17,5 Um exemplo listando permissões usando os papéis iam gcloud descrever 
comando 
Você também pode usar Cloud Console para ver as permissões. Navegue até a 
seção IAM e Admin e selecione Funções no menu. Isso exibe uma lista de funções. Clique na caixa de seleção
ao lado de um nome de função, para exibir uma lista de permissões à direita, conforme mostrado na Figura 17.6 para o 
App Engine Deployer. 
Figura 17.6 Exemplo de listagem de permissões disponíveis para o App Engine Deployer 
usando o Cloud Console 
Gerenciando o gerenciamento de identidades e acesso 411 
Você pode atribuir funções a um membro em um projeto usando o seguinte comando: 
gcloud projects add-iam-policy-binding [RESOURCE-NAME ] --member user: [USEREMAIL] --role [ROLE-ID] 
Por exemplo, para conceder a função App Engine Deployer a um usuário identificado por 
jane@acexam.com, você poderia usar: 
gcloud projects add-iam-policy -binding ace-exam-project - usuário-membro: jane @ 
aceexam.com - role roles / appengine.deployer
Funções de IAM Suporte Menor privilégio e separação de tarefas 
Duas práticas recomendadas de segurança estão atribuindo menos privilégios e mantendo uma separação 
de tarefas. O princípio de privilégios mínimos diz que você concede apenas o menor conjunto de permissões necessárias para que um usuário ou conta de serviço execute suas tarefas necessárias. Por 
exemplo, se os usuários puderem fazer tudo o que precisam fazer apenas com permissão de leitura para um banco de dados, eles não devem ter permissão de gravação. 
No caso de separação de tarefas, a ideia é que um único usuário não possa executar várias operações sigilosas que, juntas, possam representar um risco. Em domínios de alto risco,
como finanças ou defesa, você não desejaria que um desenvolvedor pudesse modificar um aplicativo e implantar essa alteração na produção sem revisão. Um engenheiro malicioso, por exemplo, poderia modificar o código em um aplicativo financeiro para suprimir o registro de aplicativos quando os fundos 
são transferidos para uma conta bancária controlada pelo engenheiro malicioso. Se esse engenheiro 
colocar esse código em produção, poderá levar algum tempo até que os auditores descubram que a 
extração de madeira foi suprimida e pode ter havido transações fraudulentas. 
As funções do IAM suportam menos privilégios, atribuindo permissões mínimas a funções predefinidas. 
Ele também suporta a separação de tarefas, permitindo que alguns usuários tenham a capacidade de alterar o 
código e outros para implantar o código.
Outra prática de segurança comum é a defesa em profundidade, que aplica vários controles de segurança sobrepostos. Essa é também uma prática que deve ser adotada. O IAM pode ser aplicado 
como uma das camadas de defesa. 
Definição de funções de gerenciamento de acesso e identidade personalizada 
Se o conjunto de funções predefinidas do IAM não atender às suas necessidades, você poderá definir uma função personalizada. 
Para definir uma função personalizada no Cloud Console, navegue até a opção Roles na seção IAM e 
Admin do console. Clique no link Criar Função na parte superior da página. Isso 
exibirá um formulário como o mostrado na Figura 17.7. 
412 Capítulo 17 ■ Configuração de acesso e segurança 
F igure 17.7 Criando uma função no Cloud Console
Nesse formulário, você pode especificar um nome para a função personalizada, uma descrição, um identificador, 
um estágio de inicialização e um conjunto de permissões. As opções do estágio de inicialização são as seguintes: Alfa, 
Beta, Disponibilidade geral e Desativado. 
Você pode clicar em Adicionar Permissões para exibir uma lista de permissões. A lista da Figura 17.8 é 
filtrada para incluir apenas as permissões na função de administrador do App Engine. 
Embora a lista inclua todas as permissões na função, nem todas as permissões estão disponíveis 
para uso em uma função personalizada. Por exemplo, appenngine.runtimes.actAsAdmin não está disponível 
para funções personalizadas. Quando uma permissão não está disponível, seu status é listado como Não suportado. 
As permissões disponíveis para uso são listadas como Suportadas, portanto, no exemplo, todas as outras
permissões estão disponíveis. Marque as caixas ao lado das permissões que você deseja incluir em 
sua função personalizada. Clique em Adicionar para retornar ao formulário Criar Função, onde a lista de permissões incluirá agora as permissões selecionadas (veja a Figura 17.9). 
Gerenciando o gerenciamento de identidades e acesso 413 
Figura 17.8 Lista de permissões disponíveis filtradas por função 
F igure 17.9 A seção de permissões do formulário Criar função com permissões adicionadas 
Você também pode definir uma função personalizada usando o comando gcloud iam roles create. A 
estrutura desse comando é a seguinte: 
gcloud iam roles create [ROLE-ID] --projeto [PROJECT-ID] --title [ROLE-TITLE] \ 
--description [ROLE-DESCRIÇÃO] --permissões [PERMISSIONS-LIST ] - estágio [LAUNCH-STAGE]
414 Capítulo 17 ■ Configurar Acesso e Segurança 
Por exemplo, para criar uma função que tem apenas permissão de atualização do aplicativo do Google App Engine, 
você poderia usar o seguinte comando: 
papéis iam gcloud criar customAppEngine1 --project ace-exame-projeto 
--title = 'Custom Atualizar o App Engine '\ 
--description =' Atualização personalizada '--permissions = appengine.applications.update 
--stage = alpha 
Gerenciando contas de 
serviço As contas de serviço são usadas para fornecer identidades independentes de usuários humanos. 
Contas de serviço são identidades que podem receber funções. As contas de serviço são atribuídas às VMs, 
que usam as permissões disponíveis para as contas de serviço para executar as tarefas.
Três coisas que os engenheiros de nuvem devem saber são como trabalhar com escopos, 
atribuir contas de serviço a VMs e conceder acesso a uma conta de serviço para outro 
projeto. 
Gerenciando contas de serviço com escopos 
Escopos são permissões concedidas a uma VM para executar alguma operação. Os escopos autorizam 
o acesso aos métodos da API. A conta de serviço atribuída a uma VM possui funções associadas a 
ela. Para configurar controles de acesso para uma VM, você precisará configurar as funções e os 
escopos do IAM . Discutimos como gerenciar os papéis do IAM, então agora vamos voltar nossa atenção para os 
escopos. 
Um escopo é especificado usando um URL que começa com https://www.googleapis.com/auth/
e é seguido pela permissão em um recurso. Por exemplo, o escopo que permite que uma VM 
insira dados no BigQuery é o seguinte: 
https://www.googleapis.com/auth/bigquery.insertdata 
O escopo que permite a exibição de dados no Cloud Storage é o seguinte: 
https: // www .googleapis.com / auth / devstorage.read_only 
E para escrever nos registros do Compute Engine, use: 
https://www.googleapis.com/auth/logging.write 
Uma instância só pode executar operações permitidas pelos dois papéis do IAM atribuídos ao 
conta de serviço e escopos definidos na instância. Por exemplo, se uma função conceder somente acesso somente leitura ao Cloud Storage, mas um escopo permitir acesso de gravação, a instância não 
poderá gravar no Cloud Storage.
Gerenciando contas de serviço 415 
Para definir escopos em uma instância, navegue até a página da instância de VM no Cloud Console. Pare 
a instância se estiver em execução. Na página Detalhe da Instância, clique no link Editar. Na parte inferior 
da página Editar, você verá a seção Access Scopes, como mostra a Figura 17.10. 
Figura 17.10 Seção Acesso a Escopos na página de edição de detalhes da instância da VM 
As opções são Permitir Acesso Padrão, Permitir Acesso Total a Todas as APIs da Cloud e 
Definir Acesso Para Cada API. O acesso padrão é geralmente suficiente. Se você não tiver certeza do que 
definir, poderá escolher Permitir acesso total, mas atribua papéis do IAM para limitar o que a 
instância pode fazer. Se você quiser escolher escopos individualmente, escolha Definir acesso para cada API.
Isso exibirá uma lista de serviços e escopos, como mostrado na Figura 17.11. 
Figura 17.11 Uma lista parcial de serviços e escopos que podem ser configurados individualmente 
Você também pode definir escopos usando o comando gcloud compute instances set-service-account 
. A estrutura do comando é a seguinte: 
gcloud compute ocorrências set-service-account [INSTANCE_NAME] \ 
 [--service-account [SERVICE_ACCOUNT_EMAIL] | [--no-service-account] \ 
 [--no-escopos | --scopes [SCOPES, ...]] 
Um exemplo de atribuição de escopo usando gcloud é o seguinte: 
gcloud compute instâncias set-service-account ace-instance \ 
 --service-account examadmin@ace-exam-project.iam.gserviceaccount. com - 
 escopos compute-rw, storage-ro
416 Capítulo 17 ■ Configuração de acesso e segurança 
Atribuição de uma conta de serviço a uma instância de máquina virtual 
Você pode atribuir uma conta de serviço a uma instância de VM. Primeiro, crie uma conta de serviço navegando até a seção Contas de serviço da seção IAM e administrador do console. Clique em 
Create Service Account para exibir um formulário como o mostrado na Figura 17.12. 
Figura 17.12 Criando uma conta de serviço no console 
Depois de especificar um nome, identificador e descrição, clique em Criar. Em seguida, você pode atribuir 
funções conforme descrito anteriormente, usando os comandos console ou gcloud. Depois de atribuir 
as funções que você deseja que a conta de serviço tenha, você pode atribuí-la a uma instância de VM.
Navegue até a página "Instâncias de VM" na seção "Compute Engine" do console. Selecione 
uma instância de VM e clique em Editar. Isso exibirá um formulário com um parâmetro para a instância. 
Role para baixo para ver o parâmetro denominado Conta de serviço (consulte a Figura 17.13). 
Figura 17.13 Seção da página Editar instância mostrando o parâmetro Conta de serviço 
Na lista suspensa, selecione a conta de serviço que você deseja atribuir a essa instância, 
como mostra a Figura 17.14. 
Gerenciando contas de serviço 417 
Figura 17.14 Lista de contas de serviço que podem ser atribuídas à instância 
Você também pode especificar uma instância de serviço na linha de comando ao criar uma instância 
usando o comando gcloud compute instance create. Tem a seguinte estrutura:
gcloud compute instances create [INSTANCE_NAME] --service-account [SERVICE_ 
ACCOUNT_EMAIL] 
Para conceder acesso a um projeto, navegue até a página IAM do console e adicione um membro. 
Use o email de contas de serviço como a entidade a ser adicionada. 
Visualização dos registros de auditoria 
Para visualizar os registros de auditoria, acesse a página Stackdriver Logging no Cloud Console. Isso 
mostrará uma listagem como a da Figura 17.15. 
Figura 17.15 Lista padrão da página Stackdriver Logging 
418 Capítulo 17 ■ Configuração de Acesso e Segurança 
Observe que você pode selecionar o recurso, os tipos de registros a serem exibidos, o nível de registro e o período 
de tempo a partir do qual as entidades serão exibidas. 
Para obter informações adicionais sobre registro, consulte o Capítulo 18. 
Resumo
Os controles de acesso no GCP são gerenciados usando IAM, funções primitivas e escopos. Os três 
papéis primitivos são proprietário, editor e visualizador. Eles fornecem controles de acesso de granulação grossa 
para os recursos. Escopos são controles de acesso que se aplicam a instâncias de VMs. Eles são usados 
para limitar operações que podem ser executadas por uma instância. O conjunto de operações que uma 
instância pode executar é determinado pelos escopos atribuídos e pelas funções atribuídas a uma conta de serviço usada pela instância. O IAM fornece papéis predefinidos. Essas funções são agrupadas 
por serviço. As funções são projetadas para fornecer o conjunto mínimo de permissões necessárias para realizar 
uma tarefa lógica, como escrever em um intervalo ou implantar um aplicativo do App Engine.
Quando as funções predefinidas não atendem às suas necessidades, você pode definir funções personalizadas. 
Contas de serviço são usadas para permitir que as VMs executem operações com um conjunto de permissões. 
As permissões são concedidas a contas de serviço por meio das funções atribuídas à 
conta de serviço . Você pode usar a conta de serviço padrão fornecida pelo GCP para uma instância ou 
pode atribuir a sua própria. 
Fundamentos do exame 
Conheça os três tipos de funções: primitivo, predefinido e personalizado. Os papéis primitivos incluem 
proprietário, editor e visualizador. Estes foram desenvolvidos antes do lançamento do IAM. Funções predefinidas 
são funções do IAM. As permissões são atribuídas a essas funções e, em seguida, as funções são atribuídas
para usuários, grupos e contas de serviço. As funções personalizadas incluem permissões selecionadas pelo 
usuário que cria a função personalizada. 
Entenda que os escopos são um tipo de controle de acesso aplicado às instâncias de VM. A VM 
só pode executar operações permitidas por escopos e funções do IAM atribuídas à 
conta de serviço da instância. Você pode usar funções do IAM para restringir escopos e usar escopos para restringir funções do IAM. 
Saiba como visualizar funções atribuídas a identidades. Você pode usar a guia Funções na seção IAM e 
Admin do console para listar as identidades atribuídas a funções específicas. Você também pode usar o 
comando get-iam-policy do gcloud projects para listar funções atribuídas a usuários em um projeto.
Entenda que os papéis do IAM apoiam a separação de funções e o princípio do menor privilégio. 
Os papéis primitivos não apoiavam o mínimo privilégio e a separação de deveres, porque são muito 
grosseiros. A separação de tarefas garante que duas ou mais pessoas sejam necessárias para 
concluir uma tarefa sensível. 
Fundamentos do exame 419 
Saiba como usar as funções gcloud iam describe para exibir detalhes de uma função, incluindo permissões atribuídas a uma função. Você também pode visualizar as funções de usuários concedidas explorando uma função 
na página Funções da seção IAM e Admin do console. Ao trabalhar com o IAM, 
você usará o comando gcloud ao trabalhar na linha de comando. 
Entenda as diferentes opções para acessar escopos ao criar uma instância. o
As opções são Acesso padrão, Acesso total e Definir acesso para cada API. Se você não tiver certeza sobre 
qual usar, poderá conceder acesso total, mas certifique-se de limitar o que a instância pode fazer 
atribuindo funções que restrinjam as operações permitidas. 
Saiba que o Stackdriver Logging coleta eventos de registro. Eles podem ser filtrados e exibidos 
na seção Registro do Cloud Console. Você pode filtrar por recurso, tipo de log, nível de log 
e período de tempo para exibição. 
Capítulo 17 ■ Configuração do acesso e da segurança 

Monitoramento, registro em log 
e estimativa de custos 
Este capítulo aborda os seguintes 
objetivos do 
exame de certificação do Engenheiro de nuvem do Google Associate : 
✓ 4.6 Monitoramento e registro em log
✓ 2.1 Planejamento e estimativa do uso do produto GCP usando a 

Calculadora de Preços Capítulo 18 
Monitorar o desempenho do sistema é uma parte essencial da 
engenharia da nuvem . Neste capítulo, você aprenderá sobre o Stackdriver, 
um serviço do GCP para monitoramento, registro, rastreamento e 
depuração de recursos. Você começará criando alertas com base em métricas de recursos e métricas personalizadas. Em seguida, você voltará sua atenção para o registro em log com uma discussão sobre como criar 
coletores de registros para armazenar dados de registro fora do Stackdriver. Você também verá como visualizar e filtrar 
dados de registro. O Stackdriver inclui ferramentas de diagnóstico, como Cloud Trace e Cloud Debugger, sobre as 
quais você também aprenderá. Vamos encerrar o capítulo com uma revisão do preço
Calculadora para estimar o custo de recursos e serviços do GCP. 
O monitoramento com o Stackdriver 
Stackdriver é um serviço para coletar métricas de desempenho, registros e dados de eventos de nossos 
recursos. As métricas incluem medidas como a porcentagem média de utilização da CPU 
no último minuto e o número de bytes gravados em um dispositivo de armazenamento no último minuto. 
O Stackdriver inclui muitas métricas predefinidas. Alguns exemplos são mostrados na Tabela 18.1 que 
você pode usar para avaliar a integridade de seus recursos e, se necessário, acionar alertas para chamar 
sua atenção para recursos ou serviços que não estão atendendo aos objetivos de nível de serviço. 
Guia le 18.1 Exemplo de métricas do Stackdriver Exemplo de métrica do 
produto GCP
Utilização da CPU do 
Compute Engine Bytes do disco do Compute Engine lidos 
BigQuery Tempos de execução 
Carga da CPU do Bigtable 
Funções da nuvem Contagem de execução 
Monitoramento com o Stackdriver O 427 
Stackdriver funciona em ambientes híbridos com suporte ao GCP, Amazon Web Services 
e recursos locais. 
Criando alertas com base em métricas de recursos Métricas 
são medidas definidas em um recurso coletado em intervalos regulares. As métricas 
retornam valores agregados, como o valor máximo, mínimo ou médio do item 
medido, o que pode ser a utilização da CPU, a quantidade de memória usada ou o número de bytes 
gravados em uma interface de rede.
Para este exemplo, suponha que você esteja trabalhando com uma VM que tenha o Apache Server e o PHP 
instalados. Para monitorar e coletar métricas, você precisa instalar o agente do Stackdriver para 
monitoramento. Como você está instalando o agente de monitoramento, instalará o agente de registro 
ao mesmo tempo, porque precisará disso mais tarde. Para instalar os agentes de monitoramento e 
registro do Stackdriver em uma VM do Linux, execute o seguinte comando no prompt do shell (observe que 
esses não são comandos do gcloud): 
curl -sSO https://dl.google.com/cloudagents/install-monitoring- agent.sh 
sudo bash 
install-monitoring-agent.sh curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh 
sudo bash install-logging-agent.sh - estruturado
As VMs com agentes instalados coletam dados de monitoramento e registro e enviam-no ao Stackdriver. 
O Stackdriver precisa de um espaço de trabalho para armazenar os dados. 
Para criar um espaço de trabalho e inicializá-lo, navegue até a seção Stackdriver Monitoring do 
Cloud Console. Se um espaço de trabalho não existir para o seu projeto, um formulário como o mostrado 
na Figura 18.1 será exibido. 
Figuração 18.1 Formulário inicial usado para criar um espaço de trabalho no Stackdriver 
428 Capítulo 18 ■ Monitoramento, registro em log e estimativa de custos 
Em seguida, selecione um projeto para monitorar, conforme mostrado na Figura 18.2. 
F igur e 18.2 Selecionando um projeto para o espaço de trabalho 
Se você quiser monitorar vários projetos em um espaço de trabalho, você pode, opcionalmente, selecionar outros 
projetos, como mostrado na Figura 18.3.
F igur e 18.3 Como adicionar outros projetos para monitorar o 
monitoramento com o Stackdriver 429 
Se você deseja monitorar recursos da AWS em uma área de trabalho, também pode, opcionalmente, selecioná-los 
, conforme mostrado na Figura 18.4. 
F igur e 18.4 Monitorando opcionalmente os recursos da AWS 
430 Capítulo 18 ■ Monitorando, registrando e estimando custos 
A próxima etapa do processo de inicialização lista os comandos para instalar os agentes (consulte a 
Figura 18.5). 
F igur e 18.5 Listagem de instruções para instalar agentes em servidores a serem monitorados O 
Stackdriver enviará relatórios diários ou semanais se você optar por enviar e-mails para eles 
(consulte a Figura 18.6). 
F igur e 18.6 Listagem de opções de relatório de e-mail
Quando o processo de inicialização é concluído, é exibido um formulário semelhante ao mostrado na Figura 18.7 
, que lista algumas tarefas comuns, como adicionar métricas e visualizar notas de versão. 
Monitorando com o Stackdriver 431 
F igur e 18.7 A inicialização do Stackdriver Workspace está concluída. 
Depois que o espaço de trabalho for inicializado, navegue até o Stackdriver Monitoring para exibir uma 
página Visão geral do monitoramento, semelhante à Figura 18.8. 
F igur e 18,8 Monitoramento página Visão geral em Stackdriver 
432 Capítulo 18 ■ monitoramento, registro e cálculo do custo 
Neste ponto, os agentes Stackdriver estão instalados e você tem um espaço de trabalho disponível. 
Em seguida, crie uma política para monitorar uma métrica. Uma política consiste em condições que determinam
quando emitir um alerta ou uma notificação, por exemplo, quando a utilização da CPU for maior que 
80% por mais de 5 minutos. As políticas também incluem canais de notificação e 
documentação opcional , conforme mostrado na Figura 18.9. Este formulário é exibido quando você clica em Criar 
Política na página Visão Geral do Monitoramento. 
F igur e 18.9 Criando uma nova política para monitorar uma métrica 
Clique em Adicionar Condição para exibir um formulário onde você pode especificar os parâmetros de condição. 
A Figura 18.10 mostra o formulário Condição Métrica antes de selecionar a utilização da CPU. 
Após selecionar a utilização da CPU, parâmetros adicionais são exibidos, conforme mostrado na 
Figura 18.11. A condição verificará o status de utilização da CPU. Será aplicado às VMs
que correspondem aos critérios de filtro, por exemplo, qualquer VM com um rótulo incluído no filtro. Os 
critérios de filtro incluem recursos da VM, como zona, região, ID do projeto, ID da instância e rótulos. 
O parâmetro Agrupar por permite agrupar séries temporais, ou dados produzidos em intervalos regulares e que possuem um formato fixo, por exemplo, por zona, e agregar os valores para que haja 
menos séries temporais a serem exibidas. Isso é especialmente útil, por exemplo, se você quiser que 
um grupo de VMs em um cluster apareça como uma única série temporal. 
Monitorando com o Stackdriver 433 
F igur e 18.10 Selecionando uma métrica de utilização da CPU 
F igur e 18.11 Parâmetros adicionais para configurar o monitoramento da utilização da CPU 
434 Capítulo 18 ■ Monitoramento, Registro em Log e Estimativa de Custos
Os agentes enviam dados de recursos monitorados para o Stackdriver em fluxos. Para executar verificações 
nos dados em fluxo, os pontos de dados precisam ser agregados em intervalos de tempo específicos. Por 
exemplo, os pontos de dados podem ser recebidos a cada 20 segundos, mas para fins de monitoramento, 
verificamos a utilização média da CPU por minuto. Considere um fluxo de métricas de utilização da CPU 
que chega ao Stackdriver ao longo de um período de 1 minuto. É útil consolidar essas medidas em um valor único, como o valor médio, máximo ou mínimo para o conjunto de medidas para esse minuto. Esse processo de agrupar dados em intervalos regulares de tempo é 
chamado de alinhamento. A Figura 18.12 mostra algumas das funções, incluindo min, max e mean,
que pode ser aplicado aos dados que chegam em um intervalo de tempo. 
Figuração 18.12 Agregados opcionais para o Alinhador 
Além de alinhar a série temporal, quando você agrega, é possível especificar um redutor, 
que é uma função para combinar valores em um grupo de séries temporais para produzir um único 
valor. Os redutores incluem estatísticas comuns, como sum, min, max e count (veja a 
Figura 18.13). 
F igur e 18.13 Funções agregadas para reduzir vários valores para um único valor 
Monitorando com o Stackdriver 435 
Em seguida, você precisa especificar quando uma condição deve ser acionada, conforme mostrado na Figura 18.14. 
Isso pode ser sempre que você vir um valor que exceda o limite especificado ou pode ser
somente se o valor medido exceder um limite por um longo período de tempo. Por exemplo, 
você só pode acionar um alerta sobre a utilização da CPU se estiver acima de um limite por mais 
de cinco minutos. Isso pode ajudar a evitar que muitos alertas sejam gerados apenas porque 
há um aumento ocasional, mas de curto prazo, na utilização da CPU. 
F igur e 18.14 Especificando um limite acima do qual um alerta é acionado 
Uma política pode ter um ou mais canais de notificação. Os canais incluem notificação por e-mail, bem como Slack, Google Cloud Console (móvel) e ferramentas populares de DevOps, como 
PagerDuty, HipChat e Campfire (veja a Figura 18.15). 
F igur e 18.15 Especificando os canais de notificação 
436 Capítulo 18 ■ Monitorando, registrando e estimando custos
O parâmetro de documentação, mostrado na Figura 18.16, é opcional, mas recomendado. 
A documentação será incluída nas notificações, o que pode ajudar os engenheiros de DevOps a 
entender o problema e fornecer informações sobre como resolver o problema. 
F igur e 18.16 Adicionando documentação e um nome de política, juntamente com uma condição e 
especificações de notificação 
Depois que as políticas são definidas, você pode visualizar um resumo do histórico recente da métrica de 
volta ao momento em que a política foi definida. Isso inclui visualizações como as 
mostradas na Figura 18.17. 
Monitorando com o Stackdriver 437 
F igur e 18.17 O status da política e uma exibição da carga da CPU no passado recente 
Criando métricas personalizadas
Se houver uma métrica específica do aplicativo que você gostaria de monitorar, você pode criar métricas personalizadas. As métricas personalizadas são como métricas predefinidas, exceto que você as cria. Os nomes de 
métricas personalizadas começam com custom.googleapis.com/, por isso são fáceis de reconhecer pelo nome. A 
diferença mais importante é que você pode decidir quais dados da série temporal serão gravados na métrica personalizada. 
Há duas maneiras de criar métricas personalizadas: usando o OpenCensus, uma 
biblioteca de monitoramento de código aberto (https://opencensus.io/) ou usando a API de monitoramento do Stackdriver. 
O OpenCensus fornece uma API de alto nível e com foco em monitoramento, enquanto a 
API do Stackdriver Monitoring é de nível inferior. 
Quando você define uma métrica personalizada, precisa especificar o seguinte:
■ Um nome de tipo que é exclusivo dentro do projeto 
■ Um projeto 
■ Um nome de exibição e uma descrição 
■ Um tipo de métrica, como um indicador, delta ou métrica cumulativa. Os indicadores são medidas em um 
determinado momento, os deltas capturam a mudança ao longo de um intervalo e os cumulativos são valores acumulados ao longo de um intervalo. 
438 Capítulo 18 ■ monitoramento, registro e cálculo do custo 
■ etiquetas métricas 
■ monitorado objetos de recurso para incluir com pontos de dados de séries temporais. Estes fornecem o 
contexto para uma medição. Por exemplo, você pode incluir um ID de instância do aplicativo 
com uma métrica específica do aplicativo. 
Para definir uma métrica personalizada, você precisará programar uma chamada para a API de monitoramento ou usar
a biblioteca do OpenCensus. Como isso é feito varia de acordo com a linguagem de programação usada. Consulte 
a documentação do Stackdriver do Google para obter exemplos usando C #, Go, Java, Node.js, PHP e 
Python (https://cloud.google.com/monitoring/custom-metrics/creating-metrics). 
Muitos monitores são tão ruins quanto poucos 
Tenha cuidado ao elaborar políticas de monitoramento. Você não quer submeter os engenheiros de DevOps 
a tantos alertas que eles começam a ignorá-los. Isso às vezes é chamado de fadiga de alerta. Políticas que são muito sensíveis geram alertas quando nenhuma intervenção humana é necessária. Por 
exemplo, a utilização da CPU pode aumentar regularmente por breves períodos de tempo. Se este for um padrão normal para o seu ambiente e não estiver impactando negativamente sua capacidade de atender ao nível de serviço
acordos, então há poucos motivos para alertá-los. Crie políticas para identificar condições 
que realmente requeiram a atenção de um engenheiro e provavelmente não serão resolvidas por conta própria. 
Use limites que sejam longos o suficiente para que as condições não sejam acionadas em estados transitórios que 
não durem muito. Muitas vezes, quando um engenheiro resolve, a condição não é mais acionada. Projetar políticas de monitoramento é uma espécie de arte. Você deve assumir que 
precisará de várias iterações para ajustar suas políticas e encontrar o equilíbrio certo para gerar os 
tipos certos de alertas úteis, sem gerar alertas que não sejam úteis. 
Registrando com o Stackdriver
O Stackdriver Logging é um serviço para coletar, armazenar, filtrar e exibir 
dados de log e de eventos gerados no GCP e no Amazon Web Services. O log é um serviço gerenciado, portanto, você 
não precisa configurar ou implantar servidores para usar o serviço. 
As diretrizes do Associate Cloud Engineering Exam anotam três tarefas de registro em que um engenheiro de nuvem deve estar familiarizado: 
■ Configurando os coletores de logs 
■ Visualizando e filtrando registros 
■ Visualizando os detalhes da mensagem 
Revisaremos cada um deles nesta seção. 
Configurando os 
coletores de registros O Stackdriver Logging mantém os dados do registro por 30 dias. Isso é suficiente se você usar logs para diagnosticar problemas operacionais, mas raramente os visualizar após alguns dias. Isso geralmente não é suficiente.
Registrando com o Stackdriver 439 
Sua organização pode precisar manter os registros por mais tempo para cumprir as 
regulamentações governamentais ou do setor . Você também pode querer analisar os logs para obter informações sobre o desempenho do aplicativo. Para esses casos de uso, é melhor exportar dados de registro para um sistema de armazenamento de longo prazo, 
como o Cloud Storage ou o BigQuery. 
O processo de copiar dados do registro em log para um sistema de armazenamento é chamado de exportação, e 
o local no qual você grava os dados do registro é chamado de coletor. Você pode criar um coletor de logs 
navegando até a seção Registro do Cloud Console e selecionando a opção Exportações 
no menu Registro, conforme mostrado na Figura 18.18. 
F igur e 18.18 Formulário de exportação de log no Cloud Console
Clique em Criar Exportação para abrir um formulário para criar um coletor de log. O formulário solicita três 
parâmetros: 
■ Nome do dissipador 
■ Serviço de 
afundamento ■ Destino do 
dissipador Você pode criar um nome de coletor, como na Figura 18.19. O serviço de coletor é um dos 
seguintes: 
■ BigQuery 
■ Cloud Storage 
■ Cloud Pub / Sub 
■ 
Fator de destino personalizado 18.19 Criando um coletor de log do BigQuery 414 
Capítulo 18 ■ Monitorando, registrando e estimando custos 
Se você escolher o BigQuery como seu serviço, o destino do coletor será um 
conjunto de dados existente do BigQuery ou um novo conjunto de dados, conforme mostrado na Figura 18.19. Quando os dados do log são exportados
para o BigQuery, ele é organizado em tabelas com base no nome do registro e nos registros de data e hora. Por exemplo, um syslog exportado em 2 de janeiro de 2019 teria o nome syslog_20190102. As 
tabelas possuem colunas que armazenam o registro de data e hora, o nome do log e a carga de texto ou a mensagem de log. 
Se você escolher o Cloud Storage, poderá exportar logs para um intervalo existente ou criar um novo intervalo (veja a Figura 18.20). Quando os dados do log são exportados para o Cloud Storage, o registro 
grava um conjunto de arquivos no bucket do coletor. Os arquivos são organizados hierarquicamente por tipo de registro e 
data. Por exemplo, se um syslog for exportado em 2 de janeiro de 2019 para um bloco chamado ace-examlog-sink1, o caminho para o arquivo seria ace-exam-log-sink1 / syslog / 2019/01/02 /. 
F igur e 18.20 Criando um coletor de log do Cloud Storage
Se você escolher Cloud Pub / Sub, poderá escolher entre criar um tópico ou usar um 
existente, como mostra a Figura 18.21. Quando os dados de log são exportados para o Cloud Pub / Sub, os 
dados são codificados em base64 em uma estrutura de objetos conhecida como LogEntry. LogEntries contém 
as propriedades logname, timestamp, textPayload e resource, como type, instance_id, 
zone e project_id. 
F igur e 18.21 Criando um dissipador de log de Pub / Sub 
Registrando com o Stackdriver 441 
Um destino personalizado é usado para especificar o nome de um projeto, diferente do 
projeto atual , que está hospedando o coletor. Se você optar por criar um novo objeto como um coletor, será 
solicitado que você nomeie o novo coletor, conforme mostrado na Figura 18.22.
F igur e 18.22 Especificando o nome de um novo conjunto de dados do BigQuery 
Depois que um coletor é criado, você receberá uma mensagem como a mostrada na Figura 18.23, 
com detalhes sobre o coletor recém-criado. 
F igur e 18.23 Confirmação de que um novo coletor foi criado 
Exibindo e filtrando registros 
Para exibir o conteúdo dos registros, navegue até a seção Stackdriver Logging do console e 
selecione Registros no menu Registro, conforme mostrado na Figura 18.24. 
F igur e 18,24 Listagem de entradas de log no Cloud Console 
442 Capítulo 18 ■ monitoramento, registro e cálculo do custo 
Observe que no topo da forma, existem várias opções para mensagens de log de filtragem, 
incluindo filtragem a seguinte redacção: 
Etiqueta ou texto de pesquisa ■
■ Tipo de recurso ■ Tipo de 
registro 
■ Nível de registro 
■ Limite de tempo 
There is also an option to jump to the latest entries by selecting Jump To Now.
You can use the label or text search to filter on text strings or labels in log messages. For
example, Figure 18.25 shows a set of log entries filtered by the text Monitoring. Stackdriver
will add types such as text: as needed.
F igur e 18.25 Log entries that contain the text string Monitoring
The resource type drop-down box (see Figure 18.26) provides a list of GCP resource
types, including any audited resources, VM instances, subnetworks, projects, and databases.
F igur e 18.26 Partial list of resource types for filtering logs
Logging with Stackdriver 443
The drop-down box labeled All Logs lets you filter by log type (see Figure 18.27).
configurado 18.27 Exemplo de listagem de registros gerando entradas no Stackdriver Logging 
A próxima opção, Qualquer nível de registro, exibe níveis de mensagens de log, como Erro, Informações, Aviso 
e Depuração Figura 18.28). 
F igur e 18.28 Uma lista de níveis de log que podem ser usados ​​para filtrar entradas de log exibidas 
O filtro de seleção de hora mostra No Limit por padrão. A lista suspensa (veja a Figura 18.29) 
inclui vários intervalos de tempo e permite um limite de tempo personalizado. 
F igur e 18.29 Opções de intervalo de tempo predefinidas para filtragem de entradas de registro 
Se você escolher Personalizado, poderá selecionar datas de início e término, conforme mostrado na Figura 18.30.
444 Capítulo 18 ■ Monitoramento, Registro em log e Estimativa de custos 
Formulário para especificar um intervalo de tempo personalizado para filtrar entradas de log 
Visualizar detalhes da mensagem 
Cada entrada de log é exibida como uma única linha quando você exibe o conteúdo dos logs. Observe o 
ícone do triângulo no final esquerdo da linha. Se você clicar nesse ícone, a linha será expandida para mostrar 
detalhes adicionais. Por exemplo, a Figura 18.31 mostra uma entrada de log expandida em um nível. 
F igur e 18.31 Uma entrada de log expandiu um nível 
No caso da expansão de primeiro nível, você vê informações de alto nível, como insertId, 
logName e receiveTimestamp. Você também vê outros elementos de dados estruturados, como
protoPayload e recursos. A Figura 18.32 mostra a estrutura protoPayload expandida. 
Registro com o Stackdriver 445 
F igur e 18.32 Uma entrada de registro com a estrutura protoPayload expandida 
Você pode continuar a fazer drill down individualmente em cada estrutura se houver um triângulo à 
esquerda. Por exemplo, na estrutura protoPayload, você poderia detalhar em authenticationInfo, authorizationInfo e requestMetadata, entre outros. Como alternativa, você pode 
clicar no link Expandir Tudo no canto superior direito da listagem de entrada de log para expandir todas as 
estruturas (veja a Figura 18.33). 
F igur e 18.33 Uma listagem parcial de uma entrada de log totalmente expandida O 
Stackdriver Logging é usado para coletar dados e eventos de log e armazená-los por até
30 dias. Os registros podem ser exportados para o Cloud Storage, o BigQuery e o Cloud Pub / Sub. O Cloud 
Console fornece uma interface de registro que fornece várias maneiras de filtrar e pesquisar 
entradas de registro . 
446 Capítulo 18 ■ Monitoramento, registro em log e estimativa de custos 
usando o Cloud Diagnostics O 
Google Cloud Platform fornece ferramentas de diagnóstico que os desenvolvedores de software podem usar para coletar informações sobre o desempenho e o funcionamento de seus aplicativos. Especificamente, os 
desenvolvedores podem usar o Cloud Trace e o Cloud Debug para coletar dados conforme seus aplicativos são 
executados. 
Visão geral do Cloud Trace 
Cloud O Trace é um sistema de rastreamento distribuído para coletar dados de latência de um aplicativo.
Isso ajuda os desenvolvedores a entender onde os aplicativos estão gastando seu tempo e a identificar 
casos em que o desempenho é degradante. A Figura 18.34 mostra a página de visão geral do 
serviço Cloud Trace. 
F igur e 18.34 Overview of Cloud Trace
From the Cloud Trace console, you can list traces generated by applications running in
a project. Traces are generated when developers specifically call Cloud Trace from their 
Using Cloud Diagnostics 447
applications. In addition to seeing lists of traces, you can create reports that filter trace data
according to report criteria (see Figure 18.35).
F igur e 18.35 Creating a report using Cloud Trace data
In addition to filtering on time and trace query, you can filter on HTTP method (see
Figure 18.36) and return status (see Figure 18.37).
F igur e 18.36 Filtering trace data by HTTP method
448 Chapter 18 ■ Monitoring, Logging, and Cost Estimating
Figurar e 18.37 Filtrar dados de rastreamento por código de resposta 
Para o objetivo do exame de Engenharia de Nuvem Associada, lembre-se de que o Cloud Trace 
é um aplicativo de rastreamento distribuído que ajuda desenvolvedores e engenheiros de DevOps a identificar seções de código que são gargalos de desempenho. 
Visão geral do Cloud Debug O 
Cloud Debug é um depurador de aplicativos para inspecionar o estado de um programa em execução. Como o 
Cloud Trace, essa é uma ferramenta normalmente usada por desenvolvedores de software, mas é útil para nuvem
engenheiros estejam familiarizados com os recursos do Cloud Debug. 
O Cloud Debug permite que os desenvolvedores insiram instruções de log ou obtenham instantâneos do estado 
de um aplicativo. O serviço é ativado por padrão no App Engine e pode ser ativado para o 
Compute Engine e o Kubernetes Engine. 
Usando o Cloud Diagnostics 449 
Para visualizar o Cloud Debug, navegue até Cloud Debug no Cloud Console para exibir uma página como 
a mostrada na Figura 18.38. 
F igur e 18.38 Página Visão geral do Cloud Debug A 
seleção de um arquivo de programa exibe o conteúdo do arquivo. Por exemplo, a Figura 18.39 
mostra o conteúdo de um arquivo chamado main.py. 
F igur e 18.39 Listagem de código do programa Python de amostra fornecido pelo Google
Nesta interface, você pode clicar em uma linha de código para obter um instantâneo quando a linha é 
executada. Na Figura 18.40, a seta azul clara na linha 20 indica onde o Cloud Debug irá 
tirar o instantâneo. 
Capítulo 18 ■ Monitoramento, Registro em Log e Estimativa de Custos 
Configuração do 18.40 Definição de um instantâneo a ser executado quando a linha 20 é executada 
Você também pode injetar um ponto de log, que é uma instrução de log que é gravada no log quando 
a instrução é executada. Na Figura 18.41, uma linha de código foi adicionada para criar um logpoint 
e imprimir uma mensagem. 
Para o objetivo do exame Associate Cloud Engineer, lembre-se de que o Cloud Debug 
é usado para tirar instantâneos do status de um programa enquanto ele é executado, e os logpoints permitem
desenvolvedores para injetar mensagens de registro em tempo real sem alterar o código-fonte. 
Usando o Cloud Diagnostics 451 
F igur e 18.41 Código com um logpoint injetado 
Exibindo o status do Google Cloud Platform 
Além de entender o estado dos seus aplicativos e serviços, os engenheiros da nuvem 
precisam estar cientes do status dos serviços do GCP. Você pode encontrar esse status no 
Painel de status do Google Cloud. 
Para visualizar o status dos serviços do Google Cloud, acesse a página inicial no Cloud Console 
e encontre o cartão de status do Google Cloud Platform na página inicial (veja a Figura 18.42). Você 
também pode encontrar o painel em https://status.cloud.google.com/. 
452 Capítulo 18 ■ Monitoramento, Registro em Log e Estimativa de Custos
F igur e 18.42 A home page do Cloud Console tem um cartão vinculado ao 
Painel de status do Cloud . 
Clique no link Ir para o painel de status da nuvem para exibir o painel. Um exemplo é 
mostrado na Figura 18.43. 
F igur e 18.43 Listagem parcial do Painel de status do Google Cloud 
Usando a calculadora de preços 453 
O painel lista os serviços do GCP no lado esquerdo. As colunas representam dias no 
passado recente. O conteúdo de cada célula indica o status. Se houver uma marca de verificação verde, o 
serviço estará em funcionamento. Se houver um ícone laranja, por exemplo, como na 
linha Armazenamento na nuvem e na coluna 21 de dezembro, houve uma interrupção no serviço. Clique na laranja
ícone para exibir detalhes adicionais, como mostrado na Figura 18.44. 
F igur e 18.44 Exemplo de descrição da interrupção do serviço 
Usando a Calculadora de Preços O 
Google fornece uma Calculadora de Preços para ajudar os usuários do GCP a entender os custos associados 
aos serviços e à configuração dos recursos que eles escolhem usar. A calculadora de preços 
é uma ferramenta on-line em https://cloud.google.com/products/calculator/. 
Com a Calculadora de Preços, você pode especificar a configuração de recursos, o tempo que eles serão 
usados ​​e, no caso de armazenamento, a quantidade de dados que serão armazenados. Outros parâmetros 
podem ser especificados também. Esses variam de acordo com o serviço para o qual você está calculando as cobranças. 
For example, Figure 18.45 shows some of the services available to use with the Pricing
Calculator. Currently, there are almost 40 services available in the Pricing Calculator.
454 Chapter 18 ■ Monitoring, Logging, and Cost Estimating
F igur e 18.45 Pricing Calculator banner with a partial display of services available
Figure 18.46 shows part of the form for estimating the cost of VMs. In this form you
can specify the following:
■ Number of instances
■ Machine types
■ Operating system
■ Average usage per day and week
■ Persistent disks
■ Load balancing
■ Cloud TPUs (for machine learning applications)
F igur e 18.46 Partial listing of pricing form for VMs
Usando a calculadora de preços 455
Depois de inserir os dados no formulário, a Calculadora de Preços gerará uma estimativa, 
como a mostrada na Figura 18.47. 
F igur e 18.47 Exemplo de estimativa de preço para 2 VMs n1-standard-1 
Diferentes recursos exigirão parâmetros diferentes para uma estimativa. Por exemplo, a 
Figura 18.48 mostra a estimativa do preço de um cluster do Kubernetes, que requer detalhes 
sobre VMs, discos permanentes e balanceadores de carga. 
A Figura 18.49 mostra outro exemplo, desta vez para o BigQuery. Para esse serviço, você 
precisa especificar a localização de seus dados, a quantidade de dados armazenados, o volume transmitido 
e o volume de dados verificados durante a execução de consultas. O parâmetro da tabela é onde
você indica qual tabela do BiqQuery você está consultando. O Preço de armazenamento e o Preço de consulta 
aceitam valores numéricos para a quantidade de dados armazenados na tabela (GBs) e o volume 
digitalizado durante as consultas (TBs). Além disso, há uma opção para preços fixos se você gastar mais 
de US $ 40.000 por mês. 
456 Capítulo 18 ■ Monitoramento, Registro em Log e Estimativa de Custos 
Formulário para estimar o preço de um cluster do 
Kubernetes F igur e 18.49 Os parâmetros necessários para estimar o custo de armazenamento e consulta de 
dados do BigQuery 
Exam Essentials 457 O 
The Pricing Calculator allows you to estimate the price of multiple services and then
generate a total estimate for all services.
Summary
Cloud engineers are responsible for monitoring the health and performance of applications
and cloud services. GCP provides multiple tools, including monitoring, logging, debugging,
and tracing services.
Stackdriver Monitoring allows you to define alerts on metrics, such as CPU utilization,
so that you can be notified if part of your infrastructure is not performing as expected.
Stackdriver Logging collects, stores, and manages log entries. Log data that needs to be
stored more than 30 days can be exported to Cloud Storage, BigQuery, or Cloud Pub/Sub.
Cloud Trace fornece serviços de rastreamento distribuídos para identificar partes de código de execução lenta.
O Cloud Debug fornece a criação de instantâneos de código em execução e a injeção de mensagens de log 
sem alterar o código-fonte. 
Você sempre pode obter o status dos serviços do GCP no Painel de status do Google Cloud em 
https://status.cloud.google.com/. 
A calculadora de preços foi projetada para ajudar você a estimar o custo de quase 40 serviços no 
GCP. 
Fundamentos do exame 
Entenda a necessidade de monitoramento e o papel das métricas. As métricas fornecem dados sobre o 
estado dos aplicativos e da infraestrutura. Criamos condições, como CPU excedendo 80% 
por 5 minutos, para acionar alertas. Os alertas são entregues por canais de notificação. O GCP tem um 
número substancial de métricas predefinidas, mas você também pode criar métricas personalizadas.
O Stackdriver Logging coleta, armazena, filtra e exibe dados de registro. Logs podem vir de 
praticamente qualquer fonte. O registro mantém os dados do registro por 30 dias. Se você precisar manter os dados de log mais longos do que isso, precisará exportar os dados para um coletor de logs. Os coletores de log podem ser um 
intervalo do Cloud Storage, um conjunto de dados do BigQuery ou um tópico do Cloud Pub / Sub. 
Saiba como filtrar logs. Os logs podem conter uma grande quantidade de dados. Use filtros para pesquisar 
texto ou rótulos, limitar as entradas de log por tipo e gravidade de log e restringir o intervalo de tempo a um 
período de interesse. 
Entradas de log são hierárquicas. O Stackdriver Logging exibe um resumo de linha única para uma 
entrada de registro por padrão, mas você pode detalhar os detalhes de uma entrada de registro. Use o Expand All
e Recolher todas as opções para exibir ou ocultar rapidamente os detalhes completos de uma entrada de log. 
O Cloud Trace é um serviço de rastreamento distribuído. Os desenvolvedores de software incluem o 
código do Cloud Tracer em seus aplicativos para registrar dados de rastreamento. Os dados de rastreio podem ser visualizados como 
rastreios individuais ou você pode criar relatórios que incluam parâmetros que especifiquem um subconjunto de rastreios a serem 
incluídos. 
O 
Debug na nuvem é usado para analisar o código em execução, tirando instantâneos ou injetando logpoints. 
Instantâneos mostram a pilha, ou contexto de execução, em um ponto na execução de um programa. 
Logpoints são instruções de log injetadas no código em execução, mas não requerem alterações no 
código-fonte.
O GCP publica o status dos serviços na página de status do Google Cloud Platform. Inclui 
uma lista de todos os serviços, seu status atual e o status no passado próximo. Se houver um 
incidente em um serviço, você encontrará detalhes adicionais sobre o impacto e a causa raiz do 
problema. 
A Calculadora de Preços é usada para estimar o custo de recursos e serviços no GCP. 
Está disponível em https://cloud.google.com/products/calculator/. 
Existe uma calculadora separada para cada serviço. Cada serviço tem seu próprio conjunto de parâmetros 
para estimar custos. A calculadora de preços permite estimar o custo de vários serviços e gerar uma estimativa total para todos esses serviços. 

Capítulo 1: Visão geral do Google Cloud
Plataforma 
1. B. A unidade básica para comprar recursos de computação é a máquina virtual (VM). Um 
servidor físico é subjacente às VMs, mas os recursos de um servidor físico são alocados para as VMs. 
Blocos e sub-redes não são relevantes para a unidade fundamental da computação. 
2. D. Ao usar clusters gerenciados, o provedor de nuvem monitorará a integridade dos nós no 
cluster, configurará a rede entre nós no cluster e configurará o firewall e outros 
controles de segurança. 
3. O B. App Engine é uma plataforma sem servidor para executar aplicativos, enquanto o Cloud Functions é um 
serviço para executar funções de execução curta em resposta a eventos. O Kubernetes Engine é um
serviço de cluster gerenciado e o Kubernetes Engine e o Compute Engine exigem que você 
configure servidores. 
4. O armazenamento de objetos, como o Cloud Storage, fornece objetos armazenados de forma redundante, sem limitar a quantidade de dados que você pode armazenar, o que torna a opção B correta. Como a 
funcionalidade do sistema de arquivos não é necessária, a opção D não é uma boa opção. O armazenamento em bloco pode ser usado, 
mas você teria que gerenciar sua própria replicação para garantir alta disponibilidade. Os caches são 
transitórios, armazenamento em memória e não são sistemas de armazenamento persistentes e de alta disponibilidade. 
5. D. Os tamanhos dos blocos em um sistema de armazenamento em bloco podem variar; Portanto, a opção D é a resposta correta. 
O tamanho do bloco é estabelecido quando um sistema de arquivos é criado. Tamanhos de bloco de 4KB são comumente usados
no Linux. 
6. C. Os firewalls no Google Cloud Platform (GCP) são controles de rede definidos por software que 
limitam o fluxo de tráfego para dentro e para fora de uma rede ou sub-rede, portanto, a opção C é a 
resposta correta . Os roteadores são usados ​​para mover o tráfego para destinos apropriados na rede. O gerenciamento de acesso à identidade é usado para autenticar e autorizar usuários; não é relevante para 
os controles de rede entre sub-redes. Tabelas de endereços IP não são um controle de segurança. 
7. C. A opção C está correta porque os serviços especializados no GCP não têm servidor. O Google gerencia 
os recursos de computação usados ​​pelos serviços. Não há necessidade de um usuário alocar ou 
monitorar VMs.
8. B. A opção B está correta; investir em servidores funciona bem quando uma organização pode 
prever com precisão o número de servidores e outros equipamentos necessários por um período prolongado e 
pode utilizar esse equipamento de forma consistente. As startups não são empresas estabelecidas com históricos que podem orientar as necessidades esperadas em três a cinco anos. Não importa se um orçamento é 
fixo ou variável; investir em servidores deve basear-se na demanda por capacidade de servidor. 
9. B. As características do servidor, como o número de servidores virtuais, a quantidade de 
memória e a região onde você executa a VM, influenciam o custo; portanto, a opção B está correta. 
A hora do dia não é um fator nem o tipo de aplicativo que você executa na VM.
10. D. Cloud Vision é um dos serviços especializados da GCP. Os usuários do serviço não precisam 
configurar nenhuma VM para usar o serviço. 
Capítulo 1: Visão geral do Google Cloud Platform 465 
11. B. Os contêineres oferecem a maior flexibilidade para usar os recursos de um cluster de maneira eficiente e as 
plataformas de orquestração reduzem a sobrecarga das operações, o que torna a opção B correta. 
A execução em um único cluster não é recomendada porque, se o servidor falhar, todos os serviços ficarão 
inativos. Usando duas VMs com um somente leitura não é útil. Servidores somente leitura às vezes são 
usados ​​com bancos de dados, mas não houve menção de bancos de dados na questão. Usando um pequeno
A VM e a atualização, quando não for mais capaz de acompanhar a carga de trabalho, fornecem serviços de baixa qualidade aos usuários e devem ser evitados. 
12. D. Todas as operações estão disponíveis para um administrador do sistema depois de criar uma VM, 
portanto , a opção D está correta. 
13. A. A opção A está correta; O Cloud Filestore é baseado no Network Filesystem (NSF), que é um 
sistema de gerenciamento de arquivos distribuído. As outras opções são sistemas de arquivos suportados pelo Linux, 
mas não são a base do Cloud Filestore. 
14. A. Quando você cria uma rede, ela é tratada como uma nuvem privada virtual, o que torna a opção 
A correta. Recursos são adicionados ao VPC e não são acessíveis fora do VPC, a menos que
você explicitamente configurá-los para ser. Um subdomínio está relacionado a domínios da web e não está relacionado 
à configuração de rede do GPC. Os clusters, como os clusters do Kubernetes, podem estar em sua rede, mas não são uma característica da rede. 
15. D. Caches usam memória e isso os torna o tipo de armazenamento mais rápido para leitura de dados, então a 
opção D está correta. Caches são armazenamentos de dados no backend de sistemas distribuídos, não nos clientes. Um cache não teria efeito na execução do JavaScript do lado do cliente. Os caches não armazenam 
dados em um cache se a energia for perdida; os dados teriam que ser recarregados. Os caches podem sair 
sync with the system of truth because the system of truth could be updated, but the cache
may not be updated. Caches have faster read times than SSDs and HDDs.
16. B. Option B is correct; cloud providers have large capacity and can quickly allocate
those resources to different customers. With a mix of customers and workloads, they can
optimize the allocation of resources. Option A is incorrect; cloud providers do not take
resources from one customer to give them to another, with the exception of preemptible
instances. Option C is incorrect; cloud providers usually offer discounts for increased use.
17. C. Specialized services are monitored by Google so users do not have to monitor them;
, portanto, a opção C está correta. Serviços especializados fornecem uma funcionalidade de computação específica
mas não requer que o usuário configure nenhum recurso. Eles também fornecem APIs. 
18. B. Unidades anexadas são dispositivos de armazenamento em bloco. O Cloud Storage é o serviço de armazenamento de objetos 
e não é anexado diretamente a uma VM. O NoSQL é um tipo de banco de dados, não um sistema de armazenamento. 
Unidades anexadas podem ser SSDs ou discos rígidos. 
19. C. Os bancos de dados exigem armazenamento persistente em dispositivos de bloco. O armazenamento de objetos não fornece 
armazenamento de bloco de dados ou de sistema de arquivos, fazendo da opção C a resposta correta. O armazenamento de dados não é um 
tipo de sistema de armazenamento. Os caches são frequentemente usados ​​com bancos de dados para melhorar o desempenho de leitura, 
mas são voláteis e não são adequados para armazenar persistentemente arquivos de dados.
20. B. Todos os três serviços são sem servidor, portanto, o usuário não precisa configurar VMs; portanto, a 
opção B está correta. O Cloud Storage é cobrado com base no tempo e no tamanho dos dados armazenados. O App 
Engine Standard e as Cloud Functions não estão restritos apenas ao idioma Go. 
466 Apêndice ■ Respostas a perguntas de revisão 
Capítulo 2: 
Serviços do Google Cloud Computing 
1. C. O Cloud Load Balancing distribui cargas de trabalho dentro e entre regiões, fornece 
verificações de integridade e implementa o escalonamento automático. O Cloud DNS fornece serviços de nome de domínio, como a 
tradução de um URL, como www.example.com, para um endereço IP. O Cloud Spanner é um 
banco de dados relacional distribuído, mas não implementa a distribuição de carga de trabalho. Cloud CDN distribui
conteúdo entre regiões para reduzir a latência ao entregar conteúdo para usuários em todo o mundo. 
2. C. Os ambientes flexíveis do App Engine permitem que você execute contêineres na PaaS do App Engine. 
O Kubernetes Engine é uma plataforma de orquestração para a execução de contêineres. Ambos fornecem serviços de gerenciamento de contêineres. O ambiente padrão do App Engine executa aplicativos em 
caixas de proteção específicas de idiomas e não é um sistema geral de gerenciamento de contêineres. O Cloud 
Functions é um serviço sem servidor para executar código em resposta a eventos. Não fornece 
serviços de contêiner. 
3. D. As opções A e B são ambas respostas corretas. A plataforma Apigee API fornece serviços de limitação de taxa e roteamento baseados em políticas para ajudar a acomodar picos de tráfego. Isso também
fornece autenticação OAuth 2.0 e SAML. Não fornece controle de versão; O Cloud 
Source Repositories é o usuário do serviço para controle de versão. 
4. A. O Cloud Armor baseia-se nos serviços de balanceamento de carga do GCP para permitir ou 
restringir o acesso com base no endereço IP, implantar regras para combater ataques de script entre sites e 
fornecer contramedidas para ataques de injeção de SQL. O Cloud CDN é um 
serviço de distribuição de conteúdo , não um serviço de segurança. O Identity Access Management é um serviço de segurança, mas é para 
autenticação e autorização, não para mitigação de negação de serviço. Nuvens privadas virtuais
são usados ​​para restringir o acesso à rede aos recursos de uma organização, mas não possuem recursos para reduzir os ataques de negação de serviço. Além disso, o Cloud CDN atua como uma primeira linha de defesa no 
caso de ataques DDoS. 
5. A. Esse é um bom caso de uso para VMs preemptivas, pois elas poderiam reduzir o custo de execução do segundo aplicativo sem o risco de perder o trabalho. Como as tarefas são excluídas da 
fila somente depois de concluídas, se uma VM preemptiva for desligada antes de concluir 
a tarefa, outra VM poderá executar a tarefa. Além disso, não há nenhum problema em executar uma tarefa mais 
de uma vez, portanto, se duas VMs realizarem a mesma tarefa, isso não afetará negativamente a saída do 
aplicativo. DataProc e Spanner não são produtos apropriados para esta tarefa.
6. O B. Cloud Memorystore é o único GCP projetado para armazenar dados em cache na memória. O Cloud SQL é 
um serviço de banco de dados relacional e pode ser uma boa opção para o banco de dados de back-end. O Cloud 
Spanner é um banco de dados relacional global e é uma boa opção quando você precisa de um banco de dados globalmente consistente. O Cloud Datastore é um banco de dados de documentos adequado para catálogos de produtos, 
perfis de usuário e outros dados semiestruturados. 
7. D. Todos os três serviços listados, Compute Engine, Cloud Storage e firewalls de rede, 
podem ser gerenciados e configurados usando o Cloud SDK. 
8. D. Cloud Functions é um produto sem servidor, nenhuma configuração é necessária. 
Capítulo 2: Serviços do Google Cloud Computing 467
9. D. O produto Stackdriver Logging é usado para consolidar e gerenciar logs gerados por 
aplicativos e servidores. 
10. B. O conjunto de analítica de dados de serviços especializados inclui produtos que ajudam na extração, 
transformação e carregamento (ETL) e trabalham com dados em lote e streaming. A plataforma Apigee API é usada para gerenciar APIs e não atende às necessidades descritas. O AI e o 
aprendizado de máquina podem ser úteis para analisar dados no data warehouse, mas os serviços 
nesse conjunto nem sempre são úteis para operações de ETL. O Cloud SDK é usado para controlar serviços, 
mas por si só não é capaz de executar diretamente as operações necessárias. 
11. B. O Bigtable é projetado para aceitar bilhões de linhas de dados. Coletando dados de
100.000 sensores a cada 5 segundos gerarão 6.000.000 de pontos de dados a cada minuto ou 
8.640.000.000 pontos de dados por dia. A chave é um banco de dados relacional e suporta transações, mas elas não são necessárias. O Cloud SQL MySQL e o Cloud SQL PostgreSQL seriam 
difíceis de escalar para esse nível de desempenho de leitura e gravação. 
12. A. O Cloud Firestore é um serviço de banco de dados móvel que pode sincronizar dados entre dispositivos 
móveis e armazenamento centralizado. O Spanner é um banco de dados relacional global para 
aplicativos de grande escala que exigem suporte a transações em bancos de dados altamente dimensionados. O Datastore e o 
Cloud SQL podem ser usados, mas exigiriam mais desenvolvimento personalizado para sincronizar dados 
entre dispositivos móveis e o armazenamento de dados centralizado.
13. B. Uma aplicação computacionalmente intensiva requer, obviamente, CPUs altas, mas o fato de que 
existem muitos cálculos matemáticos indica que uma GPU deve ser usada. Você pode 
considerar executar isso em um cluster, mas o trabalho não é distribuído facilmente em vários servidores, portanto, você precisará ter um único servidor capaz de manipular a carga. O acesso imediato 
a grandes quantidades de dados indica que uma máquina de alta memória deve ser recomendada. 
14. B. Identidades são abstrações de usuários. Eles também podem representar características de processos 
que são executados em nome de um usuário humano ou de uma VM no GCP. As identidades não estão relacionadas a 
IDs de VMs. Funções são coleções de privilégios que podem ser concedidos a identidades. Opção D é 
sinônimo da opção C.
15. C. Cloud Natural Language Processing fornece funcionalidade para análise de texto. O Cloud 
Text Miner não existe. O Cloud ML é um serviço de aprendizado de máquina de propósito geral que 
poderia ser aplicado à análise de texto, mas exigiria conhecimento do processamento da linguagem, 
que o cliente não possui. O Cloud Vision é para processamento de imagens. 
16. B. Ambas as opções B e D atenderiam à necessidade de executar o Spark, o que daria aos 
cientistas de dados acesso à biblioteca de máquinas que eles precisam. No entanto, a opção D requer que eles 
gerenciem e monitorem o cluster de servidores, o que exigiria mais DevOps e trabalho de administração do que se eles usassem o serviço Dataproc. A opção C, BigQuery, é escalonável
banco de dados, não uma plataforma para executar o Spark. O Cloud Spark é um produto fictício e 
não existe no GCP. 
17. B. A opção B está correta. Spanner suporta transações SQL e globais padrão ANSI 2011. O Cloud SQL suporta o SQL padrão, mas não possui transação global. Datastore 
e Bigtable são bancos de dados NoSQL. 
468 Apêndice ■ Respostas às Questões de Revisão 
18. A. O Dataproc foi projetado para executar fluxos de trabalho nos modos batch e streaming, o que 
torna a opção A correta. O BigQuery é um serviço de data warehouse. O armazenamento de dados é um 
banco de dados de documentos . AutoML é um serviço de aprendizado de máquina. 
19. C. O ambiente padrão do App Engine fornece uma caixa de proteção Python sem servidor que dimensiona
automaticamente, então a opção C está correta. O ambiente flexível do App Engine executa contêineres e 
exige mais configuração. O Cloud Engine e o Kubernetes Engine exigem 
gerenciamento e monitoramento significativos . 
20. D. O relatório de erros consolida as informações de falha, o que faz com que o Relatório de erros seja a 
resposta correta . O monitoramento coleta métricas sobre o desempenho do aplicativo e do servidor. O log é um 
serviço de gerenciamento de log. O Dataproc não faz parte do Stackdriver; é um serviço gerenciado do Hadoop e do 
Spark. 
Capítulo 3: Projetos, contas de serviço 
e faturamento 
1. A. A opção A, a resposta correta, separa os dois principais aplicativos em suas próprias pastas e ainda permite separar o seguro privado do pagador do governo, mas usando
pastas para cada um. Isso satisfaz a necessidade regulatória de manter o software de pagamento do governo 
isolado de outro software. A opção B não inclui uma organização, que é a raiz 
da hierarquia de recursos. A opção C não é flexível no que diz respeito às diferenças nas restrições 
em diferentes aplicações. A opção D é falsa porque a opção A atende aos requisitos. 
2. C. As hierarquias de recursos possuem uma única organização na raiz, o que torna a opção C correta. Abaixo disso, existem pastas que podem conter outras pastas ou projetos. As pastas podem 
conter várias pastas e vários projetos. 
3. B. As contas de serviço são projetadas para permitir que aplicativos ou VMs executem tarefas.
As contas de faturamento são para associar cobranças a um método de pagamento. As pastas fazem parte das 
hierarquias de recursos e não têm nada a ver com a ativação de um aplicativo para executar uma tarefa. 
Contas de mensagens são uma opção fictícia. 
4. B. As políticas herdadas podem ser substituídas definindo uma política em um nível de pasta ou projeto. 
Contas de serviço e contas de faturamento não fazem parte da hierarquia de recursos e não estão 
envolvidas na substituição de políticas. 
5. E. Todos os tipos de restrições listados são suportados em políticas. 
6. B. Opção B é a resposta correta porque o Publisher não é um papel primitivo. Proprietário, editor 
e visualizador são os três privilégios primitivos do GCP.
7. D. Os papéis primitivos incluem apenas as permissões Proprietário, Editor e Visualização. As funções predefinidas 
são projetadas para produtos e serviços da GCP, como o App Engine e o BigQuery. Para um 
aplicativo personalizado , você pode criar conjuntos de privilégios que dão ao usuário essa função com a permissão necessária, mas não mais. 
Capítulo 3: Projetos, Contas de Serviço e Faturamento 479 
8. D. Os usuários devem ter apenas os privilégios necessários para realizar suas tarefas. Este é 
o princípio do menor privilégio. Rotação de funções é outro princípio de segurança relacionado a 
ter pessoas diferentes realizando uma tarefa em momentos diferentes. A defesa em profundidade é a prática 
de usar vários controles de segurança para proteger o mesmo ativo. A opção B não é uma segurança real
diretor. 
9. A. Uma hierarquia de recursos possui apenas uma organização, o que torna a opção A correta. Você 
pode, no entanto, criar várias pastas e projetos em uma hierarquia de recursos. 
10. B. Na opção B, a resposta correta, a conta de faturamento é usada para especificar informações de pagamento e deve ser usada para configurar pagamentos automáticos. As contas de serviço são usadas para 
conceder privilégios a uma VM e não estão relacionadas a faturamento e pagamentos. Contas de recursos 
e contas de crédito não existem. 
11. C. O GCP oferece um nível de serviço gratuito para muitos produtos, o que faz da opção C a 
resposta correta . Você pode usar esses serviços sem ter que configurar uma conta de faturamento. O Google 
cobra pelos produtos sem servidor, como o Cloud Functions e o App Engine, quando os clientes
exceder o valor permitido no nível gratuito. 
12. D. As áreas de trabalho do Stackdriver estão vinculadas a projetos, não a recursos individuais, como 
instâncias de VM , clusters ou aplicativos do App Engine, portanto, a opção D está correta. As opções A, B e C 
indicam incorretamente que os espaços de trabalho estão associados a recursos de computação individuais. 
13. D. As grandes empresas devem usar o faturamento ao incorrer em grandes encargos, o que torna a 
opção D a resposta correta. Uma conta de autoatendimento é apropriada apenas para valores que estão 
dentro dos limites de crédito dos cartões de crédito. Como as subdivisões são gerenciadas independentemente 
e têm seus próprios orçamentos, cada uma deve ter suas próprias contas de faturamento. 
14. A. Quando um usuário é concedido iam.serviceAccountUser no nível do projeto, esse usuário pode
gerenciar todas as contas de serviço no projeto, portanto, a opção A está correta. Se uma nova conta de serviço 
for criada, eles automaticamente terão privilégios para gerenciar essa conta de serviço. Você 
pode conceder iam.serviceAccountUser ao administrador no nível da conta de serviço, 
mas isso exigiria a configuração da função para todas as contas de serviço. Se uma nova conta de serviço for 
criada, o administrador do aplicativo terá que conceder iam.serviceAccountUser ao 
outro administrador na nova conta de serviço. iam.serviceProjectAccountUser é 
uma função fictícia. 
15. C. Quando uma conta de serviço é criada, o Google gera chaves criptografadas para autenticação, 
tornando a opção C correta. Nomes de usuários e senhas não são uma opção para contas de serviço.
A autenticação de dois fatores é uma prática de autenticação que exige duas formas de autenticação, como um par de senhas de nome de usuário e um código de um dispositivo de autenticação. A biometria não pode ser usada por serviços e não é uma opção. 
16. B. Contas de serviço são recursos que são gerenciados por administradores, mas também funcionam como identidades que podem ser atribuídas a funções, o que torna a opção B a resposta correta. 
As contas de faturamento não estão relacionadas a identidades. Projetos não são identidades; eles não podem assumir 
papéis. Funções são recursos, mas não identidades. Eles podem assumir privilégios, mas esses privilégios são usados ​​somente quando estão ligados a uma identidade. 
470 Apêndice ■ Respostas às perguntas de revisão
17. B. Funções predefinidas são definidas para um produto específico, como o App Services ou o Compute 
Engine, portanto, a opção B é a resposta correta. Agrupam privilégios geralmente necessários juntos ao 
gerenciar ou usar um serviço. Os papéis primitivos são blocos de construção para outros papéis. 
Funções personalizadas são criadas pelos usuários para atender às suas necessidades específicas; As funções de aplicativos são um papel fictício. 
18. B. Por padrão, todos os usuários em uma organização podem criar projetos, o que torna a opção B correta. A função resourcemanager.projects.create é a função que permite aos usuários criar 
projetos. A conta de faturamento não está associada à criação de projetos. 
19. D. O número máximo de organizações é determinado por cada conta por
Google, então a opção D é a resposta correta. Se você precisar de outras organizações, 
entre em contato com o Google e solicite um aumento no seu limite. 
20. B. Usuários com a função IAM da Organização não são necessariamente responsáveis ​​por determinar 
quais privilégios devem ser atribuídos aos usuários. Isso é determinado com base no papel da pessoa 
na organização e nas políticas de segurança estabelecidas dentro da organização, o que 
torna a opção B correta. 
Capítulo 4: Introdução à computação no 
Google Cloud 
1. B. O ambiente padrão do App Engine pode executar aplicativos Python, que podem ser dimensionados automaticamente 
para nenhuma instância quando não há carga e, portanto, minimizam os custos. Compute Engine
e o ambiente flexível do App Engine exige mais gerenciamento de configuração do que 
o ambiente padrão do App Engine. O Kubernetes Engine é usado quando um cluster de servidores é 
necessário para suportar aplicativos grandes ou múltiplos usando os mesmos recursos de computação. 
2. A. Servidores de banco de dados exigem alta disponibilidade para responder a consultas de usuários ou aplicativos. As máquinas preemptivas têm garantia de desligar em no máximo 24 horas. Um 
trabalho de processamento em lote sem requisitos de tempo fixo pode usar máquinas preemptivas contanto que 
a VM seja reiniciada. Clusters de computação de alto desempenho podem usar máquinas preemptivas 
porque o trabalho em uma máquina preemptiva pode ser reprogramada automaticamente para outro nó
no cluster quando um servidor é preterido. D está incorreto porque há uma resposta correta no 
conjunto de opções. 
3. A. As VMs são criadas em projetos, que fazem parte da hierarquia de recursos. Eles também estão 
localizados em regiões geográficas e centros de dados, portanto, uma zona também é especificada. Nomes de usuário 
e funções administrativas não são especificados durante a criação. A conta de faturamento está vinculada a um projeto 
e, portanto, não precisa ser especificada quando a VM é criada. Os intervalos de armazenamento em nuvem são 
criados independentemente das VMs. Nem todas as VMs farão uso de intervalos de armazenamento. 
4. C. O Compute Engine pode executar contêineres do Docker se você instalar o Docker na VM. 
O Kubernetes e o ambiente flexível do App Engine oferecem suporte a contêineres do Docker. A aplicação
O ambiente padrão do mecanismo fornece ambientes de tempo de execução específicos do idioma e 
não permite que os clientes especifiquem imagens do Docker personalizadas para uso. 
Capítulo 4: Introdução à computação no Google Cloud 471 
5. B. O nome do arquivo usado para criar e configurar um contêiner do Docker é o Dockerfile. 
6. D. Kubernetes usa 25 por cento de memória de até 4GB e, em seguida, um pouco menos para os próximos 
4GB, e continua a reduzir a porcentagem de memória adicional para 2 por cento de 
memória em 128GB. 
7. O B. Kubernetes fornece balanceamento de carga, escalonamento e atualização automática de software. 
Não fornece varredura de vulnerabilidade. O GCP tem um Cloud Security Scanner
produto, mas que é projetado para funcionar com o Google App Engine para identificar 
vulnerabilidades de aplicativos comuns . 
8. D. O cenário descrito é um bom ajuste para o Kubernetes. Cada um dos grupos de serviços pode 
ser estruturado em pods e implantado usando a implantação do Kubernetes. O Kubernetes Engine 
gerencia a integridade do nó, o balanceamento de carga e o dimensionamento. O App Engine Standard Edition tem 
sandboxes específicas de idioma e não é adequado para esse caso de uso. O Cloud Functions é 
projetado para processamento de eventos de curta execução e não é o tipo de processamento contínuo 
necessário neste cenário. O Compute Engine pode atender aos requisitos deste caso de uso, 
mas exigiria mais esforço por parte dos administradores de aplicativos e do DevOps
profissionais para configurar balanceadores de carga, monitorar a integridade e gerenciar 
implantações de software . 
9. B. Este é um caso de uso ideal para Funções em nuvem. A função de nuvem é acionada por um 
evento de upload de arquivo . A função de nuvem chama o serviço de processamento de imagem. Com essa configuração, os 
dois serviços são independentes. Nenhum servidor adicional é necessário. A opção A viola a 
exigência de manter os serviços independentes. As opções C e D incorrem em mais 
sobrecarga de gerenciamento e provavelmente custarão mais para operar do que a opção B. 
10. D. Cada chamada de uma função de nuvem é executada em um ambiente de tempo de execução seguro e isolado. 
Não há necessidade de verificar se outras invocações estão em execução. Com as funções de nuvem
serviço, não há como um desenvolvedor controlar a execução de código no processo ou no 
nível do encadeamento . 
11. A. Você criaria uma imagem personalizada depois de instalar o código customizado, neste caso a 
biblioteca de criptografia. Uma imagem pública não contém código personalizado, mas pode ser usada como 
a base na qual você adiciona código personalizado. Tanto o CentOS quanto o Ubuntu são distribuições Linux. 
Você pode usar a imagem base à qual adiciona o código personalizado, mas por conta própria, eles 
não têm código personalizado. 
12. B. Projetos são o nível mais baixo da hierarquia de recursos. A organização está no topo da 
hierarquia e as pastas estão entre a organização e os projetos. As instâncias de VM não fazem 
parte da hierarquia de recursos.
13. D. Todas as regiões do Google têm o mesmo nível de acordo de nível de serviço, portanto, a confiabilidade é a 
mesma. Os custos podem diferir entre regiões. As regulamentações podem exigir que os dados permaneçam dentro de uma 
área geográfica, como a União Européia. A latência é uma consideração quando você deseja uma 
região próxima aos usuários finais ou os dados de que você precisa já estão armazenados em uma determinada região. 
14. B. A função de administração do Compute Engine é a função que fornece aos usuários controle total sobre as instâncias. 
As opções A e C são funções fictícias. O Administrador de segurança do Compute Engine oferece aos usuários os privilégios para criar, modificar e excluir certificados SSL e regras de firewall. 
472 Apêndice ■ Respostas às perguntas de revisão
15. D. VMs preemptivas serão encerradas após 24 horas. O Google não garante que as 
VMs preemptivas estarão disponíveis. Depois que uma instância é iniciada como uma máquina preemptiva, ela 
não pode migrar para uma VM comum. Você poderia, no entanto, salvar um instantâneo e usá-lo para criar 
uma nova instância regular. 
16. C. As VMs personalizadas podem ter até 64 CPUs e até 6,5 GB de memória por vCPU. 
17. C. A linguagem de programação C não é suportada no ambiente padrão do App Engine. Se você precisar executar um aplicativo C, ele poderá ser compilado e executado em um contêiner 
em execução no ambiente flexível do App Engine. 
18. B. Kubernetes reserva a capacidade da CPU de acordo com o seguinte cronograma: 
1. 6% do primeiro núcleo
2. 1% do núcleo seguinte (até dois núcleos) 
3. 0.5% dos próximos dois núcleos (até quatro núcleos) 
4. 0.25% de quaisquer núcleos acima de quatro núcleos 
19. B. Os únicos estados que uma implementação do Kubernetes pode estar em estão progredindo, concluído e 
falhou. 
20. A. Cloud Functions é mais adequado para processamento orientado a eventos, como um arquivo sendo 
enviado para o Cloud Storage ou um evento sendo gravado em uma fila Pub / Sub. Tarefas de longa duração 
, como o carregamento de dados em um data warehouse, são mais adequadas para o Compute Engine ou o 
App Engine. 
Capítulo 5: Computação com 
máquinas virtuais do Compute Engine 
1. C. Você deve verificar o projeto selecionado, pois todas as operações executadas serão aplicadas
aos recursos no projeto selecionado, tornando a opção C a resposta correta. Você não precisa 
abrir o Cloud Shell, a menos que queira trabalhar com a linha de comando e, se o fez, 
verifique se o projeto foi selecionado corretamente primeiro. Fazer login em uma VM usando o SSH é uma 
das tarefas que exige que você trabalhe com o projeto correto, portanto, o login via SSH 
não deve acontecer antes de verificar o projeto. A lista de VMs na janela Instância de VM é uma lista de VMs no projeto atual. Você deve verificar qual projeto está usando para 
garantir que esteja visualizando o conjunto de VMs que acha que está usando.
2. A. Você precisará configurar o faturamento se ele ainda não estiver ativado quando você começar a usar o console, portanto, a opção A é a resposta correta. Você pode criar um projeto, mas será capaz de fazer 
isso apenas se o faturamento estiver ativado. Você não precisa criar um depósito para trabalhar com o 
console. A especificação de uma zona padrão não é uma tarefa única; você pode mudar de 
zona ao longo da vida do seu projeto. 
Capítulo 5: Computing com Compute Engine máquinas virtuais 473 
3. B. O nome da VM, a região e zona e o tipo de máquina podem ser especificadas 
no console juntamente com outros parâmetros, então a opção B está correta. Opção A está faltando 
parâmetros necessários. Um bloco CIDR é um intervalo de endereços IP associado a um
sub-rede e não é necessário criar uma VM. Um endereço IP é atribuído automaticamente, portanto, não é 
necessário. 
4. B. Zonas diferentes podem ter diferentes tipos de máquinas disponíveis, então você precisará especificar uma 
região primeiro e depois uma zona para determinar o conjunto de tipos de máquinas disponíveis. Se o 
tipo de máquina não aparecer na lista, ela não estará disponível nessa zona. Isso faz da opção B a 
resposta correta. As opções A e C estão incorretas. Sub-redes e endereços IP não estão relacionados 
aos tipos de máquinas disponíveis. A menos que você esteja especificando um tipo de máquina personalizado, 
não especifica a quantidade de memória; que é definido pelo tipo de máquina, então a opção D 
está incorreta.
5. C. As etiquetas e descrições servem para nos ajudar a rastrear nossos próprios atributos de recursos; O GCP 
não precisa deles para executar suas tarefas. À medida que o número de servidores aumenta, pode ser 
difícil controlar quais VMs são usadas para quais aplicativos e serviços, portanto, a opção C é 
a resposta correta. Os rótulos e uma descrição geral ajudarão os administradores a rastrear os números 
de VMs e seus custos relacionados. As opções A e B são usadas para segurança e armazenamento, mas 
não ajudam no gerenciamento de várias VMs. A opção D está apenas parcialmente correta. As descrições são 
úteis, mas os rótulos também são úteis. 
6. A. A seção Política de Disponibilidade na guia Gerenciamento é onde você define a preempção, portanto, a opção A está correta. Identity e API Access é usado para controlar o acesso da VM a
Google Cloud APIs e qual conta de serviço é usada com a VM. A locação exclusiva é usada 
se você precisar executar suas VMs em servidores físicos que só executam suas VMs. A rede é 
usada para definir tags de rede e alterar a interface de rede. 
7. B. Shield VM é um conjunto avançado de controles de segurança que inclui o Monitoramento de Integridade, uma 
verificação para garantir que as imagens de inicialização não tenham sido adulteradas, o que torna a opção B a 
resposta correta . Os firewalls são usados ​​para controlar a entrada e a saída do tráfego de rede para um servidor ou 
sub-rede. As chaves SSH em todo o projeto são usadas para autenticar usuários entre servidores dentro de um projeto. A verificação de integridade do disco de inicialização é um recurso fictício. 
8. C. O tamanho do bloco não é uma opção na caixa de diálogo Discos Adicionais, portanto, a opção C está correta.
O gerenciamento de chave de criptografia, o tipo de disco e a opção de especificar uma imagem de origem são todas 
as opções disponíveis. 
9. B. Usar scripts controlados por versão é a melhor abordagem das quatro opções. Os scripts podem 
ser documentados com motivos para as alterações e podem ser executados repetidamente em 
máquinas diferentes para implementar a mesma alteração. Isso reduz a chance de erro ao 
inserir manualmente um comando. A opção A não ajuda a melhorar a documentação de porque as alterações foram 
feitas. A opção C pode ajudar a melhorar a documentação, mas os scripts executáveis ​​são 
reflexos precisos e precisos do que foi executado. Notas podem perder detalhes. Opção D não é aconselhável. Você pode se tornar um gargalo para fazer alterações, alterações não podem ser feitas quando
você não está disponível e sua memória pode não ser uma maneira confiável de rastrear todas as 
alterações de configuração . 
474 Apêndice ■ Respostas às perguntas de revisão 
10. A. gcloud compute instances é o início dos comandos para administrar os 
recursos do Compute Engine, tornando a opção A a resposta correta. A opção B, gcloud instances, não possui 
a palavra-chave compute que indica que estamos trabalhando com o Compute Engine. A opção 
C mudou a ordem de computação e instâncias. A opção D é falsa porque a opção A é 
a resposta correta. 
11. B. A opção B segue o padrão do comando glcoud, que é hierárquico e começa 
com o nome glcoud do serviço, neste caso, compute para o Compute Engine, seguido por
o próximo nível abaixo, que neste caso é instâncias. Finalmente, há a ação ou verbo, 
nesta lista de casos. A opção A está sem o termo instâncias para indicar que você está trabalhando com 
instâncias de VM. A opção C está sem a palavra-chave compute para indicar que você está trabalhando com o 
Compute Engine. A opção D está sem a palavra-chave da instância de computação e mudou 
a ordem das instâncias e da lista. 
12. B. O formato correto é usar o parâmetro --labels e especificar a chave seguida por 
um sinal de igual seguido pelo valor na opção B. As opções A e C têm o caracter errado, 
separando a chave e o valor. A opção D está incorreta porque é possível especificar rótulos na 
linha de comando.
13. C. As duas operações que você pode especificar ao usar a configuração do disco de livro estão adicionando 
um novo disco e anexando um disco existente, então a opção C está correta. Reformatar um 
disco existente não é uma opção, portanto, as opções A, B e D não podem ser a resposta correta. 
14. B. 10 GB de dados são pequenos o suficiente para serem armazenados em um único disco. Ao criar uma imagem de um disco 
com os dados armazenados, você pode especificar essa imagem de origem ao criar uma VM. 
A opção A exigiria que o cientista de dados copiasse os dados do Cloud Storage para um disco na 
VM. A opção C exigiria, da mesma forma, a cópia dos dados. A opção D carregaria dados em um 
banco de dados, não em um sistema de arquivos, conforme especificado nos requisitos.
15. B. Na guia Rede do formulário de VM, você pode adicionar outra interface de rede, portanto, a 
opção B está correta. O GCP define o endereço IP, portanto, a opção A está incorreta. Não há opção 
para especificar um roteador ou alterar regras de firewall na guia Rede, portanto, as opções C e D estão 
incorretas. 
16. A. A opção correta é boot-disk-type, que é a opção A. As outras três opções 
não são parâmetros para o comando gcloud compute instances. 
17. A. Opção A é o comando correto. É a única opção que inclui um 
tipo de máquina correto e especifica corretamente o nome da instância. A opção B usa o parâmetro --cpus, 
que não existe. A opção C usa o parâmetro instance-name, que não existe.
O nome da instância é passado como um argumento e não precisa de um nome de parâmetro. A opção 
D está incorreta porque o tipo de máquina n1-4-cpu não é um tipo de máquina válido. 
18. C. Opção C é o comando correto, que é gcloud compute instances, para indicar que 
você está trabalhando com VMs, seguido pelo comando stop e pelo nome da VM. 
A opção A está incorreta porque a parada não é uma opção. A opção B está incorreta porque 
–terminate não é um parâmetro. Opção D está faltando a palavra instâncias, o que 
indica que você está trabalhando com VMs. 
Capítulo 6: Gerenciamento de máquinas virtuais 475 
19. B. O SSH é um serviço para conexão a um servidor remoto e login em uma janela de terminal.
Uma vez logado, você teria acesso a uma linha de comando, então a opção B é a resposta correta. 
O FTP é um protocolo de transferência de arquivos e não permite efetuar login e executar tarefas de administração do sistema. O RDP é um protocolo usado para acessar remotamente os servidores Windows, não o Ubuntu, 
que é uma distribuição do Linux. ipconfig é um utilitário de linha de comando para configurar pilhas de IP 
em um dispositivo e não permite que você faça login em um servidor remoto. 
20. A. Todas as declarações da opção A são verdadeiras e relevantes para faturamento e custos. A opção B 
está correta de que as VMs são cobradas em incrementos de 1 segundo, mas as únicas VMs preemptivas são 
encerradas em até 24 horas após o início. A opção C está incorreta porque os descontos não são
limitado a algumas regiões. A opção D está incorreta porque as VMs não são cobradas por no mínimo 
1 hora. 
Capítulo 6: Gerenciando máquinas virtuais 
1. A. A página do Compute Engine é onde você tem a opção de criar uma única 
instância de VM , portanto, a opção A é a resposta correta. O App Engine é usado para contêineres e 
aplicativos em execução em ambientes de tempo de execução específicos do idioma. O Kubernetes Engine é usado para criar 
e gerenciar clusters do Kubernetes. Cloud Functions é onde você cria uma função para ser 
executada no ambiente de função de nuvem sem servidor do Google. 
2. B. As instâncias podem ser interrompidas e, quando estão, você não pode se conectar a elas via SSH, o 
que torna a opção B a resposta correta. Iniciar a instância ativará o acesso SSH.
A opção A não está correta porque você pode fazer login em máquinas preemptivas. A opção C está incorreta porque não há nenhuma opção SSH. A opção D está incorreta porque a opção SSH pode 
ser desativada. 
3. B. O comando Reset pode ser usado para reiniciar uma VM; assim, a opção B está correta. As propriedades da VM não serão alteradas, mas os dados na memória serão perdidos. Não há opção Reiniciar, 
Reiniciar, Desligar ou Inicializar no console. 
4. Os rótulos, os membros de um grupo de instâncias gerenciadas e o status estão todos disponíveis para filtragem, 
portanto , a opção C é a resposta correta. Você também pode filtrar por IP interno, IP externo, zona, rede, proteção de exclusão e membro de um grupo de instâncias gerenciado ou não gerenciado.
5. A. Para funcionar corretamente, o sistema operacional deve ter bibliotecas de GPU instaladas, portanto, a opção 
A está correta. O sistema operacional não precisa ser baseado no Ubuntu, e não há necessidade 
de ter pelo menos oito CPUs em uma instância antes que você possa anexar e usar uma GPU. O 
espaço em disco disponível não determina se uma GPU é usada ou não. 
6. A. Se você adicionar uma GPU a uma VM, deverá definir a instância para ser finalizada durante a manutenção, o 
que torna a opção A a resposta correta. Isso é definido na seção Políticas de disponibilidade do 
formulário de configuração da VM. A instância não precisa ser preemptiva e pode ter 
discos de inicialização não conectados. A instância não é necessária para executar o Ubuntu 14.02 ou posterior. 
476 Apêndice ■ Respostas às perguntas de revisão
7. B. Quando você cria um snapshot pela primeira vez, o GCP fará uma cópia completa dos dados no disco permanente. Na próxima vez que você criar um snapshot a partir desse disco, o GCP copiará somente os dados 
que foram alterados desde o último snapshot. Opção A está incorreta; O GCP não armazena uma 
cópia completa do segundo instantâneo. A opção C está incorreta; o primeiro instantâneo não é excluído automaticamente. A opção D está incorreta, os instantâneos subseqüentes não incorrem em sobrecarga de 10%. 
8. D. Para trabalhar com instantâneos, um usuário deve receber a função Administrador de Armazenamento de Cálculo, o 
que torna a opção D a resposta correta. As outras opções são funções fictícias. 
9. C. As imagens podem ser criadas a partir de quatro fontes, ou seja, discos, instantâneos, arquivos de armazenamento em nuvem,
ou outra imagem, então a opção C é a resposta correta. Arquivos de exportação de banco de dados não são fontes para 
imagens. 
10. B. Deprecated marca a imagem como não mais suportada e permite que você especifique uma imagem substituta a ser usada no futuro, tornando a opção B a resposta correta. Imagens obsoletas 
estão disponíveis para uso, mas não podem ser corrigidas por falhas de segurança ou ter outras atualizações. As 
outras opções são recursos fictícios de imagens. 
11. C. O comando base para trabalhar com instâncias é gcloud compute instances, o 
que faz da opção C a resposta correta. O comando list é usado para mostrar detalhes 
de todas as instâncias. Por padrão, a saída está em formato legível, e não json. Usando o
A opção --format json força a saída a estar no formato JSON. --output não é uma 
opção válida. 
12. B. - Async faz com que as informações sobre o processo de início sejam exibidas; portanto, a opção B 
está correta. --verbose é um parâmetro análogo em muitos comandos do Linux. --describe 
fornece detalhes sobre uma instância, mas não necessariamente o processo de inicialização. --details não é 
um parâmetro válido. 
13. C. O comando para excluir uma instância é gcloud compute instances delete seguido 
pelo nome da instância, portanto, a opção C está correta. A opção A está incorreta porque não há 
nenhum parâmetro de instância. A opção B está incorreta porque esse comando pára, mas não
exclua a instância. A opção D está faltando instâncias no comando, que é necessário para 
indicar que tipo de entidade está sendo excluído. 
14. A. gcloud compute instances é o comando base seguido por delete, o nome da 
instância e --keep-disks = boot, assim a opção A está correta. Não há 
parâmetro --save-disk . A opção C está errada porque o sistema de arquivos não é um valor válido para o 
parâmetro keep-disk . Opção D está faltando a opção de instâncias que é necessária no comando. 
15. B. A resposta correta é a opção B, que é usar o comando describe. A opção A 
mostrará alguns campos, mas não todos. As opções C e D estão incorretas porque não há nenhum 
parâmetro detalhado .
16. B. Os grupos de instâncias são conjuntos de VMs que podem ser configurados para escalar e são usados ​​com 
balanceadores de carga , o que contribui para melhorar a disponibilidade, portanto, a opção B está correta. As 
instâncias preemptivas não são altamente disponíveis porque podem ser encerradas a qualquer momento pelo GCP. 
O Cloud Storage não é um componente do Compute Engine. As GPUs podem ajudar a melhorar a taxa de transferência para 
operações intensivas em matemática, mas não contribuem para a alta disponibilidade. 
Capítulo 7: Computando com o Kubernetes 477 
17. B. Um modelo de grupo de instâncias é usado para especificar como o grupo de instâncias deve ser criado, o 
que torna a opção B a resposta correta. A opção A está incorreta porque as instâncias são criadas automaticamente quando um grupo de instâncias é criado. Imagens de disco de inicialização e instantâneos
não precisa ser criado antes de criar um grupo de instâncias. 
18. B. O comando para excluir um grupo de instâncias é gcloud compute instance-template 
delete, portanto, a opção B está correta. Opção A incorretamente inclui o termo instâncias. Opção 
C está em ordem incorreta. A opção D está errada porque o modelo de instância está na 
posição errada e é plural na opção. 
19. C. Você pode configurar uma política de escalonamento automático para acionar a adição ou remoção de instâncias com base 
na utilização da CPU, métrica de monitoramento, capacidade de balanceamento de carga ou cargas de trabalho baseadas em filas. 
O disco, a latência de rede e a memória podem acionar o dimensionamento se as métricas de monitoramento nesses 
recursos estiverem configuradas. Então, a opção C está correta.
20. B. Grupos de instâncias não gerenciadas estão disponíveis para casos de uso limitado como este. 
Grupos de instâncias não gerenciadas não são recomendados em geral. Grupos de instâncias gerenciadas são a maneira recomendada de usar grupos de instâncias, mas as duas configurações diferentes impedem seu uso. 
Instâncias preemptivas e GPUs não são relevantes para este cenário. 
Capítulo 7: Computação com o Kubernetes 
1. O C. Kubernetes cria grupos de instâncias como parte do processo de criação de um cluster, o que 
torna a opção C a resposta correta. O Stackdriver, e não grupos de instâncias, é usado para monitorar a 
integridade dos nós e para criar alertas e notificações. O Kubernetes cria pods e implementações; eles não são fornecidos por grupos de instâncias.
2. A. Um cluster do Kubernetes possui um único cluster mestre e um ou mais nós para executar cargas de trabalho, portanto, a opção A é a resposta correta. O Stackdriver não faz parte do cluster do Kubernetes; 
é um serviço separado do GCP. O Kubernetes não requer instâncias com pelo menos quatro vCPUs; 
Na verdade, a configuração do nó padrão usa uma vCPU. 
3. C. Pods são instâncias únicas de um processo em execução em um cluster, portanto, a opção C está correta. Os pods 
executam contêineres, mas não são conjuntos de contêineres. O código do aplicativo é executado em contêineres 
implantados em pods. Os pods não são controladores, portanto, não podem gerenciar a comunicação com 
clientes e serviços do Kubernetes. 
4. B. Serviços são aplicativos que fornecem pontos de extremidade da API que permitem que os aplicativos descubram
pods executando uma aplicação específica, tornando a opção B correta. As opções A e C, se 
pudessem ser codificadas usando a API projetada para gerenciar clusters, exigiriam mais código do 
que trabalhar com serviços e estão sujeitas a alterações em um conjunto maior de funções da API. 
A opção D não é uma opção real. 
478 APÊNDICE ■ Respostas às questões de revisão 
5. C. ReplicaSets são controladores que são responsáveis por manter o número correto de 
vagens, o que torna a opção C a resposta correta. Implantações são versões do 
código do aplicativo em execução em um cluster. O Stackdriver é um serviço de monitoramento e registro que monitora, mas 
não controla, os clusters do Kubernetes. Jobs é uma abstração de cargas de trabalho e não está vinculada a
o número de pods em execução em um cluster. 
6. B. Os clusters multizonas / multirregionais estão disponíveis no Kubernetes Engine e são usados ​​para fornecer resiliência a um aplicativo, portanto, a opção B está correta. A opção A refere-se a grupos de instâncias 
que são um recurso do Compute Engine, e não diretamente do Kubernetes Engine. A opção C está incorreta; Implementações regionais é um termo fictício. O balanceamento de carga distribui a carga e faz parte do 
Kubernetes por padrão. Se a carga não for distribuída entre zonas ou regiões, não ajudará a 
adicionar resiliência nos datacenters. 
7. A. A opção A é a melhor resposta. Começar com um modelo existente, preencher parâmetros 
e gerar o comando gcloud é a maneira mais confiável. A opção D pode funcionar, mas
vários parâmetros que são necessários para sua configuração podem não estar no script com o qual você 
começou. Pode haver alguma tentativa e erro com essa opção. As opções B e C podem levar 
a uma solução, mas podem levar algum tempo para serem concluídas. 
8. A. O comando correto é a opção A. A opção B tem beta na posição errada. Opção C 
está faltando beta. A opção D está sem o nome do parâmetro --num-nodes. 
9. C. Time to Live não é um atributo de implantações, então a opção C é a resposta correta. 
O nome do aplicativo, a imagem do container e o comando inicial podem ser especificados. 
10. B. Os arquivos de configuração de implantação criados no Cloud Console são salvos no formato YAML. 
CSV, TSV e JSON não são usados.
11. C. O comando kubectl é usado para controlar as cargas de trabalho em um cluster do Kubernetes depois que ele é 
criado, portanto, a opção C está correta. As opções A e B estão incorretas porque o gcloud não é usado 
para manipular processos do Kubernetes. A opção D está errada porque o beta não é necessário nos 
comandos do kubectl. 
12. C. A opção C é o comando correto. Opção A usa o termo atualização em vez de escala. 
A opção B usa incorretamente o gcloud. A opção D usa os pods de parâmetro incorretos. 
13. O D. Stackdriver é um serviço abrangente de monitoramento, registro, alerta e notificação 
que pode ser usado para monitorar clusters do Kubernetes. 
14. B. Espaços de trabalho são estruturas lógicas para armazenar informações sobre recursos em um projeto
que estão sendo monitorados, então a opção B está correta. O Stackdriver funciona com registros, mas 
não é necessário um registro antes de começar a usar o Stackdriver. Pods e ReplicaSets são parte do Kubernetes, não do Stackdriver. 
15. C. A página Detalhes da Instância do Stackdriver inclui gráficos de série temporal sobre o uso da CPU, 
tráfego de rede e E / S de disco. 
16. B. Ao criar uma política de alerta, você pode especificar condições, notificações e documentação, tornando a opção B a resposta correta. As opções A e D estão incorretas porque não há 
nenhum atributo Tempo de vida nas políticas. A opção C está errada porque não inclui notificações e documentação. 
Capítulo 8: Gerenciando o Kubernetes Clusters 479 
17. A. Alertas podem ter múltiplos canais, então a Opção A está correta. Canais incluem email,
webhooks e mensagens de texto SMS, bem como ferramentas de terceiros, como PagerDuty, 
Campfire e Slack. Não há necessidade de vários alertas com notificações individuais. 
A opção C é ad hoc e exigiria uma sobrecarga de manutenção adicional. A opção D não 
atende aos requisitos. 
18. B. Alertas são atribuídos a instâncias ou conjuntos de instâncias; portanto, a opção B está correta. 
A opção A está incorreta porque não inclui grupos. A opção C está incorreta porque 
não inclui instâncias. A opção D está errada porque os alertas não são atribuídos a pods. 
19. A. Todas as interações com o cluster são feitas através do mestre usando a API do Kubernetes. 
Se uma ação deve ser executada em um nó, o comando é emitido pelo mestre do cluster, portanto, opção
"A" é a resposta correta As opções B e D estão incorretas porque são controladores no 
cluster e não afetam o modo como os comandos são recebidos dos dispositivos clientes. A opção C está 
incorreta porque o kubectl, e não o gcloud, é usado para iniciar as implantações. 
20. A. Os serviços fornecem um nível de indireção para acessar os pods. Vagens são efêmeras. Os clientes se 
conectam aos serviços, que podem descobrir os pods. ReplicaSets e StatefulSets fornecem 
pods gerenciados . Os alertas são para relatar o estado dos recursos. 
Capítulo 8: Gerenciando 
clusters do Kubernetes 
1. B. Quando estiver nas páginas do Cloud Console, você pode clicar no nome do cluster para ver uma página Detalhes, 
então a opção B é a resposta correta. Digitar o nome do cluster na barra de pesquisa não
sempre retornar detalhes do cluster; ele pode retornar detalhes do grupo de instâncias. Não existe tal comando como detalhes do cluster do gcloud. 
2. D. Você pode encontrar o número de vCPUs na listagem de clusters na coluna Total Cores ou na 
página Detalhes na seção Conjunto de Nós no parâmetro tamanho, tornando a opção D correta. 
A seção Labels não possui informações de vCPU. 
3. B. O comando correto inclui o contêiner gcloud para descrever o serviço, clusters para 
indicar o recurso ao qual você está se referindo e lista para indicar o comando, o que torna a 
opção B a resposta correta. Opções A e C não são comandos válidos. 
4. B. É provável que você não tenha privilégios de acesso ao cluster. O contêiner gdcloud
O comando get-credentials de clusters é o comando correto para configurar o kubectl para 
usar as credenciais do GCP para o cluster, portanto, a opção B é a opção correta. Opções A, C e D são 
comandos inválidos. 
5. C. Clicar no botão Editar permite alterar, adicionar ou remover rótulos, portanto, a opção C é a 
resposta correta. O botão Conectar está na página de listagem de cluster e o botão Implantar 
é para criar novas implantações. Não há como inserir rótulos na seção "Marcadores" 
ao exibir detalhes. 
480 APÊNDICE ■ Respostas às questões de revisão 
6. D. Ao redimensionar, os clusters recipiente gcloud redimensionar comando requer o nome 
do cluster e da piscina nó para modificar. O tamanho é necessário para especificar quantos nós
deve estar em execução. Portanto, a opção D está correta. 
7. B. Pods são usados ​​para implementar réplicas de uma implementação. É uma prática recomendada modificar 
as implantações, que são configuradas com uma especificação do número de réplicas que 
devem sempre ser executadas, portanto, a opção B é a resposta correta. Opção A está incorreta; você não deve 
modificar os pods diretamente. As opções C e D estão incorretas porque não alteram o número de pods executando um aplicativo. 
8. C. As implantações são listadas em Cargas de trabalho, fazendo da opção C a resposta correta. A 
opção Cluster mostra detalhes sobre clusters, mas não possui detalhes sobre implantações. O armazenamento mostra informações sobre volumes persistentes e classes de armazenamento. Implantações não é uma 
opção.
9. B. Há quatro ações disponíveis para implantações (Autoscale, Expose, Rolling Update 
e Scale), portanto, a opção B está correta. Adicionar, Modificar e Excluir não são opções. 
10. Como as implantações são gerenciadas pelo Kubernetes e não pelo GCP, precisamos usar um 
comando kubectl e não um comando gcloud, o que torna a opção C correta. A opção D está 
incorreta porque segue a estrutura do comando gcloud, não a 
estrutura de comando do kubectl . O comando kubectl tem o verbo, como get, antes do tipo de recurso, como 
implementações, por exemplo. 
11. D. Você pode especificar a imagem do container, o nome do cluster e o nome do aplicativo junto com os 
rótulos, o comando inicial e o namespace; Portanto, a opção D é a resposta correta.
12. A. A página Detalhes da Implantação inclui serviços, portanto, a opção A é a resposta correta. Contêineres são usados ​​para implementar serviços; detalhes do serviço não estão disponíveis lá. A 
página Detalhes do Cluster não contém informações sobre serviços em execução no cluster. 
13. A. kubectl run é o comando usado para iniciar uma implementação. Leva um nome para a 
implantação, uma imagem e uma especificação de porta. As outras opções não são 
comandos válidos do kubectl . 
14. A. A opção A mostra o comando correto, que é kubectl delete service mlclassifier-3. A opção B está sem o termo de serviço. As opções C e D não podem estar corretas 
porque os serviços são gerenciados pelo Kubernetes, não pelo GCP. 
15. C. O Container Registry é o serviço para gerenciar imagens que podem ser usadas em outros
serviços, incluindo o Kubernetes Engine e o Compute Engine, tornando a opção C correta. O 
Compute Engine e o Kubernetes Engine usam imagens, mas não os gerenciam. Não há 
serviço chamado Container Engine. 
16. A. As imagens são gerenciadas pelo GCP, então o comando correto será um comando gcloud, 
então a opção A é a resposta correta. A opção B está incorreta porque o verbo é colocado antes 
do recurso. As opções C e D estão incorretas porque o kubectl é para gerenciar 
recursos do Kubernetes , não recursos do GCP, como imagens de contêiner. 
Capítulo 9: Computação com o Google App 481 
17. B. O comando correto é gcloud container images describe, o que torna a opção
B a resposta certa. describe é o verbo gcloud ou operação para mostrar os detalhes de um 
objeto. Todas as outras opções são comandos inválidos. 
18. B. O comando kubectl expor deployment torna um serviço acessível, então a opção B é 
a resposta correta. Endereços IP são atribuídos a VMs, não a serviços. O comando gcloud 
não gerencia os serviços do Kubernetes, portanto, a opção C está incorreta. A opção D está incorreta 
porque tornar um serviço acessível não é uma tarefa no nível do cluster. 
19. B. O escalonamento automático é a maneira mais econômica e menos onerosa de responder às mudanças 
na demanda por um serviço, portanto, a opção B é a resposta correta. A opção A pode executar nós mesmo 
quando não são necessários. A opção C é manualmente intensiva e requer intervenção humana.
A opção D reduz a intervenção humana, mas não leva em conta picos inesperados ou quedas 
na demanda. 
20. B. Os engenheiros de nuvem que trabalham com o Kubernetes precisarão estar familiarizados com o trabalho com 
clusters, nós, pods e imagens de contêiner. Eles também precisam estar familiarizados com a implantação. A opção B é a resposta correta, porque faltam às outras opções um 
componente importante do Kubernetes que os engenheiros da nuvem terão que gerenciar. 
Capítulo 9: Computação com o App Engine 
1. B. As versões suportam a migração. Um aplicativo pode ter várias versões e, ao implantar com 
o parâmetro --migrate, você pode migrar o tráfego para a nova versão, portanto, a opção B é a 
resposta correta. Os serviços são uma abstração de nível superior e representam a funcionalidade
de um microserviço. Um aplicativo pode ter vários serviços, mas eles têm finalidades diferentes. 
Instâncias executam código em uma versão. Instâncias podem ser adicionadas e removidas conforme necessário, mas 
elas executarão apenas uma versão de um serviço. Os grupos de instâncias fazem parte do Compute Engine e 
não são um componente do Google App Engine. 
2. A. O escalonamento automático permite definir um número máximo e mínimo de instâncias, o que 
torna a opção A correta. O dimensionamento básico não suporta instâncias máxima e mínima. 
A opção C não é recomendada porque é difícil prever quando a carga atingirá o pico e, mesmo 
que a programação seja previsível hoje, ela pode mudar com o tempo. A opção D está errada; não há nenhuma 
opção de detecção de instância.
3. B. A aplicação é o componente de nível superior, portanto, a opção B é a resposta correta. Aplicativos 
têm um ou mais serviços. Os serviços têm uma ou mais versões. As versões são executadas em uma 
ou mais instâncias quando o aplicativo está em execução. 
4. B. O comando correto é gcloud app deploy, que é a opção B. As opções A e C estão 
incorretas porque os comandos de componentes gcloud são usados ​​para instalar comandos gcloud para 
trabalhar com partes do App Engine, como o ambiente de tempo de execução Python. Opção D está 
incorreta; você não precisa especificar a instância no comando. 
5. B. O arquivo app.yaml é usado para configurar um aplicativo do App Engine, o que torna a opção 
B correta. As outras opções não são arquivos usados ​​para configurar o App Engine.
482 Apêndice ■ Respostas às perguntas de revisão 
6. A. Um projeto pode suportar apenas um aplicativo do App Engine, portanto, a opção A é a resposta correta. Se você 
quiser executar outros aplicativos, eles precisarão ser colocados em seus próprios projetos. 
7. C. A resposta correta é a opção C porque o parâmetro correto é --no-promote. A opção A 
usa sem tráfego, o que não é um parâmetro válido para o comando gcloud app deploy. 
A opção B não obtém o código e pode liberar o código muito cedo se houver um atraso na 
divulgação do comunicado à imprensa. A opção D não atende aos requisitos de obter o código 
o mais rápido possível.
8. B. Os aplicativos do App Engine são acessíveis a partir de URLs que consistem no nome do projeto seguido por appspot.com, portanto, a opção B está correta. A opção A está incorreta porque o domínio 
não é appengine.com. As opções C e D estão incorretas porque os nomes dos serviços não são 
usados ​​para referenciar o aplicativo como um todo. 
9. A. max_concurrent_requests permite especificar o número máximo de 
solicitações simultâneas antes que outra instância seja iniciada, o que torna a opção A correta. target_ 
throughput_utilization funciona de maneira semelhante, mas usa uma escala de 0,05 a 0,95 para especificar a utilização máxima de taxa de transferência. max_instances especifica o número máximo de instâncias, 
mas não os critérios para adicionar instâncias. max_pending_latency é baseado no tempo que um
pedido aguarda, não o número de pedidos. 
10. C. O escalonamento básico permite apenas tempo ocioso e instâncias máximas, portanto, a opção C é a 
resposta correta . min_instances não é suportado. target_throughput_utilization é um parâmetro de escalonamento automático, não um parâmetro básico de escalonamento. 
11. C. O parâmetro runtime especifica o ambiente de linguagem para executar, o que torna a 
opção C correta. O script a ser executado é especificado pelo parâmetro de script. O URL para 
acessar o aplicativo é baseado no nome do projeto e no domínio appspot.com. Não 
há parâmetro para especificar o tempo máximo que um aplicativo pode ser executado. 
12. A. As instâncias residentes são usadas com o dimensionamento manual, enquanto as instâncias dinâmicas são usadas com
escalonamento automático e escalonamento básico, então a opção A é a resposta correta. Não há 
tipos persistentes, estáveis ​​ou não residentes de instâncias do App Engine. 
13. A. O uso de instâncias dinâmicas especificando escalonamento automático ou escalonamento básico 
ajustará automaticamente o número de instâncias em uso com base na carga, portanto, a opção A está correta. A opção B está 
incorreta porque o escalonamento automático e o escalonamento básico apenas criam instâncias dinâmicas. As opções C 
e D estão incorretas porque o dimensionamento manual não ajusta as instâncias automaticamente, portanto, você 
pode continuar a executar mais instâncias do que o necessário em alguns pontos. 
14. A. A resposta correta é gcloud app services set-traffic. A opção B está incorreta
porque o termo instâncias não é necessário. A opção C está incorreta porque não especifica 
o termo serviços. A opção D está incorreta porque isso exigiria alterações na 
parte do cliente. 
15. A. --split-traffic é o parâmetro usado para especificar o método de divisão do tráfego, o 
que torna a opção A correta. Opções válidas são cookie, ip e aleatórias. Todas as outras opções 
não são válidas para o comando gcloud app services set-traffic. 
Capítulo 10: Calculando com Nuvem Funções 483 
16. B. --split é o parâmetro para especificar uma lista de instâncias e o percentual de tráfego que 
deve receber, por isso a opção B é a resposta certa. As outras opções não são parâmetros válidos 
para o comando set-traffic do gcloud app services.
17. C. - migrar é o parâmetro para especificar que o tráfego deve ser movido ou migrado para 
a instância mais recente, o que torna a opção C a resposta correta. As outras opções não são 
parâmetros válidos para o comando set-traffic do gcloud app services. 
18. D. No console do App Engine, você pode visualizar a lista de serviços e versões, bem como 
informações sobre a utilização de cada instância. 
19. D. Todos os três métodos listados, endereço IP, cookie HTTP e divisão aleatória, são 
métodos permitidos para dividir o tráfego. 
20. B. O cookie usado para dividir no Google App Engine é chamado de GOOGAPPUID, o que torna a 
opção B a resposta correta. Opções A, C e D não são nomes válidos. 
Capítulo 10: Computação com 
funções de nuvem
1. O C. App Engine é projetado para suportar múltiplos serviços fortemente acoplados que compreendem um 
aplicativo, fazendo da opção C a resposta correta. Diferentemente do Cloud Functions, que é 
projetado para suportar funções de finalidade única que operam de forma independente e em resposta a 
eventos isolados no Google Cloud e concluídos em um período de tempo especificado. O Compute Engine não é uma opção sem servidor. O Cloud Storage não é um produto de computação. 
2. C. Um período de tempo limite muito baixo explicaria porque os arquivos menores são processados ​​no 
tempo, mas os maiores não, o que faz da opção C a resposta correta. Se apenas 10 por cento dos 
arquivos estão falhando, então não é um erro de sintaxe ou o tempo de execução incorreto selecionado, como nas opções
A e B. Esses erros afetariam todos os arquivos, não apenas os maiores. Da mesma forma, se houvesse 
um problema de permissão com o intervalo do Cloud Storage, isso afetaria todos os arquivos. 
3. B. Essas ações são conhecidas como eventos na terminologia do Google Cloud; Assim, a opção B é a 
resposta correta. Um incidente pode ser uma ocorrência relacionada à segurança ou ao desempenho, mas esses 
não estão relacionados às ações esperadas e padronizadas que constituem eventos. Um gatilho é 
uma declaração de que uma determinada função deve ser executada quando um evento ocorre. Uma entrada de registro está 
relacionada a aplicativos que registram dados sobre eventos significativos. As entradas de log são úteis para 
monitoramento e conformidade, mas em si não são ações relacionadas a eventos.
4. C. A resposta correta é a opção C porque o SSL é um protocolo seguro para acessar remotamente os 
servidores. Ele é usado, por exemplo, para acessar instâncias no Compute Engine. Não tem 
eventos que podem ser acionados usando o Cloud Functions. Os três produtos GCP listados 
geram eventos que podem ter gatilhos associados a eles. 
5. C. Cloud Functions suporta três tempos de execução: Node.js 6, Node.js 8 e Python. Go e 
Node.js 5 não são suportados por tempos de execução. 
484 APÊNDICE ■ Respostas às questões de revisão 
6. solicitações HTTP D. usando GET, POST, DELETE, PUT, e as opções podem invocar um HTTP 
gatilho em Funções nuvem, então a opção C é a resposta certa. 
7. D. A resposta correta, opção D, mostra os quatro eventos suportados no Cloud Storage.
google.storage.object.finalize 
google.storage.object.delete 
google.storage.object.archive 
google.storage.object.metadataUpdate 
8. C. Não há nenhuma opção para especificar o tipo de arquivo para aplicar a função, então a opção C está correto. Você pode, no entanto, especificar o bucket ao qual a função é aplicada. Você só pode 
salvar arquivos ou os tipos que deseja processar nesse intervalo, ou pode ter o 
tipo de arquivo de verificação de função e executar o restante da função, com base no tipo. Todas as outras 
opções listadas são parâmetros para uma função do Cloud Storage. 
9. D. Cloud Functions pode ter entre 128MB e 2GB de memória alocada, o que torna a 
opção D a resposta correta. O padrão é 256MB.
10. B. Por padrão, o Cloud Functions pode ser executado por até 1 minuto antes do tempo limite, então a opção B está 
correta. Você pode, no entanto, definir o parâmetro de tempo limite para uma função de nuvem por períodos de até 
9 minutos antes do tempo limite. 
11. B. O Python Cloud Functions está atualmente em beta. O conjunto padrão de comandos do gcloud 
não inclui comandos para recursos de versão alfa ou beta por padrão. Você precisará 
instalar explicitamente os recursos beta usando o comando gcloud components install beta, por isso, a 
opção B é a resposta correta. A opção A instalará os comandos padrão do gcloud. As opções C 
e D não são comandos gcloud válidos. 
12. A. O gatilho correto na opção A é google.storage.object.finalize, que ocorre
depois que um arquivo é carregado. A opção B não é um nome de disparo válido. A opção C é acionada quando um arquivo 
é arquivado, não é carregado. A opção D é acionada quando algum atributo de metadados é alterado, mas 
não necessariamente somente após o upload de um arquivo. 
13. C. Os três parâmetros são runtime, trigger-trigger e trigger-event, conforme listado 
na opção C. Tudo deve ser definido, portanto as opções A e B estão incorretas. O tipo de arquivo não é um parâmetro para criar uma função de nuvem no Cloud Storage, portanto, a opção D está incorreta. 
14. A. A resposta correta é a opção A, gcloud exclui as funções. A opção B faz referência a 
componentes, o que é incorreto. Você precisa fazer referência a componentes ao instalar ou 
atualizar comandos do gcloud, mas não ao excluir uma função de nuvem, portanto, as opções B e C
estão incorretos. A opção D está incorreta porque o tipo de entidade do GCP, neste caso, funciona 
antes do nome da operação, neste caso, excluir, em um comando gcloud. 
15. B. As mensagens são armazenadas em um formato de texto, base64, para que os dados binários possam ser armazenados na 
mensagem em formato de texto, portanto, a opção B está correta. Opção A está incorreta; é necessário mapear 
de uma codificação binária para uma codificação de texto padrão. A opção C está incorreta porque a 
função não é preenchida com caracteres extras para torná-los do mesmo tamanho. Opção D está 
incorreta; Ele não altera os tipos de dados do dicionário em tipos de dados de lista. 
Capítulo 11: Planejando o armazenamento na nuvem 485
16. C. A opção C está correta porque inclui o nome da função, o ambiente de tempo de execução e o nome do tópico Pub / Sub. A opção A está incorreta porque falta 
o tempo de execução e o tópico. A opção B está incorreta porque está faltando o tópico. A opção D está 
incorreta porque a especificação de tempo de execução está incorreta; você tem que especificar python37 e 
não python como o tempo de execução. 
17. B. Existe apenas um tipo de evento que é acionado no Cloud Pub / Sub, e é quando uma 
mensagem é publicada, que é a opção B. A opção A está incorreta; O Cloud Pub / Sub tem um 
tipo de evento que pode ter um acionador. A opção C está incorreta; O Cloud Pub / Sub não analisa 
o código para determinar quando deve ser executado. Opção D está incorreta; você não tem que
especifique um tipo de evento com as funções do Cloud Pub / Sub. 
18. B. A resposta correta é a opção B porque ela usa um evento finalizado do Cloud Storage para acionar a 
conversão, se necessário. Há um atraso mínimo entre o momento em que o arquivo é carregado e 
quando é convertido. A opção A é uma possibilidade, mas exigiria mais codificação do que a opção 
B. A opção C não é uma boa opção porque os arquivos não são convertidos até que o trabalho em lote seja executado. 
A opção D está incorreta porque você não pode criar uma função de nuvem para o Cloud Pub / Sub usando 
um evento finalizado. Esse evento é para o Cloud Storage, não para o Cloud Pub / Sub. 
19. D. Todas as opções estão disponíveis junto com o zip do Cloud Storage. 
20. A. O gatilho HTTP permite o uso de chamadas POST, GET e PUT, então a opção A é a
resposta correta. O Webhook e o Cloud HTTP não são tipos de acionador válidos. A opção D está incorreta porque a opção A é a resposta correta. 
Capítulo 11: Planejando o armazenamento na 
nuvem 
1. D. Quando um bloco é criado como regional ou multirregional, ele não pode ser alterado para o 
outro, portanto, a opção D está correta. Nearline para coldline e regional para nearline são ambos permitidos, 
como é multirregional para coldline. 
2. C. O objetivo é reduzir o custo, portanto, você desejaria usar a opção de armazenamento menos dispendiosa. 
O Coldline tem a menor taxa por gigabyte a US $ 0,07 / GB / mês, então a opção C está correta. 
Nearline é o próximo mais baixo seguido por regional. Multirregional tem o maior por gigabyte
carregar. Tanto o nearline quanto o coldline possuem taxas de acesso, mas esses não são considerados nesta 
questão. 
3. B. O Bigtable é um banco de dados de coluna ampla que pode ingerir grandes volumes de dados de forma consistente, 
portanto , a opção B está correta. Ele também suporta latência de baixo milissegundo, tornando-o uma boa opção 
para suportar a consulta. O Cloud Spanner é um banco de dados relacional global que não é adequado 
para a ingestão em alta velocidade de grandes volumes de dados. O armazenamento de dados é um modelo de dados de objeto e 
não é um bom ajuste para IoT ou outros dados de séries temporais. O BigQuery é um banco de dados de análise e não foi 
projetado para ingestão de grandes volumes de dados em curtos períodos de tempo. 
486 Apêndice ■ Respostas às perguntas de revisão
4. A. A opção A está correta porque o Memorystore é um cache Redis gerenciado. O cache pode 
ser usado para armazenar os resultados das consultas. Consultas subseqüentes que fazem referência aos dados armazenados no 
cache podem lê-las no cache, o que é muito mais rápido do que a leitura de 
discos permanentes . Os SSDs têm latência significativamente menor do que os discos rígidos e devem ser usados ​​para 
aplicativos sensíveis ao desempenho, como bancos de dados. As opções B e D estão incorretas porque 
os discos permanentes do HDD oferecem o melhor desempenho em relação à IOPS. As opções C e 
D estão incorretas porque o Datastore é um banco de dados NoSQL gerenciado e não teria nenhum 
impacto no desempenho da consulta SQL. 
5. B. Os HDDs são a melhor opção para discos permanentes de um banco de dados local quando o desempenho
não é a principal preocupação e você está tentando manter os custos baixos, então a opção B está correta. 
A opção A está errada porque os SSDs são mais caros e os usuários não precisam da menor 
latência disponível. As opções C e D estão erradas; ambos são outros bancos de dados que 
não seriam usados ​​para armazenar dados em um banco de dados relacional local. 
6. B. As configurações do ciclo de vida podem mudar a classe de armazenamento de regional para nearline ou coldline. 
Depois que um bloco é criado como regional ou multirregional, ele não pode ser alterado para o outro, portanto, a 
opção B é a resposta correta. Opção A é verdadeira; você pode definir períodos de retenção ao criar um 
intervalo. A opção C é verdadeira; O Cloud Storage não fornece acesso semelhante ao sistema de arquivos para
blocos de dados. A opção D é verdadeira porque o Cloud Storage é altamente durável. 
7. A. A versão mais recente de um objeto é chamada de versão ao vivo, portanto, a opção A está correta. 
As opções B e C estão incorretas; top e active não são termos usados ​​para se referir a versões. 
A opção D está incorreta porque a opção A está correta. 
8. B. O Cloud SQL e o Spanner são bancos de dados relacionais e são adequados para aplicativos de processamento de transações, portanto, a opção B está correta. A opção A está incorreta porque o BigQuery é 
relacional, mas foi projetado para armazenamento e análise de dados, não para processamento de transações. 
As opções C e D estão incorretas porque o Bigtable é um banco de dados NoSQL de coluna ampla, não um 
banco de dados relacional.
9. C. Tanto o MySQL quanto o PostgreSQL são opções do Cloud SQL, então a Opção C está correta. As opções A 
e B estão incorretas, o SQL Server não é uma opção do Cloud SQL. A opção D está incorreta porque o 
Oracle não é uma opção do Cloud SQL. Você poderia optar por executar o SQL Server ou o Oracle em suas 
instâncias, mas teria de gerenciá-las, diferentemente dos bancos de dados gerenciados do Cloud SQL. 
10. D. A localização multirregional e multi-super-regional de nam-eur-aisa1 é a mais 
cara, o que faz da opção D a resposta certa. A opção A é uma região que custa menos 
que o multi-super-regional nam-eur-asia1. A opção C está incorreta; isso é uma zona e a 
Spanner é configurada para regiões ou super-regiões. A opção B está incorreta; é apenas um único
Super região, que custa menos do que a implantação em várias super-regiões. 
11. D. O BigQuery, o Datastore e o Firebase são todos serviços totalmente gerenciados que não exigem que você 
especifique informações de configuração para VMs, o que torna a opção D correta. O Cloud SQL 
e o Bigtable exigem que você especifique algumas informações de configuração para as VMs. 
12. O B. Datastore é um banco de dados de documentos, o que torna a opção B correta. Cloud SQL e Spanner são bancos de dados relacionais. O Bigtable é um banco de dados de coluna ampla. O Google não oferece um 
banco de dados gráfico gerenciado. 
Capítulo 12: Implantando o armazenamento no Google Cloud Platform 487 
13. A. O BigQuery é um serviço gerenciado desenvolvido para data warehouses e analítica. Usa
SQL padrão para consulta, o que torna a opção A a resposta correta. O Bigtable pode suportar 
o volume de dados descrito, mas não usa o SQL como uma linguagem de consulta. O Cloud SQL 
não é a melhor opção para escalar para dezenas de petabytes. O SQL Server é um banco de dados relacional da 
Microsoft; não é um serviço de banco de dados gerenciado pelo GCP. 
14. B. O Firestore é um banco de dados de documentos que possui recursos de suporte para dispositivos móveis, como a sincronização de dados, de modo que a opção B é a resposta correta. O BigQuery é para análises, não aplicativos móveis ou transacionais. O Spanner é um banco de dados relacional global, mas não possui 
recursos específicos para dispositivos móveis . O Bigtable pode ser usado com dispositivos móveis, mas não possui 
recursos específicos para dispositivos móveis, como sincronização.
15. D. Além de ler e escrever padrões, custos e consistência, você deve considerar o suporte a transações e a latência, o que torna a opção D correta. 
16. B. A opção B está correta porque o Memorystore pode ser configurado para usar entre 1 GB e 300 GB 
de memória. 
17. D. Uma vez que um bucket esteja configurado para coldline, ele não poderá ser alterado para outra classe de armazenamento; assim, a 
opção D está correta. Regional e multirregional pode mudar para nearline e coldline. 
Os baldes de nearline podem mudar para coldline. 
18. A. Para usar o BigQuery para armazenar dados, você deve ter um conjunto de dados para armazená-los, o que torna a opção 
A a resposta correta. As caçambas são usadas pelo Cloud Storage, não pelo BigQuery. Você não gerencia
discos permanentes ao usar o BigQuery. Uma entidade é uma estrutura de dados no Datastore, não no BigQuery. 
19. D. Com uma instância de segunda geração, você pode configurar a versão do MySQL, conectividade, 
tipo de máquina, backups automáticos, réplicas de failover, sinalizadores de banco de dados, janelas de manutenção 
e rótulos, portanto a opção D está correta. 
20. A. As taxas de acesso são usadas com armazenamento nearline e coldline, o que torna a opção A correta. Não há cobrança de transferência envolvida. As opções C e D não se referem às 
classes de armazenamento reais . 
Capítulo 12: Implantando o armazenamento no 
Google Cloud Platform 
1. C. Criar bancos de dados é responsabilidade dos administradores do banco de dados ou de outros usuários
Cloud SQL, então a opção C está correta. O Google aplica patches de segurança e realiza outras 
manutenções, por isso, a opção A está incorreta. O GCP executa regularmente backups agendados, portanto, a 
opção B está incorreta. Os administradores de banco de dados precisam agendar backups, mas o GCP garante 
que eles sejam executados no prazo. Os usuários do Cloud SQL não podem acessar o SSH em um servidor do Cloud SQL, 
portanto , não podem ajustar o sistema operacional. Isso não é um problema; O Google cuida disso. 
488 Apêndice ■ Respostas às Questões de Revisão 
2. A. O Cloud SQL é controlado usando o comando gcloud; a sequência de termos nos 
comandos gcloud é gcloud, seguida pelo serviço, neste caso, SQL; seguido por um recurso, 
neste caso, backups, e um comando ou verbo, neste caso, criar. A opção A é a correta
responda. A opção B está incorreta porque a gsutil é usada para trabalhar com o Cloud Storage, não com o 
Cloud SQL. A opção C está errada porque a ordem dos termos está incorreta; backups vem 
antes de criar. A opção D está incorreta porque o comando ou verbo deve ser criado. 
3. A. A opção A é a resposta correta. O comando base é gcloud sql instances patch, 
que é seguido pelo nome da instância e uma hora de início passada para o parâmetro –backup-start-time 
. A opção B está incorreta porque os bancos de dados não são o recurso correto para referência; instâncias é. A opção C usa o comando cbt, que é para uso com o Bigtable, então está 
incorreto. Da mesma forma, a Opção D está incorreta porque usa o comando bq, que é usado para 
gerenciar recursos do BigQuery.
4. O C. Datastore usa uma linguagem de consulta do tipo SQL chamada GQL, então a opção C está correta. Opção 
A está incorreta; SQL não é usado com este banco de dados. A opção B está incorreta; MDX é uma 
linguagem de consulta para sistemas de processamento analítico online (OLAP). A opção D está incorreta porque os 
DataFrames são uma estrutura de dados usada no Spark. 
5. C. Opção C é o comando correto. Ele tem o comando base correto, gcloud datastore 
export, seguido pelo parâmetro --namespaces e o nome de um intervalo do Cloud Storage 
para manter o arquivo de exportação. A opção A está incorreta porque o nome do parâmetro --namespaces 
está ausente. Opção B está incorreta porque está faltando um espaço para nome. A opção D está incorreta 
porque usa o comando ou despejo de verbos em vez de exportar.
6. C. A opção C está correta; O BigQuery exibe uma estimativa da quantidade de dados verificados. Isso 
é importante porque o BigQuery cobra pelos dados verificados nas consultas. Opção A está incorreta; 
Saber quanto tempo você levou para entrar em uma consulta não é útil. A opção B está incorreta; você 
precisa usar a estimativa de dados digitalizados com a calculadora de preços para obter um custo estimado. 
Opção D está incorreta; você não cria clusters no BigQuery como faz com o Bigtable e o 
Dataproc. Os dados de E / S da rede não são exibidos. 
7. B. A Opção B mostra a estrutura de comando bq correta, que inclui a localização e a 
opção ––dry_run. Esta opção calcula uma estimativa sem executar a consulta.
As opções A e C estão incorretas porque usam o comando errado; O gcloud e a gsutil 
não são usados ​​com o BigQuery. A opção D também está errada. O cbt é uma ferramenta para trabalhar com o Bigtable, não o BigQuery. Tenha cuidado para não confundir os dois porque seus nomes são semelhantes. 
8. A. A opção A está correta; a opção do menu é Histórico do trabalho. As opções B e C estão incorretas; 
não há nenhuma opção Trabalhos ativos ou Minhas tarefas. O histórico de trabalhos mostra trabalhos ativos, trabalhos concluídos 
e trabalhos que geraram erros. Opção D está incorreta; você pode obter o status do trabalho no console. 
9. C. O BigQuery fornece uma estimativa da quantidade de dados digitalizados e a Calculadora de preços 
fornece uma estimativa de custo para a varredura desse volume de dados. As opções A, B e C estão incorretas;
o serviço de faturamento acompanha as cobranças incorridas. Não é usado para estimar 
cobranças futuras ou potenciais . 
Capítulo 12: Implantando o armazenamento no Google Cloud Platform 489 
10. B. A opção B está correta; O próximo passo é criar um banco de dados dentro da instância. Depois que um 
banco de dados é criado, as tabelas podem ser criadas e os dados podem ser carregados em tabelas. Opção A 
está incorreta; O Cloud Spanner é um banco de dados gerenciado, portanto, você não precisa aplicar 
patches de segurança . A opção C está incorreta porque você não pode criar tabelas sem primeiro ter criado um 
banco de dados. Opção D está incorreta; nenhuma tabela é criada na qual você possa importar dados quando 
uma instância é criada.
11. D. A opção D está correta porque não há necessidade de aplicar correções aos 
recursos de computação subjacentes ao usar o Cloud Spanner. porque o Google gerencia os recursos usados ​​pelo Cloud 
Spanner. A atualização de pacotes é uma boa prática ao usar VMs, por exemplo, com o 
Compute Engine, mas não é necessária com um serviço gerenciado. 
12. C. Este caso de uso é bem adequado ao Pub / Sub, então a opção C está correta. Envolve o envio de 
mensagens para o tópico e o modelo de assinatura é um bom ajuste. Pub / Sub tem um 
período de retenção para suportar o período de retenção de três dias. Opção A está incorreta; O Bigtable é projetado 
para armazenar grandes volumes de dados. O Dataproc é para processar e analisar dados, não
passando entre sistemas. O Cloud Spanner é um banco de dados relacional global. Você poderia projetar 
um aplicativo para atender a esse caso de uso, mas isso exigiria um desenvolvimento substancial e seria 
dispendioso de ser executado. 
13. C. Pub / Sub trabalha com tópicos, que recebem e retêm mensagens e assinaturas, que 
disponibilizam mensagens para aplicativos consumidores; portanto, a opção C está correta. Opção 
A está incorreta; tabelas são estruturas de dados em bancos de dados relacionais, não filas de mensagens. 
Da mesma forma, a opção B está errada porque existem bancos de dados em instâncias de 
sistemas de gerenciamento de banco de dados , não em sistemas de mensagens. A opção D está errada porque as tabelas não são um recurso nos 
sistemas de mensagens.
14. C. O comando correto é gcloud components install cbt para instalar a 
ferramenta de linha de comando Bigtable , então a opção C está correta. As opções A e B estão incorretas; O apt-get é usado 
para instalar pacotes em alguns sistemas Linux, mas não é específico para o GCP. Opção D está incorreta; 
não existe tal comando como bigtable-tools. 
15. A. Você precisaria usar um comando cbt, que é a ferramenta de linha de comando para trabalhar 
com o Bigtable, portanto a opção A está correta. Todas as outras opções fazem referência a gcloud e, portanto, estão 
incorretas. 
16. B. O Cloud Dataproc é um serviço gerenciado para o Spark e o Hadoop, portanto, a opção B está correta. 
O Cassandra é um banco de dados distribuído de big data, mas não é oferecido como um serviço gerenciado
Google, então as opções A e C estão incorretas. A opção D está incorreta porque o TensorFlow é uma 
plataforma de aprendizado profundo não incluída no Dataproc. 
17. B. O comando correto é gcloud dataproc clusters create seguido pelo nome do 
cluster e pelo parâmetro a -zone. A opção B está correta. A opção A está incorreta porque 
bq é a ferramenta de linha de comando do BigQuery, não do Dataproc. A opção C é um comando gcloud 
sem um verbo ou comando, por isso está incorreto. A opção D está errada porque a opção B é a 
resposta correta. 
490 Apêndice ■ Respostas às Questões de Revisão 
18. B. gsutil é o comando correto, então a opção B está correta. A opção A está incorreta porque os 
comandos do gcloud não são usados ​​para gerenciar o Cloud Storage. Da mesma forma, as opções C e D são
incorreto porque eles usam comandos para Bigtable e BigQuery, respectivamente. 
19. B. O comando na opção B renomeia corretamente um objeto de um nome antigo para um novo 
nome. A opção A está incorreta porque usa um comando cp em vez de mv. A opção C 
não inclui nomes de intervalos, por isso está incorreto. A opção D usa o gcloud, mas a gsutil é a ferramenta de linha de comando para trabalhar com o Cloud Storage. 
20. A. O Dataproc com o Spark e sua biblioteca de aprendizado de máquina são ideais para esse caso de uso; portanto, a 
opção A está correta. A opção B sugere o Hadoop, mas não é uma boa escolha para 
aplicativos de aprendizado de máquina . A opção C está incorreta porque o Spanner é projetado como um banco de dados relacional global com suporte para sistemas de processamento de transações, não analítico e de máquina
sistemas de aprendizagem. A opção D está incorreta. O SQL é uma linguagem de consulta poderosa, mas não 
suporta os tipos de algoritmos de aprendizado de máquina necessários para resolver o problema proposto. 
Capítulo 13: Carregando dados no armazenamento 
1. O C. gsutil é o utilitário de linha de comando para trabalhar com o Cloud Storage. É um dos poucos 
serviços do GCP que não usa o gcloud. (BigQuery e Bigtable são outros.) A opção C é 
a resposta correta porque mb, abreviação de "make bucket", é o verbo que segue a gsutil para 
criar um bloco. As opções A e D estão erradas porque usam gcloud em vez de gsutil. 
A opção B está errada porque usa a gsutil com uma sintaxe de comando usada pelo gcloud.
2. B. A resposta correta é a opção B; A gsutil é o comando para copiar arquivos para o Cloud Storage. 
Opção A está incorreta; o verbo é cp, não copiar. As opções C e D estão erradas porque a gsutil, e 
não o gcloud, é o utilitário de linha de comando para trabalhar com o Cloud Storage. 
3. C. No console, você pode fazer upload de arquivos e pastas. As opções A e B estão incorretas 
porque estão faltando uma operação que pode ser executada no console. A opção D está 
incorreta porque não há operação de diferenciação no Cloud Console. 
4. D. Ao exportar um banco de dados do Cloud SQL, as opções de formato de arquivo de exportação são CSV 
e SQL, o que torna a opção D correta. A opção A está incorreta porque o XML não é uma 
opção. As opções B e C estão incorretas porque o JSON não é uma opção.
5. A. Opção A, formato SQL, exporta um banco de dados como uma série de comandos de definição de dados SQL. 
Esses comandos podem ser executados em outro banco de dados relacional sem precisar primeiro criar um esquema. A opção B poderia ser usada, mas isso exigiria o mapeamento de colunas para colunas 
em um esquema que foi criado antes de carregar o CSV, e o administrador de banco de dados 
gostaria de evitar isso. As opções C e D estão incorretas porque não são 
opções de formato de arquivo de exportação . 
6. C. A Opção C é o comando correto, gcloud sql export sql, indicando que o serviço é 
Cloud SQL, a operação é exportar e o formato do arquivo de exportação é SQL. O nome do arquivo e o bloco de destino estão formados corretamente. A opção A está incorreta porque faz referência ao armazenamento do gcloud.
não gcloud sql. A opção B está incorreta porque está faltando um parâmetro de formato de arquivo de exportação. 
A opção D está incorreta porque o nome do bloco e o nome do arquivo estão na ordem errada. 
Capítulo 13: Carregamento de dados no armazenamento 491 
7. A. A opção A usa o comando correto, que é gcloud datastore export seguido por 
um namespace e um nome de bucket. A opção B está incorreta porque o nome do intervalo está ausente gs: //. As opções C e D estão incorretas porque usam o dump de comando em vez da 
exportação. O nome do intervalo na opção D está faltando gs: //. 
8. C. O processo de exportação cria um arquivo de metadados com informações sobre os dados exportados 
e uma pasta que possui os dados em si, portanto, a opção C está correta. A opção A está incorreta porque
exportação não produz um único arquivo; produz um arquivo de metadados e uma pasta com os dados. 
A opção B está incorreta porque não inclui a pasta de dados. A opção D está incorreta 
porque a resposta correta é a opção C. 
9. B. A opção B está correta porque o XML não é uma opção no processo de exportação do BigQuery. Todas as 
outras opções estão disponíveis. 
10. D. A opção D está correta porque o YAML não é um formato de armazenamento de arquivos; é usado para especificar 
dados de configuração. Opções A, B e C são todos os tipos de arquivos de importação suportados. 
11. A. O comando correto é bq load na opção A. Os 
parâmetros autodetect e source_format e o caminho para a origem são especificados corretamente em todas as opções. A opção B está incorreta
porque usa o termo import em vez de load. As opções C e D estão incorretas porque 
usam gcloud em vez de bq. 
12. B. A resposta correta é B porque o Dataflow é um serviço de pipeline para processamento de dados em fluxo contínuo 
e em lotes que implementa fluxos de trabalho usados ​​pelo Cloud Spanner. Opção A está incorreta; 
O Dataproc é um serviço gerenciado do Hadoop e do Spark, que é usado para análise de dados. A opção 
C está incorreta; O Datastore é um banco de dados NoSQL. A opção D está incorreta porque bq é usado 
apenas com o BigQuery. 
13. A. Os dados do Bigtable são exportados usando um programa Java compilado, portanto, a opção A está correta. A opção 
B está incorreta; não há comando do gcloud Bigtable. A opção C está incorreta; bq não é usado
com Bigtable. A opção D está incorreta porque não exporta dados do Bigtable. 
14. C. A exportação do Dataproc exporta dados sobre a configuração do cluster, o que torna a 
opção C correta. Opção A está incorreta; os dados em DataFrames não são exportados. A opção B está 
incorreta; O Spark não possui tabelas para armazenamento persistente de dados, como bancos de dados relacionais. 
Opção D está incorreta; nenhum dado do Hadoop é exportado. 
15. C. A resposta correta é a opção C; o serviço O Dataproc suporta o Apache Spark, que 
possui bibliotecas para aprendizado de máquina. As opções A e B estão incorretas, nem um serviço de análise ou de 
aprendizado de máquina. Opção D, DataAnalyze, não é um serviço real.
16. A. O comando correto na opção A usa gcloud seguido pelo serviço, neste caso 
pubsub, seguido pelo recurso, neste caso tópicos; e finalmente o verbo, neste caso, 
criar. A opção B está incorreta porque os dois últimos termos estão fora de ordem. As opções C e 
D estão incorretas porque não usam o gcloud. O bq é a ferramenta de linha de comando do BigQuery. 
cbt é a ferramenta de linha de comando do Bigtable. 
17. C. A resposta correta, opção C, usa o gcloud pubsub subscriptions create seguido 
pelo tópico e pelo nome da assinatura. Opção A está incorreta porque está faltando 
o termo assinaturas. A opção B está incorreta porque está faltando o nome da assinatura. A opção D está incorreta porque usa a gsutil em vez de gcloud.
492 Apêndice ■ Respostas às Questões de Revisão 
18. B. O uso de uma fila de mensagens entre os serviços desacopla os serviços, portanto, se um ficar atrasado, ele não 
causará atraso em outros serviços, o que torna a opção B correta. A opção A está incorreta porque a 
inclusão de uma fila de mensagens não reduz diretamente quaisquer riscos de segurança que possam existir no 
sistema distribuído, como permissões excessivamente permissivas. A opção C está incorreta; Adicionar uma 
fila não está diretamente relacionado às linguagens de programação. Opção D está incorreta; por padrão, as 
filas de mensagens têm um período de retenção. 
19. B. A resposta correta é B, gcloud components seguido por install e depois beta. 
Opção A está incorreta porque beta e instalar estão na ordem errada. Opções C e D
estão erradas porque os comandos são usados ​​em vez de componentes. 
20. A. O nome correto do parâmetro é autodetect, que é a opção A. As opções B e C não são 
parâmetros bq realmente válidos. A opção D é um parâmetro válido, mas retorna o 
tamanho estimado dos dados verificados para a execução de uma consulta. 
21. A. Avro suporta a compactação Deflate and Snappy. O CSV suporta o Gzip e nenhuma compactação. 
XML e Thrift não são opções de tipo de arquivo de exportação. 
Capítulo 14: Rede na Nuvem: 
Nuvens Privadas Virtuais e 
Redes Privadas Virtuais 
1. D. Nuvens privadas virtuais são globais, portanto a opção D está correta. Por padrão, eles têm sub-redes em 
todas as regiões. Recursos em qualquer região podem ser acessados ​​através do VPC. Opções A, B e C
estão todos incorretos. 
2. B. As faixas de IP são atribuídas a sub-redes, portanto, a opção B está correta. Cada sub-rede é atribuída um 
intervalo de IP para seu uso exclusivo. Os intervalos de IP são atribuídos a estruturas de rede, não a regiões e regiões. 
As VPCs podem ter várias sub-redes, mas cada sub-rede possui seu próprio intervalo de endereços. 
3. B. A opção B está correta; O roteamento dinâmico é o parâmetro que especifica se as rotas são 
aprendidas regional ou globalmente. Opção A está incorreta; DNS é um serviço de resolução de nomes e 
não está envolvido no encaminhamento. A opção C está incorreta; não há parâmetro de política de roteamento estático. A opção D está incorreta porque o roteamento global não é uma opção real. 
4. A. A resposta correta é gcloud compute networks create, que é a opção A. Opção
B está incorreto; redes vpc não é uma parte correta do comando. A opção C está incorreta 
porque a gsutil é o comando usado para trabalhar com o Cloud Storage. A opção D está incorreta 
porque não existe tal coisa. 
5. A. A opção Flow Log do comando create vpc determina se os logs são enviados 
ao Stackdriver, portanto, a opção A está correta. A opção B, acesso IP privado, determina se 
um endereço IP externo é necessário para que uma VM use os serviços do Google. A opção C está incorreta 
porque o Stackdriver Logging é o serviço, não um parâmetro usado ao criar uma sub-rede. A opção D está incorreta porque o mascaramento de sub-rede de comprimento variável tem a ver com 
endereços CIDR , não com o log. 
Capítulo 14: Funcionamento em Rede na Nuvem Nuvens Privadas Virtuais 493
6. C. As VPCs compartilhadas podem ser criadas no nível de organização ou pasta da hierarquia de recursos, 
portanto , a opção C está correta. As opções A e B estão incorretas; VPCs compartilhados não são criados nos 
níveis de recurso ou projeto. Opção D está incorreta; VPCs compartilhadas não são aplicadas em sub-redes, 
que são recursos na hierarquia de recursos. 
7. A. A resposta correta é a guia Rede da seção Gerenciamento, Segurança, Discos, Rede, Inquilino único do formulário, que torna a opção A correta. A guia Gerenciamento não é sobre configurações de sub-rede. A opção D está incorreta porque não leva 
a opções de alocação única.
8. A. O VPC é usado para comunicações de intérpretes. A opção B está incorreta; não há peering de interprojeto. As opções C e D estão incorretas; eles têm a ver com a vinculação de 
redes locais com redes no GCP. 
9. B. O destino pode ser todas as instâncias de uma rede, instâncias com tags de rede específicas 
ou instâncias usando uma conta de serviço específica, portanto, a opção B está correta. Opção A está incorreta; 
A ação é permitir ou negar. A opção C está incorreta; prioridade determina qual das 
regras de correspondência é aplicada. Opção D está incorreta; especifica se a regra é aplicada ao 
tráfego de entrada ou saída. 
10. D. Direção especifica se a regra é aplicada ao tráfego de entrada ou saída, que
faz a opção D a resposta certa. Opção A está incorreta; A ação é permitir ou negar. 
A opção B está incorreta; target especifica o conjunto de instâncias às quais a regra se aplica. A opção C 
está incorreta; prioridade determina qual das regras correspondentes é aplicada. 
11. A. O 0.0.0.0/0 corresponde a todos os endereços IP, portanto a opção A está correta. A opção B representa um 
bloco de 16.777.214 endereços. A opção C representa um bloco de 1.048.574 endereços. A opção 
D representa um bloco de 65.534. Você pode experimentar as opções de bloco do CIDR usando uma 
calculadora CIDR como a que está em www.subnet-calculator.com/cidr.php.
12. B. O produto com o qual você está trabalhando é computado e o recurso que você está criando é uma regra de firewall, portanto a opção B está correta. As opções A e C fazem referência à rede em vez de computar. 
A opção D faz referência a regras em vez de regras de firewall. 
13. B. O parâmetro correto é rede, o que torna a opção B correta. Opção A está incorreta; 
A sub-rede não é um parâmetro para gcloud criar um firewall. A opção C está incorreta; destino não é um parâmetro válido. Opção D está incorreta; source-ranges é para especificar 
fontes de tráfego de rede às quais a regra se aplica. 
14. A. A regra na opção A usa o comando gcloud correto e especifica os 
parâmetros de permissão e direção. A opção B está incorreta porque faz referência à rede gcloud
de gcloud compute. A opção C está incorreta porque não especifica o intervalo de portas. A opção D 
está incorreta porque não especifica o protocolo ou o intervalo de portas. 
15. D. A opção D está correta porque é o maior número permitido no intervalo de valores para 
prioridades. Quanto maior o número, menor a prioridade. Ter a prioridade mais baixa 
garantirá que outras regras correspondentes sejam aplicadas. 
16. C. A opção de criação de VPC está disponível na seção Conectividade Híbrida, então a opção C está correta. O Compute Engine, o App Engine e o IAM e o Admin não possuem recursos relacionados a VPNs. 
494 Apêndice ■ Respostas às perguntas de revisão 
17. C. A VPN do Google Compute Engine é onde você especifica informações sobre o Google.
Cloud final da conexão VPN, então a opção C está correta. Você especifica nome, descrição, rede, região e endereço IP. A opção A está incorreta porque os túneis são sobre as 
conexões entre a nuvem e a rede remota. A opção B está incorreta; 
Opções de roteamento é sobre como configurar roteadores. Opção D está incorreta; IKE Version é sobre 
troca de chaves secretas. 
18. A. A opção A está correta porque o roteamento dinâmico global é usado para aprender todas as rotas em uma rede. A opção B está incorreta; o roteamento regional aprenderia apenas rotas em uma região. As opções 
C e D estão incorretas porque não são usadas para configurar as opções de roteamento. 
19. B. O número do sistema autônomo (ASN) é um número usado para identificar um roteador de nuvem em um
rede, a opção B está correta. Endereços IP não são identificadores exclusivos para o protocolo BGP. 
A opção C está incorreta; não há ID de roteamento de carga dinâmica. A opção D está incorreta porque a 
opção B está correta. 
20. D. Ao usar o gcloud para criar uma VPN, você precisa criar regras de encaminhamento, túneis e 
gateways, para que todos os comandos gcloud listados sejam usados. 
Capítulo 15: Funcionamento em rede na nuvem: 
DNS, balanceamento de carga e endereçamento IP 
1. B. O registro A é usado para mapear um nome de domínio para um endereço IPv4, portanto, a opção B está correta. 
A opção A está incorreta porque o registro AAAA é usado para endereços IPv6. A opção C está 
incorreta; NS é um registro do servidor de nomes. Opção D está incorreta; SOA é um começo de 
registro de autoridade .
2. A. O DNSSEC é um protocolo seguro projetado para evitar spoofing e envenenamento de cache, portanto, a 
opção A está correta. As opções B e C estão incorretas porque os registros SOA e CNAME contêm dados sobre o registro DNS; eles não são uma medida de segurança adicional. A opção D está 
incorreta porque a exclusão de um registro CNAME não melhora a segurança. 
3. A. Os parâmetros TTL especificam a hora em que um registro pode estar em um cache antes que os dados 
sejam consultados novamente, portanto a opção A está correta. A opção B está incorreta; este período de tempo não está 
relacionado a tempos limite. A opção C está incorreta; os TTLs não estão relacionados à restrição de tempo nas 
operações de alteração de dados. A opção D não está correta; não há revisão manual necessária.
4. B. A resposta correta, Opção B, é gcloud beta dns managed-zones create. A opção A está 
incorreta. Ela usa o comando gsutil, usado para trabalhar com o Cloud Storage. Opção C está 
incorreta, está faltando o termo dns. A opção D está incorreta, a ordenação dos termos está incorreta. 
5. B. O parâmetro de visibilidade é o parâmetro que pode ser definido como privado, portanto a opção B está 
correta. A opção A não é um parâmetro válido. A opção C está incorreta; private não é um parâmetro. 
Da mesma forma, a opção D está incorreta; status não é um parâmetro válido para tornar uma zona DNS 
privada. 
Capítulo 15: Rede na nuvem: DNS, balanceamento de carga e endereçamento IP 495 
6. C. Os três balanceadores de carga globais são HTTP (S), Proxy SSL e Proxy TCP, então a opção C
está correto. Opções A e B estão faltando pelo menos um balanceador de carga global. A opção D está incorreta porque o TCP / UD interno é um balanceador de carga regional. 
7. D. Rede TCP / UDP permite o balanceamento baseado no protocolo IP, endereço e porta, então a 
opção D está correta. As opções A, B e C são todas balanceadores de carga globais, não regionais. 
8. A. No console, há uma opção para selecionar entre De Internet para Minhas VMs e Somente 
Entre Minhas VMs. Esta é a opção para indicar privado ou público, então a opção A está correta. 
As opções B, C e D são todos os parâmetros fictícios. 
9. B. Os balanceadores de carga TCP Proxy exigem que você configure tanto o frontend quanto o backend,
então a opção B está correta. As opções A e D estão incorretas porque estão faltando um componente. A opção C está incorreta; as regras de encaminhamento são o único componente especificado com 
balanceamento de carga de rede . Não há nenhum componente conhecido como uma regra de tráfego. 
10. B. As verificações de integridade monitoram a integridade das VMs usadas com balanceadores de carga, portanto, a opção B está correta. 
A opção A está incorreta, o armazenamento nearline é um tipo de armazenamento em nuvem. Opção C e D estão 
incorretas; dispositivos de armazenamento ou buckets não são verificados. 
11. B. Você especifica portas para encaminhar ao configurar o frontend, então a opção B está correta. O 
back-end é onde você configura como o tráfego é roteado para as VMs. A opção C está incorreta; Serviços de rede é uma área de alto nível do console. Opção D está incorreta; VPCs não estão onde
você especifica configurações do balanceador de carga. 
12. A. A resposta correta, opção A, é gcloud compute forwarding-rules create. 
A opção B está incorreta; o serviço deve ser computado, não em rede. A opção C está incorreta; 
create vem depois das regras de encaminhamento. A opção D está incorreta porque tem o 
serviço errado e o verbo está na posição errada. 
13. C. Os endereços estáticos são atribuídos até que sejam liberados, portanto, a opção C está correta. As opções A 
e B estão incorretas porque os endereços internos e externos determinam se o tráfego é 
roteado para dentro e para fora da sub-rede. Endereços externos podem ter tráfego para acessá-los da 
Internet; endereços internos não podem. Opção D está incorreta; endereços efêmeros são liberados
quando uma VM é encerrada ou é excluída. 
14. A. Um endereço efêmero é suficiente, uma vez que os recursos fora da sub-rede não precisarão 
alcançar a VM e você poderá acessar o SSH na VM a partir do console, portanto, a opção A está correta. 
A opção B está incorreta porque não há necessidade de atribuir um endereço permanente, o qual teria 
que ser liberado. A opção C está incorreta; não existe um tipo permanente. Opção D está 
incorreta; não há endereço IPv8. 
15. D. Você não pode reduzir o número de endereços usando nenhum dos comandos, então a opção D está 
correta. A opção A está incorreta porque o comprimento do prefixo especificado no 
comando expand-ip-range deve ser um número menor que o comprimento atual. Se houver 65.534 endereços,
então o tamanho do prefixo é 16. A opção B está incorreta pelo mesmo motivo, e o tamanho do prefixo 
não pode ser um número negativo. A opção C está incorreta; não há parâmetro ––size. 
496 Apêndice ■ Respostas às Questões de Revisão 
16. B. O tamanho do prefixo especifica o comprimento em bits da máscara de sub-rede. Os bits restantes do 
endereço IP são usados ​​para endereços de dispositivos. Como há 32 bits em um endereço IP, você 
subtrai o comprimento da máscara para obter o número de bits usado para representar o endereço. 16 é 
igual a 24, então você precisa de 4 bits para representar 14 endereços. 32-4 é 28, então a opção B é a resposta correta. A opção A deixaria 1 endereço, a opção C forneceria 4.094 endereços e a 
opção D forneceria 65.534.
17. C. Premium é o nível de serviço de rede que roteia todo o tráfego pela rede do Google, 
portanto , a opção C está correta. Opção A está incorreta; o nível Padrão pode usar a Internet pública ao rotear o tráfego. As opções B e D estão incorretas; não há níveis de serviço chamados 
somente Google ou não-Internet. 
18. B. Parar e iniciar uma VM libera endereços IP efêmeros, portanto a opção B está correta. 
Use um endereço IP estático para ter o mesmo endereço IP nas reinicializações. Opção A está incorreta; 
reinicializar uma VM não altera um registro DNS. A opção C está incorreta porque, se você tinha 
endereços suficientes para obter um endereço quando iniciou a VM e liberou 
esse endereço IP, deveria haver pelo menos um endereço IP, presumindo que nenhum outro dispositivo fosse adicionado
para a sub-rede. A opção D está incorreta porque nenhuma outra alteração, incluindo alterações na 
sub - rede, foi feita. 
19. A. O TCP / UDP interno é uma boa opção. É um balanceador de carga regional que suporta UDP, portanto, a 
opção A está correta. As opções B, C e D são todas balanceadoras de carga globais. Opção B suporta 
TCP, não UDP. A opção D suporta HTTP e HTTPS, não UDP. 
20. B. Serviços de Rede é a seção do Cloud Console que possui o console do Cloud DNS, portanto, a 
opção B está correta. Opção A está incorreta; O Compute Engine não possui formulários de gerenciamento de DNS. Nem a opção C, Kubernetes Engine. A opção D está relacionada à rede, 
mas os serviços da Conectividade Híbrida são para serviços como VPNs. 
Capítulo 16: Implantando Aplicativos
com o Cloud Launcher e o Deployment 
Manager 
1. D. Categorias de soluções incluem todas as categorias mencionadas, então a opção D está correta. 
Outros incluem Kubernetes Apps, API e Serviços e Bancos de Dados. 
2. B. O Cloud Launcher também é conhecido como Marketplace, então a opção B está correta. A opção A está 
incorreta porque o Cloud Deployment Manager é usado para criar modelos de implantação. 
As opções C e D são nomes fictícios de serviços. 
3. A. Você inicia uma solução clicando no link Iniciar no Compute Engine na 
página de visão geral , portanto, a opção A está correta. A opção B está incorreta; a página principal contém informações resumidas sobre os produtos. A opção C está incorreta; Serviços de rede não está relacionado a este tópico.
A opção D está incorreta porque a opção A é a resposta correta. 
Capítulo 16: Implantando aplicativos com o Cloud Launcher e o Deployment Manager 497 
4. B. O Cloud Launcher possui um conjunto de filtros predefinidos, incluindo a filtragem por sistema operacional, portanto, a 
opção B está correta. Opção A pode eventualmente levar à informação correta, mas não é 
eficiente. A opção D está incorreta porque é impraticável para uma tarefa tão simples. 
5. B. Vários fornecedores podem oferecer configurações para os mesmos aplicativos, então a opção B está correta. Isso dá aos usuários a oportunidade de escolher o mais adequado às suas necessidades. 
Opções A e C estão incorretas; esse é um recurso do Cloud Launcher. A opção D está incorreta 
porque a opção B é a resposta correta.
6. C. O Cloud Launcher exibirá as opções de configuração apropriadas para o aplicativo que você 
está implementando, portanto, a opção C está correta. Por exemplo, ao implantar o WordPress, você terá 
a opção de implantar uma ferramenta de administração para o PHP. Opção A está incorreta; esse é 
um recurso do Cloud Launcher. A opção B está incorreta; você não está necessariamente na 
forma errada . Opção D está incorreta; esse é um recurso do Cloud Launcher. 
7. D. Você pode alterar a configuração de qualquer um dos itens listados, então a opção D está correta. Você 
também pode especificar regras de firewall para permitir o tráfego HTTP e HTTPS ou alterar a zona 
em que a VM é executada. 
8. B. Deployment Manager é o nome do serviço para criar recursos de aplicativo
usando um arquivo de configuração YAML, então a opção B está correta. A opção A está incorreta, embora 
você possa usar scripts com comandos gcloud para implantar recursos no Compute Engine. 
As opções C e D estão incorretas porque são nomes fictícios de produtos. 
9. D. Os arquivos de configuração são definidos na sintaxe YAML, portanto, a opção D está correta. As opções A, B 
e C estão todas incorretas; os arquivos de configuração são definidos em YAML. 
10. B. Os arquivos de configuração definem recursos e iniciam com o termo recursos, portanto, a opção B está correta. As opções A, B e C estão todas incorretas. Esses termos não iniciam o arquivo de configuração. 
11. D. Todos os três tipos, propriedades e nome são usados ​​ao definir recursos em um 
arquivo de configuração do Cloud Deployment Manager, portanto, a opção D está correta.
12. D. Todos os três podem ser definidos; Especificamente, as chaves são deviceName, boot e autodelete. 
A opção D está correta. 
13. A. A opção A é o comando correto. A opção B está incorreta; está faltando o termo compute. 
A opção C está incorreta; A gsutil é o comando para trabalhar com o Cloud Storage. A opção D 
está incorreta porque a lista de termos e as imagens estão na ordem errada. 
14. D. O Google recomenda o uso do Python para modelos complicados, portanto a opção D está correta. 
A opção A está incorreta porque o Jinja2 é recomendado apenas para modelos simples. As opções B 
e C estão incorretas; Nenhum idioma é suportado por modelos. 
15. A. A resposta correta é que as implantações do gcloud deployment-manager criam, então opção
A está correto. As opções B e D estão incorretas; o serviço não é chamado de lançador de nuvem no 
comando. A opção C está incorreta; o lançamento não é um verbo válido para este comando. 
498 Apêndice ■ Respostas às perguntas de revisão 
16. C. A resposta correta é que as implantações do gcloud deployment-manager descrevem, portanto, a 
opção C está correta. As opções A e D estão incorretas; O Cloud Launcher não é o nome do 
serviço. A opção B está incorreta; lista exibe um breve resumo de cada implantação. 
describe exibe uma descrição detalhada. 
17. A. Você poderá configurar endereços IP, portanto a opção A está correta. Você não pode configurar os 
controles de faturamento ou acesso no Gerenciador de Implantação, portanto, as opções B e C estão incorretas. Você
pode configurar o tipo de máquina, mas essa não é a seção Mais de Rede. 
18. D. A resposta correta é a opção D porque o gratuito, pago e a BYOL são todas as opções de licença 
usadas no Cloud Launcher. 
19. B. Os tipos de licença paga incluem o pagamento da licença em suas cobranças do GCP, portanto, a opção B 
está correta. O tipo de licença livre não incorre em encargos. O tipo de licença BYOL exige que você 
trabalhe com o fornecedor do software para obter e pagar uma licença. Não existe tal tipo de licença 
como chargeback, portanto, a opção D está incorreta. 
20. D. LAMP é a abreviação de Linux, Apache, MySQL e PHP. Todos estão incluídos na instalação de 
soluções LAMP, portanto, a opção D está correta. 
Capítulo 17: Configurando o acesso 
e a segurança
1. B. IAM significa Identity and Access Management, portanto, a opção B está correta. Opção A está 
incorreta; o A não significa autorização, embora isso esteja relacionado. A opção C está 
incorreta; o A não significa auditoria, embora isso esteja relacionado. A opção D está incorreta. 
O IAM também trabalha com grupos, não apenas indivíduos. 
2. A. Os membros e suas funções são listados, portanto, a opção A está correta. As opções B e C estão incorretas 
porque estão faltando a outra informação principal fornecida na listagem. Opção D 
está incorreta; as permissões não são exibidas nessa página. 
3. B. Os papéis primitivos foram criados antes do IAM e forneceram controles de acesso de granulação grossa,
então a opção B está correta. Opção A está incorreta; eles são usados ​​para controle de acesso. A opção C está 
incorreta; O IAM é a forma mais nova de controle de acesso. Opção D está incorreta; eles fornecem 
funcionalidade de controle de acesso. 
4. B. Funções são usadas para agrupar permissões que podem ser atribuídas a identidades, portanto, a opção B 
está correta. Opção A está incorreta; os papéis não têm identidades, mas as identidades podem receber 
papéis. A opção C está incorreta; as funções não usam listas de controle de acesso. Opção D está incorreta; 
funções não incluem logs de auditoria. Os registros são coletados e gerenciados pelo Stackdriver Logging. 
5. C. A resposta correta é gcloud projetos get-iam-policy ace-exame-projeto, então
a opção C está correta. Opção A está incorreta porque o recurso deve ser projetos e não 
iam. A opção B está incorreta; lista não fornece descrições detalhadas. Opção D está incorreta porque iam e lista são referenciados incorretamente. 
Capítulo 17: Configurando o acesso e a segurança 499 
6. B. Novos membros podem ser usuários, indicados por seus endereços de e-mail ou grupos, portanto, a opção B 
está correta. Opção A está incorreta; não inclui grupos. As opções C e D estão incorretas 
porque as funções não são adicionadas lá. 
7. D. Os implementadores podem ler configurações e configurações de aplicativos e gravar novas 
versões de aplicativos , portanto, a opção D está correta. A opção A está incorreta porque está faltando a capacidade de
leia configurações e configurações. A opção B está incorreta porque falta escrever novas 
versões. A opção C está incorreta porque faz referência à gravação de novas configurações. 
8. B. As etapas corretas estão navegando para IAM e Admin, selecionando Funções e, em seguida, marcando 
a caixa ao lado de uma função, portanto, a opção B está correta. Opção A está incorreta; todas as funções não são exibidas automaticamente. A opção C está incorreta; logs de auditoria não exibem permissões. Opção 
D está incorreta; não há opção de funções em contas de serviço. 
9. D. As funções predefinidas ajudam a implementar o menor privilégio e a separação de tarefas, portanto, a opção 
D está correta. As funções predefinidas não implementam a defesa em profundidade por si mesmas, mas podem ser
usado com outros controles de segurança para implementar a defesa em profundidade. 
10. D. Os quatro estágios de lançamento disponíveis são alfa, beta, disponibilidade geral e desativado, então a 
opção D está correta. 
11. B. A resposta correta, opção B, é gcloud iam roles create. Opção A está incorreta 
porque faz referência ao projeto em vez de iam. A opção C está incorreta porque faz referência ao 
projeto em vez de iam, e os termos create e roles estão fora de ordem. A opção D está 
incorreta porque os termos criar e funções estão fora de ordem.
12. B. Escopos são permissões concedidas a instâncias de VM, portanto, a opção B está correta. Escopos em combinação com funções do IAM atribuídas a contas de serviço atribuídas à instância da VM determinam quais operações a instância da VM pode executar. Opções A e C estão incorretas; escopos 
não se aplicam a recursos de armazenamento. Opção D está incorreta; escopos não se aplicam a sub-redes. 
13. C. Os identificadores de escopo começam com https://www.googleapis.com/auth/ e são seguidos por 
um nome específico do escopo, como devstorage.read_only ou logging.write, portanto, a opção C está 
correta. Opção A está incorreta; IDs de escopo não são gerados aleatoriamente. A opção B está incorreta; 
o nome do domínio não é googleserviceaccounts. Opção D está incorreta; escopos não estão 
ligados diretamente aos projetos.
14. C. Tanto os escopos como as funções do IAM atribuídas às contas de serviço devem permitir que uma operação 
seja bem-sucedida, portanto, a opção C está correta. Opção A está incorreta; controles de acesso não afetam 
o fluxo de controle em aplicativos, a menos que explicitamente codificados para isso. A opção B está incorreta; 
a permissão mais permissiva não é usada. Opção D está incorreta; a operação não terá 
sucesso. 
15. B. As opções para definir escopos são: Permitir acesso padrão, Permitir acesso total e Definir 
acesso para cada API, portanto, a opção B está correta. Opção A está incorreta; está faltando Definir acesso 
para cada API. A opção C está incorreta; está faltando Permitir acesso padrão. Opção D está incorreta; está em falta Permitir acesso total.
16. B. O comando correto é gcloud compute instances set-service-account, então a 
opção B está correta. Opção A está incorreta; não há verbos de comando set-scopes. A opção C 
está incorreta; o verbo de comando não é set-scopes. Opção D está incorreta; não há nenhum 
escopo de definição de verbos de comando . 
Apêndice ■ Respostas às perguntas de revisão 
17. A. Você pode atribuir uma conta de serviço ao criar uma VM usando o comando create. 
A opção B está incorreta; não há verbo de comando create-service-account. A opção C está 
incorreta; não há verbos de comando define-service-account. Opção D está incorreta; 
não há comando instances-service-account; Além disso, criar deve vir no final do 
comando.
18. C. O Stackdriver Logging coleta, armazena e exibe mensagens de log, portanto, a opção C está correta. 
Opção A está incorreta; O Compute Engine não gerencia logs. A opção B está incorreta; O Cloud 
Storage não é usado para exibir logs, embora arquivos de log possam ser armazenados lá. Opção D está incorreta; soluções de log personalizadas não são serviços GCP. 
19. B. Os registros podem ser filtrados por recurso, tipo de registros, nível de registro e período de tempo apenas, portanto, a 
opção B está correta. As opções A, C e D estão incorretas porque estão faltando pelo menos 
uma opção. 
20. B. Este é um exemplo de atribuição do menor privilégio necessário para executar uma tarefa, portanto, a opção 
B está correta. Opção A está incorreta; A defesa em profundidade combina vários controles de segurança.
A opção C está incorreta porque está tendo pessoas diferentes executando tarefas confidenciais. Opção D 
está incorreta; A varredura de vulnerabilidades é uma medida de segurança aplicada a aplicativos que ajuda a 
revelar possíveis vulnerabilidades em um aplicativo que um invasor poderia explorar. 
Capítulo 18: Monitoramento, Registro em Log e 
Estimativa de Custos 
1. B. O serviço Monitoramento é usado para definir um limite em métricas e gerar alertas quando uma 
métrica exceder o limite por um período de tempo especificado, portanto, a opção B está correta. Opção A 
está incorreta; O registro é para coletar eventos registrados. A opção C está incorreta; O Cloud Trace é 
para rastreamento de aplicativos. Opção D está incorreta; A depuração é usada para depurar aplicativos.
2. B. Você deve instalar o agente de monitoramento na VM. O agente coletará dados e os enviará 
ao Stackdriver, portanto a opção B estará correta. A opção A está incorreta porque um espaço de trabalho não está 
instalado em uma VM; é criado no Stackdriver. A opção C está incorreta; não há 
caixa de seleção Monitorar com o Stackdriver no formulário de configuração da VM. A opção D está incorreta porque 
você definiu canais de notificação no Stackdriver, não em uma VM. 
3. O D. Stackdriver pode monitorar recursos no GCP, na AWS e nos data centers locais, portanto, a 
opção D está correta. As opções de A a C estão incorretas porque não incluem duas 
outras opções corretas. 
4. B. Alinhamento é o processo de separar pontos de dados em intervalos regulares, portanto, a opção B é
corrigir. Opção A está incorreta; A agregação é usada para combinar pontos de dados usando uma estatística, 
como média. As opções C e D estão incorretas; eles não são processos relacionados ao processamento de 
fluxos de dados métricos. 
5. D. Todas as três opções são canais de notificação válidos no Stackdriver Monitoring, por isso, a opção D 
está correta. PagerDuty e HipChat são ferramentas populares de DevOps. 
Capítulo 18: monitoramento, registro e cálculo do custo 501 
6. D. A documentação é útil para documentar a propósito da política e por fornecer orientação para resolver o problema, por isso, a opção D é correta. Opção A está incorreta; onde 
uma política é armazenada é irrelevante para sua utilidade. As opções B e C sozinhas estão parcialmente corretas, 
mas a opção D é uma resposta melhor.
7. A. Fadiga de alerta é um estado causado pelo envio de muitas notificações de alerta para eventos que 
não requerem intervenção humana, portanto, a opção A está correta. Isso cria o risco de que, eventualmente, os engenheiros de DevOps comecem a prestar menos atenção às notificações. A opção B está incorreta, embora seja concebível que muitos alertas possam afetar adversamente o desempenho, 
mas isso não é provável. A opção C também é um problema em potencial, mas isso não é uma fadiga de alerta. 
A opção D está incorreta porque muitos alertas verdadeiros contribuem para a fadiga de alerta. 
8. C. O Stackdriver Logging armazena as entradas de registro por 30 dias, então a opção C está correta. 
9. B. A melhor opção é usar a funcionalidade de exportação do Stackdriver Logging para gravar dados de log
para um coletor de log, a opção B está correta. Opção A está incorreta; Existe uma maneira de exportar dados. 
As opções C e D estão incorretas porque escrever um script personalizado levaria mais tempo para 
desenvolver e manter do que usar a funcionalidade de exportação do Log. 
10. D. Todos os três, intervalos do Cloud Storage, conjuntos de dados do BigQuery e tópicos do Cloud Pub / Sub estão 
disponíveis como repositórios para registro de exportações, portanto, a opção D está correta. 
11. D. Todas as opções listadas podem ser usadas para filtrar, então a opção D está correta. O nível de log também é outra 
opção. 
12. B. A resposta correta, opção B, é interrompida. Não há esse status de nível de log padrão. Os status incluem Critical, Error, Warning, Info e Debug.
13. B. A maneira mais rápida de ver os detalhes é expandir todos os níveis de dados estruturados na entrada, 
portanto , a opção B está correta. A opção A mostraria os detalhes, mas não é o caminho mais rápido. A opção 
C consome mais tempo do que usar a funcionalidade incorporada no Stackdriver Logging. 
Opção D está incorreta; não existe tal link. 
14. C. O Cloud Trace é um aplicativo de rastreamento distribuído que fornece detalhes sobre quanto tempo as diferentes partes do código são executadas, portanto, a opção C está correta. Opção A está incorreta; O monitoramento é usado 
para notificar os engenheiros de DevOps quando os recursos não estão funcionando conforme o esperado. A opção B está 
incorreta; O registro é para coletar, armazenar e exibir dados de log e, embora entradas de log
pode ajudar a diagnosticar gargalos, não é especificamente projetado para isso. Opção D está incorreta; A depuração é usada para gerar instantâneos e injetar pontos de log. 
15. D. Debug é usado para gerar snapshots que fornecem uma visão do status de um aplicativo 
em um determinado ponto em sua execução, então a opção D está correta. Opção A está incorreta; O monitoramento é usado para notificar os engenheiros de DevOps quando os recursos não estão funcionando conforme o esperado. 
A opção B está incorreta; O registro é para coletar, armazenar e exibir dados de registro. A opção C está 
incorreta porque o Cloud Trace é um aplicativo de rastreamento distribuído que fornece detalhes sobre 
quanto tempo as diferentes partes do código são executadas. 
502 Apêndice ■ Respostas às perguntas de revisão
16. B. O Painel de status do Google Cloud em https://status.cloud.google.com/ tem 
informações sobre o status dos serviços do GCP, por isso, a opção B está correta. As opções A e B podem 
levar à informação, mas demorariam mais. A opção C não é um link para uma fonte de informações no BigQuery. 
17. B. O Compute Engine e o Kubernetes Engine exigirão detalhes sobre as configurações das VMs, portanto, a opção B está correta. As outras opções estão incorretas porque o BigQuery e o 
Cloud Pub / Sub são serviços sem servidor. 
18. C. O sistema de preços de consulta no BigQuery baseia-se na quantidade de dados verificados, portanto, a opção C está correta. Opção A está incorreta; a quantidade de armazenamento de dados é especificada no Preço de armazenamento
seção. A opção B está incorreta; O preço de consulta não se baseia no volume de dados retornados. 
A opção D está incorreta porque isso não está relacionado ao Cloud Storage. A opção D está incorreta 
porque a opção C está correta. 
19. B. Alguns sistemas operacionais, como o Microsoft Windows Server, exigem uma licença, portanto, a opção B 
está correta. O Google às vezes tem acordos com fornecedores para cobrar taxas pelo uso de software proprietário. Opção A está incorreta; não há cobrança de taxa fixa para sistemas operacionais. 
A opção C está incorreta; Às vezes, as informações são necessárias para computar as cobranças. A opção D 
está incorreta porque, se você trouxer sua própria licença, não haverá cobrança de licença adicional.
20. B. O OpenCensus é uma biblioteca para o desenvolvimento de métricas personalizadas que podem ser usadas com o Stackdriver 
Logging, portanto, a opção B está correta. Opção A está incorreta; O Prometheus é uma ferramenta de monitoramento de código aberto, mas não é usado para definir métricas personalizadas no Stackdriver Monitoring. A opção C 
está incorreta; Grafana é uma ferramenta de visualização para Prometheus. Opção D está incorreta; O Nagios 
é um serviço de monitoramento e alerta de código aberto, mas não é usado para definir 
métricas personalizadas no Stackdriver Logging.

